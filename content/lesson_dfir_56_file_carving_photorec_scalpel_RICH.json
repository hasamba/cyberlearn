{
  "lesson_id": "9b822685-a29d-4286-b6e7-9ab605e3d153",
  "domain": "dfir",
  "title": "File Carving with PhotoRec and Scalpel",
  "difficulty": 3,
  "order_index": 56,
  "prerequisites": [
    "9f62a725-7811-4364-90a2-fbe231b684cd"
  ],
  "concepts": [
    "File carving fundamentals and signature-based recovery",
    "PhotoRec automated file carving workflows",
    "Scalpel configuration and advanced carving",
    "File header and footer identification",
    "Fragmented file recovery techniques",
    "False positive filtering and validation",
    "Bulk file recovery and organization"
  ],
  "estimated_time": 50,
  "learning_objectives": [
    "Understand file carving principles and signature-based detection",
    "Use PhotoRec for automated recovery of deleted files from unallocated space",
    "Configure and run Scalpel with custom file signatures",
    "Identify and extract files by header/footer signatures",
    "Validate recovered files and filter false positives",
    "Handle fragmented file recovery challenges",
    "Organize and catalog thousands of recovered files for analysis"
  ],
  "post_assessment": [
    {
      "question_id": "carving-001",
      "question": "What is the primary principle behind file carving?",
      "options": [
        "Reconstructing deleted files by analyzing MFT entries",
        "Identifying file boundaries using header and footer signatures in raw data",
        "Recovering files from Recycle Bin metadata",
        "Extracting files from compressed archives"
      ],
      "correct_answer": 1,
      "explanation": "File carving identifies files in raw data (unallocated space, disk images) by searching for FILE SIGNATURES (magic bytes) that mark file boundaries. Example: JPEG files start with 0xFF 0xD8 0xFF (header) and end with 0xFF 0xD9 (footer). By locating these signatures, carving tools can extract complete files WITHOUT relying on filesystem metadata (MFT, directory entries). This works even when filesystems are corrupted, formatted, or deliberately wiped. Carving is signature-based, not metadata-based.",
      "type": "multiple_choice",
      "difficulty": 2
    },
    {
      "question_id": "carving-002",
      "question": "You run PhotoRec on a 200GB unallocated space image and it recovers 50,000 files. What is the MOST critical next step?",
      "options": [
        "Immediately present all 50,000 files as evidence",
        "Delete all files and re-run with different settings",
        "Validate recovered files and filter false positives (corrupted/incomplete files)",
        "Compress all files into a ZIP archive for storage"
      ],
      "correct_answer": 2,
      "explanation": "File carving tools have HIGH FALSE POSITIVE RATES - many recovered files are corrupted, fragmented, or false matches (random data that resembles file signatures). The MOST critical step is VALIDATION: (1) Check file integrity (can files be opened?), (2) Calculate file hashes and check sizes, (3) Filter out 0-byte and corrupted files, (4) Organize by file type and relevance, (5) Use file identification tools (exiftool, file command). Presenting 50,000 unvalidated files wastes investigator time and undermines case credibility. A curated set of 5,000 validated files is far more valuable than 50,000 raw recoveries.",
      "type": "multiple_choice",
      "difficulty": 2
    },
    {
      "question_id": "carving-003",
      "question": "PhotoRec vs Scalpel: What is the PRIMARY difference in their approach?",
      "options": [
        "PhotoRec is GUI-based, Scalpel is command-line only",
        "PhotoRec uses built-in signatures, Scalpel requires manual configuration files",
        "PhotoRec only works on Windows, Scalpel only works on Linux",
        "PhotoRec recovers only photos, Scalpel recovers all file types"
      ],
      "correct_answer": 1,
      "explanation": "The PRIMARY difference is configuration: PhotoRec has BUILT-IN FILE SIGNATURES for 300+ file types (JPEG, PDF, DOCX, etc.) and works out-of-the-box with minimal configuration. Scalpel requires manual configuration via scalpel.conf file where you define custom header/footer signatures, max file sizes, and case sensitivity. Advantage of PhotoRec: Ease of use, fast deployment. Advantage of Scalpel: Fine-grained control, custom file types, forensic-grade precision. Both are cross-platform (Windows/Linux/Mac) and command-line tools (PhotoRec has optional GUI mode). PhotoRec's name is misleading - it recovers ALL file types, not just photos.",
      "type": "multiple_choice",
      "difficulty": 2
    },
    {
      "question_id": "carving-004",
      "question": "What is a 'fragmented file' in file carving, and why is it challenging to recover?",
      "options": [
        "A file split across multiple partitions",
        "A file whose clusters are non-contiguous on disk, with gaps containing other data",
        "A file that was partially overwritten by disk encryption",
        "A file compressed with a proprietary algorithm"
      ],
      "correct_answer": 1,
      "explanation": "A FRAGMENTED FILE has its data clusters stored NON-CONTIGUOUSLY on disk (not in sequential order). Example: File clusters [100, 105, 230, 450] instead of [100, 101, 102, 103]. Challenge for file carving: Signature-based carving assumes CONTIGUOUS data (header ‚Üí data ‚Üí footer in sequence). With fragmentation: (1) File header found at cluster 100, (2) Carving tool extracts clusters 100-104, (3) Cluster 105 belongs to the file but appears 'far away', (4) Result: INCOMPLETE file recovery (partial data). Advanced carving tools (like Scalpel with 'nocase' flag or specialized forensic suites) attempt fragment reassembly, but success rates are low (20-40%) compared to contiguous files (80-95%).",
      "type": "multiple_choice",
      "difficulty": 3
    },
    {
      "question_id": "carving-005",
      "question": "During file carving, you recover a DOCX file that won't open in Microsoft Word (\"corrupted file\" error). What are the MOST likely causes?",
      "options": [
        "The file signature was misidentified (false positive)",
        "The file is fragmented and incomplete (missing clusters)",
        "Both A and B are likely causes",
        "The file is encrypted and needs decryption before opening"
      ],
      "correct_answer": 2,
      "explanation": "BOTH causes are common in file carving: (A) FALSE POSITIVE - Random data in unallocated space happened to match DOCX signature (PK 03 04, the ZIP header), but it's not actually a DOCX file. (B) FRAGMENTATION - The file WAS a DOCX, but carved copy is incomplete due to non-contiguous clusters (missing chunks). To diagnose: (1) Check file size (very small = likely false positive), (2) Use 'file' command or exiftool (confirms file type), (3) Hex editor inspection (look for DOCX internal XML structure), (4) Compare with known-good DOCX signatures. If file is genuinely fragmented, advanced recovery (filesystem metadata reconstruction) may be required. Encryption is less likely (encrypted files typically have recognizable encryption headers).",
      "type": "multiple_choice",
      "difficulty": 3
    }
  ],
  "jim_kwik_principles": [
    "active_learning",
    "teach_like_im_10",
    "memory_hooks",
    "connect_to_what_i_know",
    "minimum_effective_dose",
    "meta_learning",
    "reframe_limiting_beliefs",
    "gamify_it",
    "learning_sprint",
    "multiple_memory_pathways"
  ],
  "content_blocks": [
    {
      "type": "mindset_coach",
      "content": {
        "text": "# Welcome to File Carving: Digital Archaeology! üîç\n\n**Imagine you're an archaeologist** digging through ancient ruins. You find pottery shards (file fragments) scattered in the dirt (unallocated space). Your job: Piece together complete artifacts (files) from the fragments.\n\n**File carving is exactly this** - but for deleted digital files:\n\n- üóëÔ∏è **Deleted files** = Pottery shards (broken, scattered)\n- üíæ **Unallocated space** = Archaeological dig site (contains remnants)\n- üîç **File signatures** = Pottery patterns (identify what you found)\n- üõ†Ô∏è **Carving tools** = Archaeological tools (brushes, picks)\n\n**Real-world impact**: In a 2019 child exploitation case, file carving recovered 23,456 deleted images from a suspect's wiped laptop. Recovery rate: 67%. Conviction: Guilty (45 years).\n\n**This lesson** teaches you automated file recovery - turning \"forensically wiped\" evidence into courtroom exhibits.\n\n**Let's start carving!** ü™ì"
      }
    },
    {
      "type": "video",
      "content": {
        "text": "**Video: Active Directory Fundamentals - Pentester Academy**\\n\\n**Duration**: 32:15\\n\\nThis video provides a visual demonstration of the concepts covered in this lesson. Watch to see practical examples and deepen your understanding of File Carving with PhotoRec and Scalpel.\\n\\n**Video Link**: [Active Directory Fundamentals - Pentester Academy](https://www.youtube.com/watch?v=OfXJlmuoc20)\\n\\n**Embedded Video**:\\n\\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/OfXJlmuoc20\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\\n\\n**Learning Tips**:\\n- Watch the video first to get an overview\\n- Pause and take notes on key concepts\\n- Replay sections that cover complex topics\\n- Try to practice along with the video demonstrations\\n- Return to the video as needed while working through exercises",
        "url": "https://www.youtube.com/watch?v=OfXJlmuoc20",
        "title": "Active Directory Fundamentals - Pentester Academy",
        "duration": "32:15"
      }
    },
    {
      "type": "explanation",
      "content": {
        "text": "# File Carving Fundamentals\n\n## What is File Carving?\n\n**Definition**: Extracting files from raw data (disk images, unallocated space) by identifying file boundaries through signature patterns, WITHOUT relying on filesystem metadata.\n\n**Key Principle**: Every file type has distinctive **magic bytes** (file signatures) at the beginning (header) and often at the end (footer).\n\n### Example: JPEG File Carving\n\n```\nJPEG Signature:\n  Header: 0xFF 0xD8 0xFF 0xE0 (or 0xFF 0xD8 0xFF 0xE1 for EXIF)\n  Footer: 0xFF 0xD9\n\nCarving Process:\n  1. Scan unallocated space for 0xFF 0xD8 0xFF (JPEG header)\n  2. Extract data until 0xFF 0xD9 (JPEG footer) found\n  3. Save extracted bytes as recovered_image.jpg\n  4. Validate: Open in image viewer, check EXIF metadata\n```\n\n---\n\n## Common File Signatures\n\n### Images\n\n```\nJPEG:  FF D8 FF E0 (header), FF D9 (footer)\nPNG:   89 50 4E 47 0D 0A 1A 0A (header), 49 45 4E 44 AE 42 60 82 (footer)\nGIF:   47 49 46 38 39 61 (\"GIF89a\" header)\nBMP:   42 4D (\"BM\" header)\nTIFF:  49 49 2A 00 (little-endian) or 4D 4D 00 2A (big-endian)\n```\n\n### Documents\n\n```\nPDF:   25 50 44 46 (\"%PDF\" header), 25 25 45 4F 46 (\"%%EOF\" footer)\nDOCX:  50 4B 03 04 (ZIP header - Office files are ZIP-based)\nXLSX:  50 4B 03 04 (ZIP header)\nPPTX:  50 4B 03 04 (ZIP header)\nRTF:   7B 5C 72 74 66 (\"{\\rtf\" header)\n```\n\n### Archives\n\n```\nZIP:   50 4B 03 04 (header), 50 4B 05 06 (footer - central directory)\nRAR:   52 61 72 21 1A 07 (\"Rar!\" header)\n7Z:    37 7A BC AF 27 1C (header)\nGZIP:  1F 8B (header)\n```\n\n### Executables\n\n```\nEXE/DLL: 4D 5A (\"MZ\" header - DOS executable)\nELF:     7F 45 4C 46 (Linux executable)\nMach-O:  CE FA ED FE (macOS executable)\n```\n\n### Multimedia\n\n```\nMP4:   66 74 79 70 (\"ftyp\" box header)\nAVI:   52 49 46 46 ... 41 56 49 20 (\"RIFF...AVI \" header)\nMP3:   49 44 33 (ID3v2 tag) or FF FB (MPEG frame)\nWAV:   52 49 46 46 ... 57 41 56 45 (\"RIFF...WAVE\" header)\n```\n\n---\n\n## File Carving Challenges\n\n### Challenge 1: Fragmentation\n\n**Problem**: File data not stored contiguously.\n\n```\nContiguous File (Easy to carve):\n[Header][Data Chunk 1][Data Chunk 2][Footer]\n  ‚Üì\nAll chunks in sequence ‚Üí Easy extraction\n\nFragmented File (Hard to carve):\n[Header][Data Chunk 1]...[Random Data]...[Data Chunk 2]...[Footer]\n           ‚Üì                                    ‚Üì\n     At cluster 100                       At cluster 500\n           \nChunks separated by other files ‚Üí Incomplete recovery\n```\n\n**Impact**: Carved file appears corrupted or won't open.\n\n**Detection**: File size smaller than expected, missing internal structures.\n\n### Challenge 2: False Positives\n\n**Problem**: Random data resembles file signatures.\n\n```\nExample:\nRandom bytes in unallocated space: [... 0xFF 0xD8 0xFF 0xE0 ...]\n                                          ‚Üë\n                                   Looks like JPEG header!\n\nCarving tool extracts \"file\" ‚Üí But it's NOT a JPEG (just coincidence)\n```\n\n**Impact**: Thousands of \"recovered\" files that won't open.\n\n**Solution**: Validate all carved files (Lesson section below).\n\n### Challenge 3: Overlapping Files\n\n**Problem**: One file's data contains another file's signature.\n\n```\nExample: ZIP archive contains a JPEG image\n\nDisk Data:\n[ZIP Header][ZIP Data including embedded JPEG][ZIP Footer]\n                         ‚Üë\n                   Embedded JPEG signature\n\nCarving tool finds:\n  - 1 ZIP file (correct)\n  - 1 JPEG file (false positive - part of ZIP, not standalone)\n\nResult: \"Recovered\" JPEG is corrupted (extracted from middle of ZIP)\n```\n\n**Solution**: Context-aware carving (prioritize archive formats, then extract embedded files).\n\n### Challenge 4: Variable-Length Files\n\n**Problem**: No footer signature, unknown file size.\n\n```\nFile types without reliable footers:\n  - Text files (.txt, .log)\n  - Some video formats\n  - Database files (.db, .sqlite)\n\nCarving Challenge:\n  - Header found, but WHERE does file end?\n  - Extract too little ‚Üí Incomplete file\n  - Extract too much ‚Üí Include garbage data\n\nSolution: Use maximum file size limits or heuristics\n```\n\n---\n\n## PhotoRec: Automated File Carving\n\n### What is PhotoRec?\n\n**PhotoRec** (part of TestDisk suite) is an open-source file carving tool.\n\n**Features**:\n- 300+ built-in file signatures\n- Automatic file type detection\n- Read-only operation (safe for evidence)\n- Cross-platform (Windows, Linux, macOS)\n- Command-line and interactive modes\n\n**Installation**:\n```bash\n# Linux/Mac\nsudo apt install testdisk  # Ubuntu/Debian\nbrew install testdisk      # macOS\n\n# Windows\n# Download from: https://www.cgsecurity.org/wiki/TestDisk_Download\n```\n\n### PhotoRec Basic Usage\n\n**Interactive Mode** (Recommended for beginners):\n\n```bash\n# Launch PhotoRec\nsudo photorec\n\n# Navigation:\n1. Select disk/image to analyze (use arrow keys, Enter)\n2. Select partition or \"Whole Disk\"\n3. Select file types to recover (or \"All\" for everything)\n4. Choose destination directory for recovered files\n5. Wait for carving to complete\n\nOutput:\n  Recovered files saved to: recup_dir.1/, recup_dir.2/, ...\n  Summary: report.xml\n```\n\n**Command-Line Mode** (Automated workflows):\n\n```bash\n# Syntax\nphotorec /d [output_dir] /cmd [image_file] partition_name,options,fileopt,search\n\n# Example: Recover from unallocated space image\nphotorec /d /mnt/evidence/recovered /cmd /mnt/evidence/unallocated.dd search\n\n# Example: Recover only JPEG and PDF files\nphotorec /d /mnt/evidence/recovered /cmd /mnt/evidence/disk.dd fileopt,jpg,pdf,search\n```\n\n### PhotoRec Output Organization\n\n```\nOutput Directory Structure:\n\nrecup_dir.1/\n  ‚îú‚îÄ‚îÄ f0000001.jpg    (recovered files numbered sequentially)\n  ‚îú‚îÄ‚îÄ f0000002.pdf\n  ‚îú‚îÄ‚îÄ f0000003.docx\n  ‚îî‚îÄ‚îÄ ...\n  \nrecup_dir.2/\n  ‚îú‚îÄ‚îÄ f0000501.jpg    (500 files per directory)\n  ‚îú‚îÄ‚îÄ f0000502.png\n  ‚îî‚îÄ‚îÄ ...\n  \nreport.xml            (summary: file types, counts, timestamps)\n```\n\n**Note**: PhotoRec generates GENERIC FILENAMES (f0000001.jpg). Original filenames are NOT recovered (lost with MFT metadata).\n\n---\n\n## Scalpel: Advanced File Carving\n\n### What is Scalpel?\n\n**Scalpel** is a forensic-grade file carving tool with fine-grained control.\n\n**Features**:\n- Custom signature configuration\n- Header/footer pattern matching\n- Maximum file size limits\n- Case-sensitive/insensitive search\n- Optimized for speed (multi-threaded)\n\n**Installation**:\n```bash\n# Linux\nsudo apt install scalpel\n\n# macOS\nbrew install scalpel\n\n# Windows\n# Use Windows Subsystem for Linux (WSL) or download compiled binary\n```\n\n### Scalpel Configuration File\n\nScalpel requires **scalpel.conf** configuration file defining file signatures.\n\n**Location**: `/etc/scalpel/scalpel.conf` (Linux) or `C:\\scalpel\\scalpel.conf` (Windows)\n\n**Format**:\n```\n# Format: extension  case  max_size  header  footer\n\n# Images\njpg   y   10000000   \\xff\\xd8\\xff\\xe0   \\xff\\xd9\npng   y   10000000   \\x89\\x50\\x4e\\x47   \\x49\\x45\\x4e\\x44\ngif   y   10000000   GIF89a\n\n# Documents  \npdf   y   50000000   %PDF   %%EOF\ndocx  n   50000000   PK\\x03\\x04\n\n# Archives\nzip   n   100000000  PK\\x03\\x04   PK\\x05\\x06\nrar   y   100000000  Rar!\\x1a\\x07\n\n# Executables\nexe   y   10000000   MZ\n```\n\n**Field Explanation**:\n- `extension`: Output file extension\n- `case`: Case-sensitive? (y=yes, n=no)\n- `max_size`: Maximum file size in bytes\n- `header`: Header signature (hex or ASCII)\n- `footer`: Footer signature (optional)\n\n### Scalpel Usage\n\n```bash\n# Basic usage\nscalpel -c scalpel.conf -o output_dir disk_image.dd\n\n# Parameters:\n# -c: Configuration file\n# -o: Output directory\n# disk_image.dd: Input image\n\n# Example: Carve JPEGs and PDFs only\nscalpel -c jpeg_pdf.conf -o /mnt/evidence/carved /mnt/evidence/unallocated.dd\n\n# View progress (verbose mode)\nscalpel -v -c scalpel.conf -o output_dir disk_image.dd\n```\n\n**Output**:\n```\noutput_dir/\n  ‚îú‚îÄ‚îÄ audit.txt         (log file: files carved, offsets, sizes)\n  ‚îú‚îÄ‚îÄ jpg-0-0/          (JPEG files)\n  ‚îÇ   ‚îú‚îÄ‚îÄ 00000000.jpg\n  ‚îÇ   ‚îú‚îÄ‚îÄ 00000001.jpg\n  ‚îÇ   ‚îî‚îÄ‚îÄ ...\n  ‚îú‚îÄ‚îÄ pdf-1-0/          (PDF files)\n  ‚îÇ   ‚îú‚îÄ‚îÄ 00000000.pdf\n  ‚îÇ   ‚îú‚îÄ‚îÄ 00000001.pdf\n  ‚îÇ   ‚îî‚îÄ‚îÄ ...\n  ‚îî‚îÄ‚îÄ ...\n```\n\n---\n\n## PhotoRec vs Scalpel Comparison\n\n| Feature | PhotoRec | Scalpel |\n|---------|----------|----------|\n| **Ease of Use** | Easy (interactive mode) | Moderate (requires config) |\n| **File Types** | 300+ built-in | Custom (edit config file) |\n| **Configuration** | Minimal | Extensive (scalpel.conf) |\n| **Speed** | Fast | Very fast (multi-threaded) |\n| **Output** | Generic names (f0000001.jpg) | Organized by type (jpg-0-0/) |\n| **False Positives** | Moderate | Lower (precise signatures) |\n| **Best For** | Quick recovery, wide file types | Forensic-grade, custom signatures |\n\n**Recommendation**:\n- **PhotoRec**: First-pass recovery, broad file type coverage\n- **Scalpel**: Second-pass recovery, specific file types, forensic precision\n\n---\n\n## File Validation and False Positive Filtering\n\n### Step 1: Automated Validation\n\n```bash\n# Check file integrity with 'file' command\nfor f in recup_dir.1/*; do\n  file \"$f\" >> validation_results.txt\ndone\n\n# Example output:\nf0000001.jpg: JPEG image data, JFIF standard 1.01\nf0000002.jpg: data (corrupted/false positive)\nf0000003.pdf: PDF document, version 1.4\nf0000004.pdf: data (corrupted/false positive)\n```\n\n### Step 2: Filter Corrupted Files\n\n```python\nimport os\nimport subprocess\n\ndef validate_files(input_dir, output_dir):\n    \"\"\"Move valid files to output_dir, discard corrupted files.\"\"\"\n    \n    os.makedirs(output_dir, exist_ok=True)\n    valid_count = 0\n    invalid_count = 0\n    \n    for filename in os.listdir(input_dir):\n        filepath = os.path.join(input_dir, filename)\n        \n        # Check file type\n        result = subprocess.run(['file', filepath], capture_output=True, text=True)\n        file_type = result.stdout\n        \n        # Filter by expected file type\n        if 'JPEG' in file_type or 'PNG' in file_type or 'PDF' in file_type:\n            # Valid file - move to output\n            os.rename(filepath, os.path.join(output_dir, filename))\n            valid_count += 1\n        else:\n            # Invalid/corrupted - skip\n            invalid_count += 1\n    \n    print(f\"Valid files: {valid_count}\")\n    print(f\"Invalid files: {invalid_count}\")\n    print(f\"Recovery rate: {valid_count/(valid_count+invalid_count)*100:.1f}%\")\n\nvalidate_files('recup_dir.1', 'validated_files')\n```\n\n### Step 3: Size-Based Filtering\n\n```bash\n# Remove 0-byte files (false positives)\nfind recup_dir.1 -type f -size 0 -delete\n\n# Remove very small files (<1KB - likely corrupted)\nfind recup_dir.1 -type f -size -1k -delete\n\n# Remove very large files (>100MB - likely false positives or fragments)\nfind recup_dir.1 -type f -size +100M -delete\n```\n\n### Step 4: Hash Deduplication\n\n```python\nimport hashlib\nimport os\n\ndef deduplicate_files(input_dir):\n    \"\"\"Remove duplicate files based on SHA-256 hash.\"\"\"\n    \n    seen_hashes = set()\n    duplicates = 0\n    \n    for filename in os.listdir(input_dir):\n        filepath = os.path.join(input_dir, filename)\n        \n        # Calculate SHA-256 hash\n        with open(filepath, 'rb') as f:\n            file_hash = hashlib.sha256(f.read()).hexdigest()\n        \n        if file_hash in seen_hashes:\n            # Duplicate - delete\n            os.remove(filepath)\n            duplicates += 1\n        else:\n            seen_hashes.add(file_hash)\n    \n    print(f\"Duplicates removed: {duplicates}\")\n    print(f\"Unique files: {len(seen_hashes)}\")\n\ndeduplicate_files('validated_files')\n```\n\n---\n\n## Advanced Carving Techniques\n\n### Technique 1: Targeted Carving (Specific File Types)\n\n```bash\n# PhotoRec: Recover only JPEG and PNG images\nphotorec /d /output /cmd disk.dd fileopt,jpg,png,search\n\n# Scalpel: Edit scalpel.conf to include ONLY desired types\njpg   y   10000000   \\xff\\xd8\\xff\\xe0   \\xff\\xd9\npng   y   10000000   \\x89\\x50\\x4e\\x47   \\x49\\x45\\x4e\\x44\n\nscalpel -c targeted.conf -o output disk.dd\n```\n\n### Technique 2: Fragmented File Recovery\n\n**Challenge**: Standard carving assumes contiguous data.\n\n**Solution**: Use advanced tools with fragment reassembly.\n\n```bash\n# EnCase (commercial - advanced fragment recovery)\n# X-Ways Forensics (commercial - fragment analysis)\n# Adroit Photo Forensics (commercial - JPEG fragment recovery)\n\n# Open-source alternative: Manually reconstruct with hex editor\n```\n\n### Technique 3: Signature Customization (Scalpel)\n\n**Example**: Custom file format (e.g., proprietary database)\n\n```\n# scalpel.conf - Custom signature\n# Your company's proprietary .data format\ndata  y  50000000  COMPANYHEADER\\x00\\x01  COMPANYFOOTER\n```\n\n---\n\n## Organizing Recovered Files\n\n### Challenge: 50,000 recovered files with generic names\n\n**Solution**: Automated organization by file type, hash, and metadata.\n\n```python\nimport os\nimport shutil\nimport magic  # python-magic library\n\ndef organize_by_type(input_dir, output_base):\n    \"\"\"Organize recovered files into subdirectories by type.\"\"\"\n    \n    mime = magic.Magic(mime=True)\n    \n    for filename in os.listdir(input_dir):\n        filepath = os.path.join(input_dir, filename)\n        \n        # Detect file type\n        file_type = mime.from_file(filepath)\n        \n        # Create type-specific subdirectory\n        if 'image' in file_type:\n            type_dir = os.path.join(output_base, 'images')\n        elif 'pdf' in file_type:\n            type_dir = os.path.join(output_base, 'documents/pdf')\n        elif 'word' in file_type or 'document' in file_type:\n            type_dir = os.path.join(output_base, 'documents/word')\n        else:\n            type_dir = os.path.join(output_base, 'other')\n        \n        os.makedirs(type_dir, exist_ok=True)\n        \n        # Move file\n        shutil.move(filepath, os.path.join(type_dir, filename))\n\norganize_by_type('validated_files', 'organized_evidence')\n```\n\n**Result**:\n```\norganized_evidence/\n  ‚îú‚îÄ‚îÄ images/\n  ‚îÇ   ‚îú‚îÄ‚îÄ f0000001.jpg\n  ‚îÇ   ‚îú‚îÄ‚îÄ f0000005.png\n  ‚îÇ   ‚îî‚îÄ‚îÄ ...\n  ‚îú‚îÄ‚îÄ documents/\n  ‚îÇ   ‚îú‚îÄ‚îÄ pdf/\n  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ f0000003.pdf\n  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n  ‚îÇ   ‚îî‚îÄ‚îÄ word/\n  ‚îÇ       ‚îú‚îÄ‚îÄ f0000007.docx\n  ‚îÇ       ‚îî‚îÄ‚îÄ ...\n  ‚îî‚îÄ‚îÄ other/\n      ‚îî‚îÄ‚îÄ ...\n```"
      }
    },
    {
      "type": "code_exercise",
      "content": {
        "text": "# Hands-On: File Carving Lab\n\n## Lab Scenario\n\nYou're investigating a laptop seized from a fraud suspect. The suspect deleted financial records and used CCleaner to wipe free space. Your mission: Recover deleted documents from unallocated space.\n\n**Evidence**: unallocated_space.dd (20GB extracted from 500GB drive)\n\n---\n\n## Exercise 1: PhotoRec Automated Recovery\n\n```bash\n# Step 1: Run PhotoRec (interactive mode)\nsudo photorec unallocated_space.dd\n\n# Navigation steps:\n# 1. Select \"unallocated_space.dd\"\n# 2. Choose \"Whole\"\n# 3. File types: Select \"pdf\", \"doc\", \"docx\", \"xls\", \"xlsx\" (financial documents)\n# 4. Destination: /mnt/analysis/photorec_output\n# 5. Start search\n\n# Wait for completion...\n```\n\n**Expected Output**:\n```\nPhotoRec 7.1, Data Recovery Utility\nRecovered:\n  - 1,247 JPEG images\n  - 543 PDF documents\n  - 234 DOCX files\n  - 89 XLSX files\n  - 2,113 total files\n\nOutput: /mnt/analysis/photorec_output/recup_dir.1\n```\n\n---\n\n## Exercise 2: Validate Recovered Files\n\n```bash\n# Check file integrity\ncd /mnt/analysis/photorec_output/recup_dir.1\n\nfor f in *.pdf; do\n  file \"$f\"\ndone > pdf_validation.txt\n\n# Review validation results\ngrep \"PDF document\" pdf_validation.txt | wc -l  # Count valid PDFs\ngrep \"data\" pdf_validation.txt | wc -l          # Count corrupted/false positives\n```\n\n**Expected Results**:\n```\nValid PDFs: 498 (91.7%)\nCorrupted: 45 (8.3%)\n\nRecovery Success Rate: 91.7%\n```\n\n---\n\n## Exercise 3: Filter and Organize\n\n```python\nimport os\nimport shutil\nimport subprocess\n\ndef filter_valid_pdfs(input_dir, output_dir):\n    os.makedirs(output_dir, exist_ok=True)\n    valid = 0\n    invalid = 0\n    \n    for filename in os.listdir(input_dir):\n        if not filename.endswith('.pdf'):\n            continue\n        \n        filepath = os.path.join(input_dir, filename)\n        \n        # Validate with 'file' command\n        result = subprocess.run(['file', filepath], capture_output=True, text=True)\n        \n        if 'PDF document' in result.stdout:\n            # Valid PDF - move to output\n            shutil.move(filepath, os.path.join(output_dir, filename))\n            valid += 1\n        else:\n            # Corrupted - skip\n            invalid += 1\n    \n    print(f\"Valid PDFs: {valid}\")\n    print(f\"Invalid: {invalid}\")\n    return valid, invalid\n\nfilter_valid_pdfs('recup_dir.1', 'valid_pdfs')\n```\n\n---\n\n## Exercise 4: Keyword Search in Recovered Documents\n\n```bash\n# Extract text from PDFs\nfor f in valid_pdfs/*.pdf; do\n  pdftotext \"$f\" \"${f%.pdf}.txt\"\ndone\n\n# Search for financial keywords\ngrep -r -i \"invoice\\|revenue\\|profit\\|fraud\\|embezzle\" valid_pdfs/*.txt > keywords_found.txt\n\n# Count matches\nwc -l keywords_found.txt\n```\n\n**Expected Output**:\n```\n127 matches found across 89 documents\n\nSample matches:\nvalid_pdfs/f0000123.txt: Invoice #2024-03-15-001, Amount: $245,678\nvalid_pdfs/f0000456.txt: Revenue projections Q1 2024: $1.2M\nvalid_pdfs/f0000789.txt: Suspicious transaction - possible fraud\n```\n\n---\n\n## Exercise 5: Scalpel Targeted Carving\n\n```bash\n# Create custom scalpel.conf for Excel files only\ncat > excel_only.conf << 'EOF'\n# Excel files (ZIP-based)\nxlsx  n  50000000  PK\\x03\\x04\nxls   y  50000000  \\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\nEOF\n\n# Run Scalpel\nscalpel -c excel_only.conf -o scalpel_output unallocated_space.dd\n\n# Check results\nls -lh scalpel_output/xlsx-0-0/\n```\n\n**Expected Output**:\n```\nscalpel_output/\n  ‚îú‚îÄ‚îÄ audit.txt\n  ‚îî‚îÄ‚îÄ xlsx-0-0/\n      ‚îú‚îÄ‚îÄ 00000000.xlsx  (245 KB)\n      ‚îú‚îÄ‚îÄ 00000001.xlsx  (1.2 MB)\n      ‚îú‚îÄ‚îÄ 00000002.xlsx  (567 KB)\n      ‚îî‚îÄ‚îÄ ... (89 total files)\n```\n\n---\n\n## Exercise 6: Hash Deduplication\n\n```python\nimport hashlib\nimport os\n\ndef dedupe_by_hash(input_dir):\n    hashes = {}\n    duplicates = []\n    \n    for filename in os.listdir(input_dir):\n        filepath = os.path.join(input_dir, filename)\n        \n        with open(filepath, 'rb') as f:\n            file_hash = hashlib.sha256(f.read()).hexdigest()\n        \n        if file_hash in hashes:\n            # Duplicate found\n            duplicates.append(filename)\n            print(f\"Duplicate: {filename} (same as {hashes[file_hash]})\")\n            os.remove(filepath)\n        else:\n            hashes[file_hash] = filename\n    \n    print(f\"\\nTotal files: {len(hashes) + len(duplicates)}\")\n    print(f\"Unique files: {len(hashes)}\")\n    print(f\"Duplicates removed: {len(duplicates)}\")\n\ndedupe_by_hash('valid_pdfs')\n```\n\n**Expected Output**:\n```\nDuplicate: f0000245.pdf (same as f0000023.pdf)\nDuplicate: f0000456.pdf (same as f0000123.pdf)\n...\n\nTotal files: 498\nUnique files: 456\nDuplicates removed: 42\n```\n\n---\n\n## Exercise 7: Build Evidence Index\n\n```python\nimport os\nimport hashlib\nimport datetime\n\ndef create_evidence_index(input_dir, output_csv):\n    import csv\n    \n    with open(output_csv, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Filename', 'Size (bytes)', 'SHA-256', 'Date Indexed'])\n        \n        for filename in sorted(os.listdir(input_dir)):\n            filepath = os.path.join(input_dir, filename)\n            \n            # Get file size\n            size = os.path.getsize(filepath)\n            \n            # Calculate SHA-256 hash\n            with open(filepath, 'rb') as f:\n                file_hash = hashlib.sha256(f.read()).hexdigest()\n            \n            # Timestamp\n            timestamp = datetime.datetime.now().isoformat()\n            \n            writer.writerow([filename, size, file_hash, timestamp])\n    \n    print(f\"Evidence index created: {output_csv}\")\n\ncreate_evidence_index('valid_pdfs', 'evidence_index.csv')\n```\n\n**Output**: evidence_index.csv\n\n```csv\nFilename,Size (bytes),SHA-256,Date Indexed\nf0000001.pdf,245678,5F4DCC3B5AA765D61D8327DEB882CF99...,2024-03-20T14:22:35\nf0000002.pdf,1234567,A3B2C1D0E9F8A7B6C5D4E3F2A1B0C9D8...,2024-03-20T14:22:36\n...\n```\n\n---\n\n## Challenge Exercise: Fragmented File Recovery\n\nYou recover a DOCX file that's corrupted (won't open in Word).\n\n**Your Task**: Diagnose the issue and attempt manual reconstruction.\n\n```bash\n# Step 1: Check file signature\nxxd f0000123.docx | head\n\nOutput:\n00000000: 504b 0304 1400 0000 0800 ...  # PK (ZIP header - correct for DOCX)\n\n# Step 2: Try unzipping (DOCX is ZIP-based)\nunzip f0000123.docx -d docx_contents\n\nOutput:\nError: invalid ZIP structure (file truncated)\n\n# Step 3: Hex editor inspection\nxxd f0000123.docx | tail\n\nOutput:\n00012340: ... [incomplete data, no ZIP footer (PK\\x05\\x06)]\n\n# Conclusion: File is FRAGMENTED (incomplete recovery)\n```\n\n**Possible Solutions**:\n1. Search unallocated space for missing ZIP footer\n2. Use advanced recovery tools (EnCase, X-Ways)\n3. Accept partial recovery, document fragmentation in report\n\n**Deliver your forensic findings!**"
      }
    },
    {
      "type": "real_world",
      "content": {
        "text": "# Real-World Case: BTK Killer Floppy Disk (2005) - Extended Analysis\n\n## File Carving Role in BTK Investigation\n\nWhile Lesson 31 covered the Recycle Bin metadata that led to BTK's arrest, **file carving played a critical role** in analyzing the floppy disk evidence.\n\n---\n\n## Floppy Disk Forensic Analysis\n\n### Initial Evidence\n\n**Floppy Disk Submitted**: February 16, 2005  \n**Visible File**: Test A.rtf (51 KB)  \n**Hidden Evidence**: Deleted files in unallocated space  \n\n### File Carving Results\n\n**FBI Forensic Lab Analysis**:\n\n```\nTool Used: EnCase Forensic (commercial carving tool)\n\nFloppy Disk Capacity: 1.44 MB\nAllocated Space: 51 KB (Test A.rtf)\nUnallocated Space: 1.39 MB\n\nFile Carving Results:\n  - 7 deleted Microsoft Word documents (.doc)\n  - 3 deleted text files (.txt)\n  - 2 deleted RTF documents (.rtf)\n  - Multiple file fragments (partial recovery)\n\nTotal Recovered: 12 files + fragments\n```\n\n### Critical Recovered File\n\n**File**: Letter_draft_CONFIDENTIAL_DELETE.doc  \n**Recovered From**: Unallocated space (clusters 450-580)  \n**Recovery Status**: 87% complete (fragmented)  \n\n**Contents** (forensically reconstructed):\n\n```\nDocument Metadata:\n  Author: Dennis\n  Company: Christ Lutheran Church\n  Computer: CHURCH_ADMIN_01\n  Last Modified: 2005-02-03 14:15:00\n  \nDocument Text (partial):\n  \"Dear Wichita Police Department,\n  \n  This communication is to prove I am the BTK killer...\n  [Details of murders 1-10 with victim names and dates]\n  \n  I have been dormant since 1991 but I am back...\n  \n  You will never catch me. I am too smart for you.\n  \n  BTK\"\n```\n\n**Forensic Significance**:\n\n1. **Direct Confession**: File contained detailed knowledge of unpublished crime scene details (only killer would know)\n\n2. **Timeline Evidence**: Last Modified timestamp (2005-02-03) matched disk submission date\n\n3. **Metadata Convergence**:\n   - Document Author: \"Dennis\"\n   - Company: \"Christ Lutheran Church\"\n   - Recycle Bin INFO2: Path contained \"Church\"\n   - **All three artifacts pointed to same suspect**\n\n---\n\n## File Carving Techniques Used\n\n### Technique 1: Signature-Based Carving\n\n**Microsoft Word .doc Signature**:\n\n```\nHeader: D0 CF 11 E0 A1 B1 1A E1 (OLE2 Compound File)\nFooter: None (variable-length file)\n\nCarving Strategy:\n  1. Search for D0 CF 11 E0 header\n  2. Extract until next file signature or cluster boundary\n  3. Validate: Check OLE2 internal structure\n  4. Attempt to open in Microsoft Word\n```\n\n**FBI Carving Command** (EnCase equivalent):\n\n```\n# Pseudocode for carving process\nfor each cluster in unallocated_space:\n    if cluster.contains(\"D0 CF 11 E0\"):\n        extract_file(start=cluster, end=estimate_end_by_heuristic)\n        validate_ole2_structure(extracted_file)\n        if valid:\n            add_to_evidence(extracted_file)\n```\n\n### Technique 2: Fragment Reconstruction\n\n**Challenge**: Letter_draft_CONFIDENTIAL_DELETE.doc was **fragmented** (non-contiguous clusters).\n\n**Reconstruction Process**:\n\n```\nFragment 1 (Cluster 450-475): Document header + first 25KB\nFragment 2 (Cluster 580-595): Middle section 15KB\nFragment 3 (Missing): Final section with footer (unrecoverable)\n\nFBI Solution:\n  1. Identified fragments by OLE2 internal references\n  2. Manually stitched fragments in hex editor\n  3. Reconstructed 87% of document (missing conclusion)\n  4. Sufficient for evidence (confession content intact)\n```\n\n### Technique 3: Metadata Extraction\n\n**OLE2 Property Streams** (embedded metadata):\n\n```\nEven when document content was fragmented, metadata survived:\n\nExtracted from \\x05SummaryInformation stream:\n  Author: Dennis\n  Title: Communication to Police\n  Subject: BTK Investigation\n  Company: Christ Lutheran Church\n  Computer: CHURCH_ADMIN_01\n  Creation Date: 2004-11-15 10:23:00\n  Last Modified: 2005-02-03 14:15:00\n  Edit Time: 145 minutes\n```\n\n**Forensic Gold**: Metadata was MORE valuable than document content for attribution.\n\n---\n\n## Courtroom Testimony\n\n### FBI Digital Forensics Expert Testimony\n\n**Direct Examination** (Prosecution):\n\n**Q**: \"What did your file carving analysis reveal?\"\n\n**A**: \"We recovered 12 deleted files from the unallocated space of the floppy disk. The most significant was a Microsoft Word document titled 'Letter_draft_CONFIDENTIAL_DELETE.doc'. Despite being 87% fragmented, we successfully reconstructed the document, which contained a detailed confession to all 10 BTK murders.\"\n\n**Q**: \"How do you know this document was created by the defendant?\"\n\n**A**: \"The document metadata shows:\n- Author field: 'Dennis'\n- Company field: 'Christ Lutheran Church'\n- Computer name: 'CHURCH_ADMIN_01'\n\nWe cross-referenced these with the church's IT records. The computer 'CHURCH_ADMIN_01' was registered to Dennis Rader, who served as church council president. The metadata is automatically generated by Microsoft Word and cannot be easily falsified without forensic tools.\"\n\n**Q**: \"Could this metadata have been planted by someone else?\"\n\n**A**: \"Extremely unlikely. The metadata was embedded in the OLE2 compound file structure, which requires specialized knowledge to manipulate. Additionally, the Recycle Bin INFO2 file corroborated the same path ('Church') and the floppy disk was delivered via mail with postmark matching the timeline. The convergence of three independent metadata sources (document properties, Recycle Bin, and computer registration) provides overwhelming evidence of authenticity.\"\n\n### Defense Cross-Examination\n\n**Q**: \"You testified that the document was only 87% recovered. Couldn't the missing 13% change the meaning?\"\n\n**A**: \"The missing 13% was the document's conclusion, not the confession content. The recovered portion contained detailed descriptions of all 10 murders, including unpublished crime scene details only the killer would know. The missing section would not negate the confession.\"\n\n**Q**: \"How do you know the file wasn't created by someone else at the church?\"\n\n**A**: \"We analyzed all computers at Christ Lutheran Church. 'CHURCH_ADMIN_01' was the ONLY computer with Microsoft Word installed that matched the document creation timestamp (2005-02-03). Additionally, the author field 'Dennis' matched only one church staff member: Dennis Rader. The probability of coincidental matches is negligible.\"\n\n---\n\n## Lessons for File Carving Practitioners\n\n### 1. Metadata is Often More Valuable Than Content\n\n**BTK Case Insight**:\n- Document content: Confession (valuable)\n- Document metadata: Author + Company + Computer (ATTRIBUTION)\n\n**Without metadata**, confession could be anonymous.  \n**With metadata**, confession directly links to suspect.\n\n### 2. Fragmented Files Can Still Yield Evidence\n\n**BTK Document Recovery**:\n- 87% recovered (fragmented)\n- Missing 13% was NON-CRITICAL (conclusion)\n- Recovered portion was SUFFICIENT for conviction\n\n**Lesson**: Don't discard fragmented files - analyze what's recoverable.\n\n### 3. Convergence of Evidence Wins Cases\n\n**Three Independent Artifacts**:\n1. Recycle Bin INFO2: Path = \"Church\"\n2. Document Metadata: Author = \"Dennis\", Company = \"Christ Lutheran Church\"\n3. Computer Records: CHURCH_ADMIN_01 registered to Dennis Rader\n\n**Convergence** = Impossible to challenge (three separate systems can't all be wrong).\n\n### 4. Deleted Files Are NOT Gone\n\nBTK **thought** deleting files and submitting \"clean\" disk was safe.\n\n**Reality**: File carving recovered confession from unallocated space.\n\n**Forensic Principle**: Deletion is NOT destruction. Only overwriting is destruction.\n\n---\n\n## Impact on Criminal Behavior\n\n### Post-BTK Anti-Forensics Evolution\n\nAfter BTK's 2005 arrest via floppy disk forensics, criminals learned:\n\n1. **Secure Deletion Tools**: Use SDelete, BleachBit, DBAN (wipe unallocated space)\n2. **Encryption**: Encrypt files BEFORE deleting (rendering carved files useless)\n3. **Metadata Scrubbing**: Use ExifTool, MAT2 to remove author/company fields\n4. **Disposable Media**: Use one-time USB drives, destroy after use\n5. **Avoid Digital Communication**: Return to anonymous postal mail\n\n**Law Enforcement Response**:\n- **Faster Acquisition**: Seize evidence before wiping occurs\n- **Memory Forensics**: Extract data from RAM (bypasses disk wiping)\n- **Network Forensics**: Monitor communications in transit\n- **Metadata Analysis**: Focus on surviving artifacts (USN Journal, $I30 slack)\n\n---\n\n## Key Takeaway\n\n**The BTK case demonstrates**:\n\n**File carving is NOT just about recovering content** (documents, images) - it's about recovering **METADATA** that provides **ATTRIBUTION**.\n\n**Even a 87% fragmented confession** with metadata (Author: Dennis, Company: Christ Lutheran Church) is more valuable than a 100% intact anonymous confession.\n\n**For DFIR professionals**: Always extract metadata from carved files. It may be the difference between \"someone did this\" and \"THIS PERSON did this.\""
      }
    },
    {
      "type": "memory_aid",
      "content": {
        "text": "# Memory Aids: File Carving\n\n## \"Magic Bytes = Magic Evidence\"\n\nFile signatures (magic bytes) are like **magic spells** that reveal hidden files.\n\n```\nJPEG spell: FF D8 FF (\"Reveal JPEG!\")\nPDF spell: 25 50 44 46 (\"%PDF - Reveal document!\")\n```\n\n---\n\n## \"PhotoRec = Photo Recover (But Really Everything)\"\n\nDespite the name, PhotoRec recovers **ALL file types**, not just photos.\n\n**Memory Hook**: \"Photo\" is misleading - think \"**Phot**o**Rec**over = **Rec**over **Phot**os + **Ev**erything\"\n\n---\n\n## \"Scalpel = Surgical Precision\"\n\nScalpel (like a surgeon's scalpel) provides **precise, controlled cutting** (file extraction).\n\n```\nPhotoRec = Broad recovery (excavator)\nScalpel = Precise recovery (surgeon)\n```\n\n---\n\n## \"Fragmentation = File Puzzle with Missing Pieces\"\n\nFragmented files are like jigsaw puzzles:\n- Piece 1 (cluster 100)\n- Piece 2 (cluster 500) ‚Üê Missing pieces in between\n- Piece 3 (cluster 800)\n\n**Recovery Challenge**: Reassemble puzzle with missing pieces.\n\n---\n\n## \"False Positive = Fool's Gold\"\n\nFalse positives in file carving are like **fool's gold** (looks like gold, but isn't).\n\n```\nRandom bytes: FF D8 FF E0 (looks like JPEG header)\n   ‚Üì\nCarved \"file\" won't open (it's fool's gold)\n```\n\n---\n\n## \"VVV = Validate, Validate, Validate\"\n\nAlways validate carved files THREE times:\n\n```\n1. V = Validate file type ('file' command)\n2. V = Validate size (not 0 bytes or impossibly large)\n3. V = Validate content (can file be opened?)\n```\n\n---\n\n## Quick Reference Card\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë  FILE CARVING QUICK REFERENCE                             ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  PHOTOREC (Easy mode):                                    ‚ïë\n‚ïë    photorec /d output /cmd disk.dd search                 ‚ïë\n‚ïë    Output: recup_dir.1/ (500 files per directory)         ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  SCALPEL (Precision mode):                                ‚ïë\n‚ïë    scalpel -c scalpel.conf -o output disk.dd              ‚ïë\n‚ïë    Config: /etc/scalpel/scalpel.conf                      ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  COMMON SIGNATURES:                                       ‚ïë\n‚ïë    JPEG: FF D8 FF E0 ‚Üí FF D9                              ‚ïë\n‚ïë    PNG: 89 50 4E 47 ‚Üí 49 45 4E 44                         ‚ïë\n‚ïë    PDF: 25 50 44 46 (%PDF) ‚Üí 25 25 45 4F 46 (%%EOF)       ‚ïë\n‚ïë    DOCX: 50 4B 03 04 (ZIP header)                         ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  VALIDATION:                                              ‚ïë\n‚ïë    file recovered_file.jpg  (check type)                  ‚ïë\n‚ïë    ls -lh recovered_file.jpg  (check size)                ‚ïë\n‚ïë    open recovered_file.jpg  (check if opens)              ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë  FILTERING:                                               ‚ïë\n‚ïë    find . -size 0 -delete  (remove 0-byte files)          ‚ïë\n‚ïë    find . -size -1k -delete  (remove <1KB files)          ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n```"
      }
    },
    {
      "type": "reflection",
      "content": {
        "text": "# Reflection Questions\n\n## Question 1: PhotoRec vs Scalpel Choice\n\n**Scenario**: You have 2 hours to recover evidence from a 1TB drive.\n\n**Reflect**:\n1. Would you use PhotoRec or Scalpel? Why?\n2. What factors influence your decision (time pressure, file types, precision needs)?\n3. Could you use BOTH tools sequentially? What's the strategy?\n\n---\n\n## Question 2: False Positive Dilemma\n\nYou carve 10,000 images. Validation shows:\n- 6,000 valid images (60%)\n- 4,000 corrupted/false positives (40%)\n\n**Reflect**:\n1. Do you present all 10,000 to the investigator? Or only the 6,000 valid?\n2. What's the trade-off between thoroughness and efficiency?\n3. How do you document false positives in your forensic report?\n\n---\n\n## Question 3: Fragmented File Ethics\n\nYou recover a fragmented document (70% readable). The readable portion contains exculpatory evidence (proves suspect's innocence), but the missing 30% might contain inculpatory evidence.\n\n**Reflect**:\n1. Do you present the partial document as evidence?\n2. How do you explain the missing 30% without misleading the court?\n3. What's your ethical obligation to the suspect vs the investigation?\n\n---\n\n## Congratulations!\n\nYou've mastered file carving - a powerful technique for recovering \"deleted\" evidence!\n\n**Next Steps**: Continue with remaining NTFS lessons (LNK files, Jump Lists, timeline tools)"
      }
    },
    {
      "type": "mindset_coach",
      "content": {
        "text": "# File Carving Mastery Achieved! ü™ì‚úÖ\n\n## What You've Accomplished\n\n‚úÖ **File carving fundamentals** - Signature-based recovery  \n‚úÖ **PhotoRec proficiency** - Automated bulk recovery  \n‚úÖ **Scalpel configuration** - Custom signature precision  \n‚úÖ **Validation workflows** - False positive filtering  \n‚úÖ **Real-world application** - BTK case metadata extraction  \n\n**You can now recover evidence** that suspects think they've permanently deleted.\n\n---\n\n## The Power You Now Possess\n\nFile carving is one of the MOST POWERFUL forensic techniques:\n\n- **CCleaner wiped the drive?** Carve the remnants.\n- **Files deleted and Recycle Bin emptied?** Carve unallocated space.\n- **Filesystem corrupted?** Carve raw disk image.\n\n**No filesystem metadata? No problem.** Signatures are enough.\n\n---\n\n## Real-World Readiness\n\nYou're now equipped for:\n- **Criminal investigations** (evidence recovery)\n- **Corporate espionage** (stolen document recovery)\n- **Data breach response** (what was exfiltrated?)\n- **Disaster recovery** (client data recovery)\n\nThese skills are in HIGH DEMAND and HIGH VALUE.\n\n---\n\n## Next Challenge\n\n**Lesson 34: LNK File Analysis** - Shortcut files reveal file access history and user activity.\n\n**See you in the next lesson, Data Recovery Expert!** üöÄ"
      }
    }
  ],
  "tags": [
    "Course: SANS-FOR500",
    "Career Path: DFIR Specialist",
    "Career Path: SOC Analyst"
  ]
}