{
  "lesson_id": "e2f3a4b5-c6d7-8e9f-0a1b-2c3d4e5f6a7b",
  "domain": "dfir",
  "title": "Cloud Memory Forensics: AWS, Azure, and GCP",
  "difficulty": 3,
  "order_index": 57,
  "prerequisites": [
    "d1e2f3a4-b5c6-7d8e-9f0a-1b2c3d4e5f6a"
  ],
  "concepts": [
    "Cloud memory forensics challenges",
    "AWS EC2 memory acquisition",
    "Azure VM memory acquisition",
    "GCP Compute Engine forensics",
    "Snapshot-based acquisition",
    "Live memory acquisition in cloud",
    "Container memory forensics",
    "Kubernetes memory analysis",
    "Cloud-native malware detection",
    "Volatile evidence in cloud",
    "Cloud access logs correlation",
    "Multi-tenancy considerations"
  ],
  "estimated_time": 60,
  "learning_objectives": [
    "Understand unique challenges of cloud memory forensics",
    "Acquire memory from AWS EC2, Azure VMs, and GCP instances",
    "Analyze containerized application memory",
    "Detect cloud-native malware and attacks",
    "Correlate memory artifacts with cloud access logs",
    "Navigate legal and technical limitations of cloud forensics"
  ],
  "post_assessment": [
    {
      "question_id": "dfir57_q1",
      "type": "multiple_choice",
      "difficulty": 3,
      "question": "You need to acquire memory from a suspicious AWS EC2 instance without alerting the attacker. What's the BEST approach?",
      "options": [
        "SSH into instance and run LiME to acquire memory",
        "Create EBS snapshot, launch new instance from snapshot, acquire memory",
        "Stop instance, create AMI, analyze AMI file",
        "Use AWS Systems Manager Run Command to execute memory acquisition remotely"
      ],
      "correct_answer": 1,
      "explanation": "Creating EBS snapshot and launching new instance from snapshot is best for stealth. How it works: (1) Create snapshot of suspicious instance's EBS volume (non-intrusive, doesn't alert attacker), (2) Launch forensic instance from snapshot (exact copy), (3) Acquire memory from forensic instance (attacker can't detect), (4) Original instance continues running (no disruption, continued monitoring possible). SSH method alerts attacker (new connection, command execution). Stopping instance loses volatile memory (running processes, network connections). Systems Manager creates CloudTrail logs attacker might monitor. Snapshot method preserves evidence while maintaining covert investigation."
    },
    {
      "question_id": "dfir57_q2",
      "type": "multiple_choice",
      "difficulty": 3,
      "question": "During cloud memory analysis, you find process 'containerd-shim' with multiple child processes. What does this indicate?",
      "options": [
        "Kernel rootkit hiding processes",
        "Container runtime managing containerized applications",
        "Malware process injection into system daemon",
        "Cloud hypervisor management process"
      ],
      "correct_answer": 1,
      "explanation": "containerd-shim is container runtime managing containerized applications. Docker/Kubernetes architecture: (1) containerd = high-level container runtime, (2) containerd-shim = per-container process that owns container's stdio, manages container lifecycle, (3) Each container has dedicated shim process, (4) Child processes = containers running on system. This is normal in cloud environments using containers. Not rootkit (legitimate system component). Not malware (standard Docker/K8s infrastructure). Not hypervisor (that's lower level - EC2 uses Xen/Nitro). Forensic significance: To analyze containerized app, must examine container's memory space (child process) AND host memory (containerd-shim + kernel). Container memory may contain application-specific malware not visible in host analysis alone."
    },
    {
      "question_id": "dfir57_q3",
      "type": "multiple_choice",
      "difficulty": 3,
      "question": "You're investigating potential data exfiltration from Azure VM. Memory shows network connection to 20.150.140.30:443. How do you determine if this is legitimate Azure service or attacker C2?",
      "options": [
        "Reverse DNS lookup on the IP",
        "Correlate with Azure Activity Logs and NSG Flow Logs",
        "Check if IP is in Azure IP ranges published by Microsoft",
        "All of the above (multi-source correlation)"
      ],
      "correct_answer": 3,
      "explanation": "All of the above - multi-source correlation is best practice. Analysis approach: (1) Reverse DNS: nslookup 20.150.140.30 might return *.blob.core.windows.net (Azure Storage), (2) Azure IP ranges: Check if IP in Microsoft's published Azure IP list (legitimate service if match), (3) Activity Logs: Search Azure Activity Logs for API calls involving that IP (e.g., blob upload logs), (4) NSG Flow Logs: Check Network Security Group logs for allowed/denied flows to that IP. Single-source validation insufficient: (a) Attacker could use compromised Azure service as C2, (b) Legitimate service might show suspicious patterns (excessive uploads), (c) IP could be recently changed (DNS lag). Multi-source correlation reveals: legitimate service + expected usage patterns = likely benign, legitimate service + anomalous patterns = investigate deeper, non-Azure IP + no Activity Logs = likely C2."
    },
    {
      "question_id": "dfir57_q4",
      "type": "multiple_choice",
      "difficulty": 3,
      "question": "In GCP Compute Engine investigation, you discover instance metadata endpoint (169.254.169.254) being accessed by unexpected process. What's the security significance?",
      "options": [
        "Normal behavior - all GCP instances access metadata",
        "Potential SSRF or instance profile credential theft",
        "Hypervisor-level attack attempting to escape VM",
        "Network misconfiguration causing DNS resolution to wrong IP"
      ],
      "correct_answer": 1,
      "explanation": "This indicates potential Server-Side Request Forgery (SSRF) or credential theft. 169.254.169.254 is cloud metadata service providing: (1) Instance metadata (hostname, tags, project info), (2) **Service account access tokens** (credentials for GCP API access), (3) User-data scripts, SSH keys. Attack scenario: (1) Attacker exploits web app SSRF vulnerability, (2) Forces app to request http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token, (3) Receives service account OAuth token, (4) Uses token to access GCP resources (Storage, BigQuery, etc.). Detection in memory: Unexpected process (not cloud-init, not expected app) making HTTP requests to metadata endpoint. Legitimate apps access metadata during init, not continuously. Hypervisor escape wouldn't use metadata endpoint (different attack vector). DNS misconfiguration wouldn't consistently resolve to link-local address. Forensic action: Identify process, check what metadata was accessed (tokens = critical, hostname = less concerning), review GCP audit logs for API calls using that service account."
    },
    {
      "question_id": "dfir57_q5",
      "type": "multiple_choice",
      "difficulty": 3,
      "question": "You acquire memory from Kubernetes pod. Analysis shows multiple processes but pod's container image only includes single application binary. What's the most likely explanation?",
      "options": [
        "Kubernetes automatically injects sidecar containers for logging/monitoring",
        "Container escape - attacker compromised host and injected processes",
        "Memory acquisition captured multiple pods' memory (acquisition error)",
        "Container image was tampered with and includes hidden binaries"
      ],
      "correct_answer": 1,
      "explanation": "Most likely: container escape where attacker compromised host and injected processes into pod's namespace. Container escape attacks: (1) Exploit container runtime vulnerability (Docker/containerd/runC), (2) Break out of container isolation, (3) Gain host-level access, (4) Inject malicious processes into container namespaces (appears as processes in pod but actually host-level). Evidence to look for: (a) Processes with capabilities unusual for app (CAP_SYS_ADMIN, CAP_SYS_MODULE), (b) Processes accessing host filesystem (/var/run/docker.sock, /proc/1/root), (c) Processes with parent PID 1 or low PIDs (host PIDs leak into container). Sidecar containers would show in pod spec (kubectl describe pod shows multiple containers). Acquisition error would show mixed process trees from different pods. Tampered image would show in image history (docker history command) and processes would be child of container's init. Forensic priority: If container escape, entire Kubernetes node is compromised (not just pod), must analyze node memory and other pods on same node."
    }
  ],
  "jim_kwik_principles": [
    "active_learning",
    "minimum_effective_dose",
    "teach_like_im_10",
    "memory_hooks",
    "meta_learning",
    "connect_to_what_i_know",
    "reframe_limiting_beliefs",
    "gamify_it",
    "learning_sprint",
    "multiple_memory_pathways"
  ],
  "content_blocks": [
    {
      "type": "mindset_coach",
      "content": {
        "text": "# Welcome to Cloud Memory Forensics: The New Frontier\n\n## Why Cloud Forensics Is Different\n\nEverything you've learned about memory forensics applies... with a twist.\n\n**Traditional forensics**:\n- Physical access to hardware\n- Full control over acquisition\n- Direct memory access\n- No legal/contractual barriers\n\n**Cloud forensics**:\n- Virtual instances (no physical access)\n- Provider controls infrastructure\n- Memory access through hypervisor/APIs\n- Shared responsibility model\n- Multi-tenancy concerns\n- Data sovereignty issues\n\n**But the fundamentals remain**: Processes, network connections, malware indicatorsâ€”all still in memory. You just need new acquisition techniques.\n\n## Real-World Cloud Breaches\n\n**Capital One Breach (2019)**:\n- **Target**: AWS S3 buckets\n- **Method**: SSRF + metadata endpoint exploitation\n- **Impact**: 100 million customer records\n- **Memory forensics value**: Would have shown suspicious requests to 169.254.169.254 (metadata endpoint)\n\n**Cryptojacking Epidemic (2018-2023)**:\n- **Target**: AWS/Azure/GCP compute instances\n- **Method**: Exposed Kubernetes dashboards, stolen credentials\n- **Impact**: $billions in stolen compute resources\n- **Memory forensics value**: Detected mining processes (xmrig, cpuminer) in memory\n\n**SolarWinds (2020)**:\n- **Target**: Microsoft Office 365 (cloud services)\n- **Method**: Compromised on-prem â†’ cloud lateral movement\n- **Impact**: 18,000+ organizations\n- **Memory forensics value**: Hybrid forensics (on-prem memory + cloud logs) revealed full attack chain\n\n## What You'll Master Today\n\n1. **Cloud Architecture**: How AWS EC2, Azure VMs, GCP instances differ from bare metal\n2. **Memory Acquisition**: Snapshot-based and live acquisition in cloud\n3. **Container Forensics**: Analyzing Docker/Kubernetes memory\n4. **Cloud-Native Threats**: Metadata exploitation, privilege escalation, container escape\n5. **Correlation**: Memory + CloudTrail/Activity Logs/Audit Logs for complete picture\n\n## Your \"Why\" for Learning This\n\n**Stat**: 94% of enterprises use cloud services (Flexera 2023 State of Cloud Report)\n\n**Reality**: If you can't do cloud forensics, you can't investigate 94% of modern breaches.\n\n**Job market**: Cloud forensics skills command $140K-$200K salaries (limited talent pool, high demand)\n\n**This lesson**: Positions you in that high-value niche.\n\nLet's conquer cloud memory forensics. â˜ï¸ğŸ”"
      }
    },
    {
      "type": "video",
      "content": {
        "text": "**Video: Memory Forensics with Volatility - 13Cubed**\\n\\n**Duration**: 25:15\\n\\nThis video provides a visual demonstration of the concepts covered in this lesson. Watch to see practical examples and deepen your understanding of Cloud Memory Forensics: AWS, Azure, and GCP.\\n\\n**Video Link**: [Memory Forensics with Volatility - 13Cubed](https://www.youtube.com/watch?v=BMFCdAGxVN4)\\n\\n**Embedded Video**:\\n\\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/BMFCdAGxVN4\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\\n\\n**Learning Tips**:\\n- Watch the video first to get an overview\\n- Pause and take notes on key concepts\\n- Replay sections that cover complex topics\\n- Try to practice along with the video demonstrations\\n- Return to the video as needed while working through exercises",
        "url": "https://www.youtube.com/watch?v=BMFCdAGxVN4",
        "title": "Memory Forensics with Volatility - 13Cubed",
        "duration": "25:15"
      }
    },
    {
      "type": "explanation",
      "content": {
        "text": "# Cloud Memory Forensics Fundamentals\n\n## Key Differences: Cloud vs. On-Premises\n\n### 1. No Physical Access\n\n**On-prem**: Pull server, connect to RAM, image with hardware tool\n\n**Cloud**: No physical access. Must use:\n- Cloud provider APIs\n- Hypervisor-based snapshots\n- Agent-based acquisition (SSH + LiME, Volatility)\n\n### 2. Shared Responsibility Model\n\n**AWS Shared Responsibility**:\n\n```\nAWS Responsibility (Security OF the Cloud):\n- Physical security\n- Hypervisor\n- Network infrastructure\n- Hardware\n\nCustomer Responsibility (Security IN the Cloud):\n- OS configuration\n- Application security\n- Data encryption\n- Memory forensics â† Your job!\n```\n\n**Implication**: AWS won't acquire memory for you. You must do it yourself (or use third-party tools).\n\n### 3. Volatile Nature (More Volatile)\n\n**Auto-scaling**: Instances can terminate automatically\n\n**Spot instances**: Can be reclaimed by provider with 2-minute notice\n\n**Containers**: Even more ephemeral (seconds to minutes lifespan)\n\n**Lesson**: Acquire memory FAST or lose evidence forever.\n\n### 4. Legal Considerations\n\n**Data sovereignty**: EU data might be in Ireland (GDPR applies)\n\n**Multi-tenancy**: Your forensic actions must not impact other tenants\n\n**Provider cooperation**: May need legal process to get provider's assistance\n\n---\n\n## AWS EC2 Memory Forensics\n\n### Architecture Overview\n\n**EC2 Stack**:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Your Application                â”‚  â† User space\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Guest OS (Linux/Windows)        â”‚  â† You control (memory accessible)\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Xen/Nitro Hypervisor            â”‚  â† AWS controls (memory NOT accessible)\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Physical Hardware               â”‚  â† AWS controls\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Forensic access level**: Guest OS memory only (can't access hypervisor)\n\n### Method 1: EBS Snapshot + Analysis\n\n**Best for**: Stealth, preserving running instance\n\n**Steps**:\n\n```bash\n# 1. Create snapshot of EBS volume (root + data volumes)\naws ec2 create-snapshot \\\n  --volume-id vol-0abcd1234efgh5678 \\\n  --description \"Forensic snapshot - $(date)\"\n\n# Output: snapshot-0xyz9876fedcba543\n\n# 2. Wait for snapshot completion\naws ec2 wait snapshot-completed --snapshot-ids snapshot-0xyz9876fedcba543\n\n# 3. Create volume from snapshot (in forensic account/region)\naws ec2 create-volume \\\n  --snapshot-id snapshot-0xyz9876fedcba543 \\\n  --availability-zone us-east-1a\n\n# Output: vol-forensic123\n\n# 4. Launch forensic instance\naws ec2 run-instances \\\n  --image-id ami-0abcd1234  \\  # SIFT workstation or similar\n  --instance-type t3.medium \\\n  --key-name forensic-key\n\n# Output: i-forensic456\n\n# 5. Attach forensic volume to forensic instance\naws ec2 attach-volume \\\n  --volume-id vol-forensic123 \\\n  --instance-id i-forensic456 \\\n  --device /dev/sdf\n\n# 6. Mount and analyze\nssh -i forensic-key.pem ec2-user@<forensic-instance-ip>\nsudo mkdir /mnt/evidence\nsudo mount -o ro /dev/xvdf1 /mnt/evidence  # Read-only!\n\n# 7. Acquire memory (if pagefile/hiberfil.sys present)\nvolatility -f /mnt/evidence/pagefile.sys --profile=Win10x64 pslist\n\n# OR if Linux, check swap\nvolatility -f /mnt/evidence/swapfile --profile=LinuxUbuntu2004x64 linux_pslist\n```\n\n**Limitations**:\n- Only gets page file/swap (not full RAM)\n- Running memory lost\n- Best for disk forensics with opportunistic memory recovery\n\n---\n\n### Method 2: Live Memory Acquisition (LiME)\n\n**Best for**: Live memory acquisition from running instance\n\n**Prerequisites**: SSH access, root/sudo privileges\n\n**Steps**:\n\n```bash\n# On forensic workstation: Prepare LiME\ngit clone https://github.com/504ensicsLabs/LiME\ncd LiME/src\nmake  # Compile kernel module\n\n# Transfer to target instance\nscp lime.ko ec2-user@<target-instance-ip>:~/\n\n# On target instance: Acquire memory\nssh ec2-user@<target-instance-ip>\nsudo insmod lime.ko \"path=/tmp/memory.lime format=lime\"\n\n# Download memory image\nscp ec2-user@<target-instance-ip>:/tmp/memory.lime ./evidence/\n\n# Analyze with Volatility\nvolatility -f memory.lime --profile=LinuxAmazonLinux2x64 linux_pslist\n```\n\n**Advantages**:\n- Full RAM acquisition\n- Running processes, network connections\n\n**Disadvantages**:\n- Modifies system (loads kernel module)\n- Attacker might detect (new SSH connection, kernel module load)\n- Requires SSH access (might not be possible if compromised)\n\n---\n\n### Method 3: AWS Systems Manager (Remote Execution)\n\n**Best for**: Agentless remote acquisition\n\n**Requirements**: Systems Manager agent installed (default on Amazon Linux)\n\n**Steps**:\n\n```bash\n# 1. Upload LiME to S3\naws s3 cp lime.ko s3://forensic-bucket/tools/\n\n# 2. Execute remote acquisition via Systems Manager\naws ssm send-command \\\n  --instance-ids i-suspect123 \\\n  --document-name \"AWS-RunShellScript\" \\\n  --parameters 'commands=[\n    \"wget https://forensic-bucket.s3.amazonaws.com/tools/lime.ko\",\n    \"sudo insmod lime.ko path=/tmp/memory.lime format=lime\",\n    \"aws s3 cp /tmp/memory.lime s3://forensic-bucket/evidence/\"\n  ]'\n\n# 3. Monitor command execution\naws ssm list-command-invocations --command-id <command-id>\n\n# 4. Download evidence from S3\naws s3 cp s3://forensic-bucket/evidence/memory.lime ./\n```\n\n**Advantages**:\n- No SSH required\n- Centralized execution logs\n\n**Disadvantages**:\n- Attacker might monitor CloudTrail logs (see Systems Manager activity)\n- Still modifies system\n\n---\n\n### Method 4: EC2 Memory Forensics via AVML (Azure but works on AWS)\n\n**AVML** (Acquire Volatile Memory for Linux): Microsoft's open-source memory acquisition tool\n\n**Advantages**: Single binary, no kernel module compilation\n\n```bash\n# On target instance\nwget https://github.com/microsoft/avml/releases/download/v0.9.0/avml\nchmod +x avml\nsudo ./avml memory.lime\n\n# Compressed acquisition\nsudo ./avml --compress memory.lime.gz\n```\n\n---\n\n## Azure VM Memory Forensics\n\n### Architecture\n\n**Azure VM Stack**:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Your Application                â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Guest OS (Windows/Linux)        â”‚  â† Memory accessible\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Hyper-V Hypervisor              â”‚  â† Microsoft controls\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Physical Hardware               â”‚  â† Microsoft controls\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Method 1: Managed Disk Snapshot\n\n```bash\n# Azure CLI\n# 1. Create snapshot\naz snapshot create \\\n  --resource-group forensics-rg \\\n  --name suspect-vm-snapshot \\\n  --source /subscriptions/<sub-id>/resourceGroups/prod-rg/providers/Microsoft.Compute/disks/suspect-vm-os-disk\n\n# 2. Create disk from snapshot\naz disk create \\\n  --resource-group forensics-rg \\\n  --name forensic-disk \\\n  --source suspect-vm-snapshot\n\n# 3. Attach to forensic VM\naz vm disk attach \\\n  --resource-group forensics-rg \\\n  --vm-name forensic-vm \\\n  --name forensic-disk\n\n# 4. Mount and analyze\nsudo mount -o ro /dev/sdc1 /mnt/evidence\n```\n\n### Method 2: Azure VM Run Command\n\n```bash\n# Remote AVML execution\naz vm run-command invoke \\\n  --resource-group prod-rg \\\n  --name suspect-vm \\\n  --command-id RunShellScript \\\n  --scripts \"wget https://forensic-storage.blob.core.windows.net/tools/avml && chmod +x avml && sudo ./avml /tmp/memory.lime && az storage blob upload --account-name forensicstorage --container evidence --name memory.lime --file /tmp/memory.lime\"\n```\n\n---\n\n## GCP Compute Engine Forensics\n\n### Architecture\n\n**GCP Instance Stack**:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Your Application                â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Guest OS (Linux/Windows)        â”‚  â† Memory accessible\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  KVM Hypervisor                  â”‚  â† Google controls\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Physical Hardware               â”‚  â† Google controls\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Method 1: Persistent Disk Snapshot\n\n```bash\n# gcloud CLI\n# 1. Create snapshot\ngcloud compute disks snapshot suspect-instance-disk \\\n  --snapshot-names=forensic-snapshot-$(date +%Y%m%d-%H%M%S) \\\n  --zone=us-central1-a\n\n# 2. Create disk from snapshot\ngcloud compute disks create forensic-disk \\\n  --source-snapshot=forensic-snapshot-20250115-143000 \\\n  --zone=us-central1-a\n\n# 3. Attach to forensic instance\ngcloud compute instances attach-disk forensic-instance \\\n  --disk=forensic-disk \\\n  --zone=us-central1-a\n\n# 4. Mount and analyze\nsudo mount -o ro /dev/sdb1 /mnt/evidence\n```\n\n### Method 2: Live Acquisition via SSH\n\n```bash\n# Use AVML or LiME\ngcloud compute ssh suspect-instance --zone=us-central1-a\nsudo ./avml memory.lime\ngsutil cp memory.lime gs://forensic-bucket/evidence/\n```\n\n---\n\n## Container Memory Forensics\n\n### Docker Container Memory\n\n**Challenge**: Containers share host kernel. Traditional memory acquisition gets **host memory**, not just container.\n\n**Approach**: Acquire host memory, then filter for container processes.\n\n```bash\n# On Docker host\nsudo ./avml memory.lime\n\n# Analyze with Volatility\nvolatility -f memory.lime --profile=LinuxUbuntu2004x64 linux_pslist\n\n# Identify container processes\nvolatility -f memory.lime --profile=LinuxUbuntu2004x64 linux_pslist | grep docker\n\n# Common container process patterns:\n# - containerd-shim (container runtime shim)\n# - process names matching deployed containers\n# - PID namespace indicators\n```\n\n**Advanced**: Use container-specific memory extraction\n\n```bash\n# Get container ID\ndocker ps\n# CONTAINER ID: abc123def456\n\n# Inspect container's memory from host\nsudo cat /proc/<container-pid>/maps  # Memory mappings\nsudo gcore <container-pid>  # Core dump of container process\n\n# Analyze core dump\nvolatility -f core.<pid> --profile=LinuxUbuntu2004x64 linux_pslist\n```\n\n---\n\n### Kubernetes Pod Memory\n\n**Architecture**:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Pod (Logical grouping)             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚  â”‚Container 1  â”‚  â”‚Container 2  â”‚  â”‚  â† Application memory\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  containerd / Docker Runtime        â”‚  â† Container runtime\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Kubernetes Node (Linux Host)       â”‚  â† Host memory\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Approach**: Acquire node memory, correlate with Kubernetes metadata.\n\n```bash\n# 1. Identify pod's node\nkubectl get pod suspect-pod -o wide\n# NODE: gke-cluster-1-default-pool-abc123\n\n# 2. SSH to node\ngcloud compute ssh gke-cluster-1-default-pool-abc123\n\n# 3. Find container processes\nsudo docker ps  # If Docker runtime\nsudo crictl ps  # If containerd/CRI-O\n\n# 4. Acquire memory\nsudo ./avml memory.lime\n\n# 5. Extract pod information\nkubectl get pod suspect-pod -o json > pod_metadata.json\n\n# 6. Correlate: Match process PIDs in memory dump with container IDs\n```\n\n---\n\n## Cloud-Native Threat Detection\n\n### Threat 1: Metadata Endpoint Exploitation\n\n**All cloud providers** expose metadata endpoint:\n- AWS: `http://169.254.169.254/latest/meta-data/`\n- Azure: `http://169.254.169.254/metadata/instance`\n- GCP: `http://metadata.google.internal/computeMetadata/v1/`\n\n**Attack**: SSRF vulnerability forces app to request metadata endpoint, stealing credentials.\n\n**Memory forensics detection**:\n\n```bash\nvolatility -f memory.lime --profile=LinuxAWS2x64 linux_pslist\n\n# Find suspicious processes\n# Check network connections\nvolatility -f memory.lime --profile=LinuxAWS2x64 linux_netstat\n\n# Look for connections to 169.254.169.254\n# Example output:\nTCP 10.0.1.50:45678 -> 169.254.169.254:80 (curl process)\n\n# Investigate: Is curl normal for this application?\n# Check command line:\nvolatility -f memory.lime --profile=LinuxAWS2x64 linux_psaux | grep curl\n\n# Example:\ncurl http://169.254.169.254/latest/meta-data/iam/security-credentials/MyRole\n\n# â† Credential theft attempt!\n```\n\n**Correlation with CloudTrail**:\n\n```bash\n# Check if stolen credentials were used\naws cloudtrail lookup-events \\\n  --lookup-attributes AttributeKey=AccessKeyId,AttributeValue=<stolen-key> \\\n  --start-time 2025-01-15T14:00:00 \\\n  --end-time 2025-01-15T16:00:00\n\n# Look for unusual API calls (S3 GetObject, DynamoDB Scan, etc.)\n```\n\n---\n\n### Threat 2: Container Escape\n\n**Attack**: Exploit container runtime vulnerability, break out to host.\n\n**Memory forensics detection**:\n\n```bash\n# Acquire node memory\nsudo ./avml node_memory.lime\n\n# Analyze for container escape indicators\nvolatility -f node_memory.lime --profile=LinuxK8sNode linux_pslist\n\n# Look for:\n# 1. Processes with suspicious capabilities\n#    CAP_SYS_ADMIN, CAP_SYS_MODULE, CAP_SYS_PTRACE\n\n# 2. Processes accessing host filesystem from container\nvolatility -f node_memory.lime --profile=LinuxK8sNode linux_mount\n# Look for /proc/1/root mounts (host root from container)\n\n# 3. Processes with host PID namespace\n# Container PIDs should be high (>1000)\n# Host PIDs include low numbers (1, 2, 3...)\n# If container process has PID 5 â†’ likely escaped\n```\n\n**Kubernetes context**:\n\n```bash\n# Check pod security context\nkubectl get pod suspect-pod -o json | jq '.spec.securityContext'\n\n# Red flags:\nprivileged: true  # Disables security boundaries\nhostPID: true     # Shares host PID namespace\nhostNetwork: true # Shares host network\n```\n\n---\n\n### Threat 3: Cryptojacking\n\n**Attack**: Unauthorized cryptocurrency mining using cloud compute.\n\n**Memory forensics detection**:\n\n```bash\n# Analyze for mining processes\nvolatility -f memory.lime --profile=LinuxAWS2x64 linux_pslist | grep -E \"xmrig|cpuminer|minerd|ethminer\"\n\n# Check network connections to mining pools\nvolatility -f memory.lime --profile=LinuxAWS2x64 linux_netstat | grep -E \"3333|4444|5555|9999\"\n# Common mining pool ports\n\n# Check CPU usage (if available in memory artifacts)\nvolatility -f memory.lime --profile=LinuxAWS2x64 linux_psaux\n# Look for processes with 100% CPU usage\n```\n\n**Correlation with CloudWatch** (AWS):\n\n```bash\n# Check historical CPU usage\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/EC2 \\\n  --metric-name CPUUtilization \\\n  --dimensions Name=InstanceId,Value=i-suspect123 \\\n  --start-time 2025-01-15T00:00:00Z \\\n  --end-time 2025-01-15T23:59:59Z \\\n  --period 3600 \\\n  --statistics Maximum\n\n# Spike to 100% CPU = likely cryptojacking\n```"
      }
    },
    {
      "type": "code_exercise",
      "content": {
        "text": "**Hands-On Exercise**\\n\\nLet's practice the forensic workflow with real commands:\\n\\n**Step 1: Acquire the Artifact**\\n```cmd\\n# Copy artifact from evidence drive\\nrobocopy E:\\\\Evidence\\\\C\\\\Windows\\\\System32 C:\\\\Analysis\\\\ [artifact] /B\\n```\\n\\n**Step 2: Parse with Forensic Tools**\\n```cmd\\n# Use Eric Zimmerman tools or equivalent\\n[ToolName].exe -f C:\\\\Analysis\\\\[artifact] --csv C:\\\\Output\\\\\\n```\\n\\n**Step 3: Analyze Results**\\nOpen the CSV output and look for:\\n- Timestamps that align with incident timeframe\\n- Suspicious file paths or executables\\n- User accounts associated with malicious activity\\n- Network indicators or data transfer evidence\\n\\n**Step 4: Document Findings**\\nRecord all relevant artifacts in your investigation timeline."
      }
    },
    {
      "type": "real_world",
      "content": {
        "text": "**Real-World Investigation Scenario**\\n\\n**Background:** A financial services company detected suspicious network activity. You've been called in to perform digital forensics on a compromised workstation.\\n\\n**Initial Evidence:**\\n- Network monitoring detected 8.5 GB data transfer to external IP\\n- User reported system slowdown 3 days ago\\n- Antivirus quarantined 2 files yesterday\\n\\n**Your Forensic Approach:**\\n\\n1. **Timeline Development**\\n   - Collect all execution artifacts (Prefetch, AmCache, ShimCache, SRUM, UserAssist)\\n   - Create master timeline spanning 7-14 days before incident\\n   - Identify initial compromise vector\\n\\n2. **Artifact Analysis**\\n   - Examine this artifact for evidence of malicious executables\\n   - Cross-reference timestamps with network logs\\n   - Identify persistence mechanisms\\n\\n3. **Data Exfiltration Analysis**\\n   - Review SRUM for bandwidth usage by application\\n   - Check browser history and cloud sync logs\\n   - Analyze LNK files for accessed documents\\n\\n4. **Lateral Movement Detection**\\n   - Search for remote access tools (PsExec, RDP, WMI)\\n   - Review Windows Event Logs (4624, 4672, 4688)\\n   - Check for credential theft tools (Mimikatz indicators)\\n\\n**Key Findings:**\\nThis artifact revealed that `data_sync.exe` (disguised malware) executed 47 times over 3 days, correlating perfectly with the 8.5 GB data transfer detected by network monitoring. The attacker used a legitimate-looking filename to evade detection. By correlating this artifact with SRUM network data and MFT file access records, you can reconstruct exactly which files were exfiltrated and when.\\n\\n**Lessons Learned:**\\n- Multiple artifacts provide corroborating evidence\\n- Attackers often use legitimate-sounding filenames\\n- Timeline correlation is critical for proving causation\\n- Network logs + endpoint forensics = comprehensive investigation"
      }
    },
    {
      "type": "memory_aid",
      "content": {
        "text": "**Forensic Analysis Checklist**\\n\\nUse this mnemonic to remember key forensic steps:\\n\\n**T-R-A-C-E**\\n- **T**imeline: Build comprehensive timeline of events\\n- **R**ecovery: Extract and preserve artifacts\\n- **A**nalysis: Parse and interpret forensic data\\n- **C**orrelation: Cross-reference multiple artifacts\\n- **E**vidence: Document findings for legal proceedings\\n\\n**Quick Reference:**\\n- Artifact location: [Primary path]\\n- Parsing tool: [Recommended tool name]\\n- Key fields: Timestamp, User, Path, Execution count\\n- Correlate with: Prefetch, SRUM, AmCache, Event Logs\\n- Retention period: Varies by artifact (7-60 days typical)\\n\\n**Pro Tip:** Always collect artifacts from BOTH filesystem AND Volume Shadow Copies to catch evidence that attackers attempted to delete."
      }
    },
    {
      "type": "mindset_coach",
      "content": {
        "text": "**You're Building Forensic Expertise**\\n\\nDigital forensics can feel overwhelming with dozens of artifacts to master. Here's the mindset that successful DFIR analysts develop:\\n\\n**Master One Artifact at a Time**\\nYou don't need to memorize every field in every artifact. Focus on:\\n1. **What** the artifact proves (execution, file access, network activity)\\n2. **Where** it's located on the system\\n3. **How** to extract it with tools\\n4. **When** to use it in investigations\\n\\n**Build Mental Models**\\nThink of forensic artifacts as puzzle pieces. Each one tells part of the story:\\n- **Execution artifacts** (Prefetch, AmCache) = \"What ran?\"\\n- **File system artifacts** (MFT, USN Journal) = \"What files were created/accessed?\"\\n- **Network artifacts** (SRUM, Browser history) = \"Where did data go?\"\\n- **User artifacts** (LNK, UserAssist) = \"Who did what?\"\\n\\n**Practice Makes Permanent**\\nSet up a Windows VM and:\\n1. Run various applications\\n2. Extract the artifacts\\n3. Parse them with tools\\n4. See how your actions appear in forensic data\\n\\nThis hands-on practice builds intuition faster than reading alone.\\n\\n**You're Not Expected to Memorize Everything**\\nProfessional DFIR analysts use cheat sheets and reference guides. Your goal is to understand WHICH artifacts answer WHICH questions, then look up the specific syntax when needed.\\n\\n**Keep Going!** Every artifact you master makes you more valuable as an investigator. You're building skills that take years to developâ€”be patient with yourself and celebrate each new technique you learn."
      }
    },
    {
      "type": "reflection",
      "content": {
        "text": "**Reflect on Your Forensic Journey**\\n\\nTake a moment to consider:\\n\\n**Integration Questions:**\\n1. How does this artifact fit into your overall forensic workflow?\\n2. What other artifacts would provide corroborating evidence?\\n3. In what types of investigations would this be most valuable?\\n\\n**Critical Thinking:**\\n4. What are the limitations of this artifact? What can't it tell you?\\n5. How might an attacker attempt to evade or manipulate this evidence?\\n6. What additional data sources would you need to build a complete timeline?\\n\\n**Practical Application:**\\n7. If you had to explain this artifact to a non-technical manager, what would you say?\\n8. What specific commands or tools do you need to practice to feel confident?\\n9. What real-world case studies demonstrate the value of this artifact?\\n\\n**Next Steps:**\\n- Set up a lab environment to practice artifact extraction\\n- Download and install recommended forensic tools\\n- Work through practice scenarios with sample evidence\\n- Join DFIR communities (Reddit r/computerforensics, SANS forums)\\n- Read case studies from DFIR blogs (13Cubed, SANS DFIR Summit talks)\\n\\nRemember: Every expert was once a beginner. Your consistent practice is building professional-grade investigative skills."
      }
    }
  ],
  "tags": [
    "dfir",
    "cloud-forensics",
    "aws",
    "azure",
    "gcp",
    "container-forensics",
    "kubernetes",
    "memory-acquisition",
    "advanced"
  ]
}