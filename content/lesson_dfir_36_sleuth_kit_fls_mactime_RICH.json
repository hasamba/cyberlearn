{
  "lesson_id": "8b3f2d91-5e67-4a2c-9f1d-3c4e8a9b2d5f",
  "domain": "dfir",
  "title": "The Sleuth Kit: fls and mactime for MACB Timeline Creation",
  "difficulty": 2,
  "order_index": 36,
  "prerequisites": [
    "10f6b021-16ed-44e6-91fb-6487b594659f"
  ],
  "concepts": [
    "The Sleuth Kit (TSK) open-source forensic framework",
    "fls command for filesystem listing and MFT parsing",
    "mactime tool for MACB timeline generation",
    "Body file format (intermediate timeline representation)",
    "inode vs MFT entry number correlation",
    "Deleted file recovery with fls -r (recursive unallocated)",
    "Timeline filtering by date range and file type",
    "Super-timeline concept and multi-source integration",
    "TSK mmls, fsstat, and icat auxiliary tools"
  ],
  "estimated_time": 60,
  "learning_objectives": [
    "Understand The Sleuth Kit (TSK) architecture and command-line tools ecosystem",
    "Use fls to extract filesystem metadata and create body files from MFT",
    "Generate MACB timelines with mactime for comprehensive activity reconstruction",
    "Interpret body file format and customize timeline output formats",
    "Recover deleted files and orphaned MFT entries using fls -r flag",
    "Filter timelines by date range, file type, and activity patterns for focused analysis",
    "Integrate TSK timelines with other artifacts (Jump Lists, Prefetch, Event Logs)",
    "Apply TSK workflows to real-world incident response and forensic investigations"
  ],
  "post_assessment": [
    {
      "question_id": "tsk-001",
      "question": "What is the primary purpose of the 'body file' format in The Sleuth Kit workflow?",
      "options": [
        "It stores encrypted copies of file contents for secure analysis",
        "It serves as an intermediate format that separates data collection (fls) from timeline generation (mactime)",
        "It contains autopsy reports generated by forensic examiners",
        "It maps file signatures to MIME types for file identification"
      ],
      "correct_answer": 1,
      "explanation": "The body file is TSK's intermediate format that separates the data collection phase (fls extracts filesystem metadata) from the presentation phase (mactime generates human-readable timelines). This separation enables: (1) collecting body files from multiple sources (MFT, Registry, logs) and merging them into a single super-timeline, (2) generating timelines with different date ranges or formats without re-parsing the filesystem, and (3) portability - body files can be analyzed on different systems. The body file contains pipe-delimited fields: MD5|filename|inode|mode_as_string|UID|GID|size|atime|mtime|ctime|crtime.",
      "type": "multiple_choice",
      "difficulty": 2
    },
    {
      "question_id": "tsk-002",
      "question": "Which fls command correctly extracts a body file including deleted files from an NTFS filesystem image?",
      "options": [
        "fls -m C: -r suspect_disk.dd > bodyfile.txt",
        "fls -o 2048 -r -m C: suspect_disk.dd > bodyfile.txt",
        "fls --deleted --recursive --output bodyfile.txt suspect_disk.dd",
        "fls -i ntfs -d -r suspect_disk.dd > bodyfile.txt"
      ],
      "correct_answer": 1,
      "explanation": "The correct syntax is: fls -o 2048 -r -m C: suspect_disk.dd > bodyfile.txt. Breaking down the flags: -o 2048 specifies the partition offset in sectors (required for disk images with partition tables), -r enables recursive directory traversal including deleted entries, -m C: prepends 'C:' to all file paths for clarity in timeline output, and > bodyfile.txt redirects output to a file. The -r flag is critical because it includes deleted files and orphaned MFT entries (files that exist in MFT but are marked as unallocated). Option A lacks the offset flag (will fail on partitioned disks), Option C uses non-existent long-form flags, and Option D uses incorrect flag syntax.",
      "type": "multiple_choice",
      "difficulty": 2
    },
    {
      "question_id": "tsk-003",
      "question": "In a MACB timeline, you observe the following entry: 'Apr 15 2024 14:32:18,4096,macb,0,0,52341-128-1,C:/Users/suspect/Desktop/confidential.xlsx'. What does the 'macb' field indicate?",
      "options": [
        "The file was Modified, Accessed, Changed, and Born (created) all at the exact same timestamp",
        "This timestamp represents all four MACB events occurring (Modified=Apr 15 14:32, Accessed=Apr 15 14:32, Changed=Apr 15 14:32, Born=Apr 15 14:32)",
        "The file has metadata anomalies and should be flagged for timestomping investigation",
        "This is a directory entry, not a file (directories show 'macb' while files show specific letters)"
      ],
      "correct_answer": 0,
      "explanation": "The 'macb' field in a mactime timeline indicates that ALL FOUR timestamp types (Modified, Accessed, Changed, Born/Created) occurred at the exact same moment (Apr 15 2024 14:32:18). This is forensically significant because: (1) For new files created and immediately saved, macb alignment is normal (file created, written, metadata updated, all within same second), (2) For existing files, macb alignment is HIGHLY SUSPICIOUS and often indicates timestomping (attacker used tools to set all timestamps to same value to hide activity), (3) In this case, 'confidential.xlsx' on Desktop with perfectly aligned timestamps warrants investigation - was it legitimately created at 14:32, or did someone modify it later and timestamp it? The mactime format shows lowercase letters for which timestamps fired: 'm'=modified, 'a'=accessed, 'c'=changed, 'b'=born. When all four fire, you see 'macb'. If only modified fired, you'd see 'm...'.",
      "type": "multiple_choice",
      "difficulty": 2
    },
    {
      "question_id": "tsk-004",
      "question": "You're investigating a data exfiltration incident that occurred between May 10-14, 2024. Your body file contains 2.3 million entries spanning 3 years. Which mactime command filters the timeline to show only activity during the incident window?",
      "options": [
        "mactime -b bodyfile.txt -d -z UTC -y 2024-05-10..2024-05-14 > timeline_filtered.csv",
        "mactime -b bodyfile.txt -d -z UTC | grep '2024-05-1[0-4]' > timeline_filtered.csv",
        "mactime -b bodyfile.txt --start='2024-05-10' --end='2024-05-14' --format=csv > timeline_filtered.csv",
        "mactime -b bodyfile.txt -d '2024-05-10' -e '2024-05-14' -z UTC > timeline_filtered.csv"
      ],
      "correct_answer": 1,
      "explanation": "The correct approach is Option B: mactime -b bodyfile.txt -d -z UTC | grep '2024-05-1[0-4]' > timeline_filtered.csv. Here's why: mactime does NOT have built-in date range filtering flags (no -y, --start, --end, or -d/-e flags exist). Instead, you must: (1) generate the full timeline with mactime -b bodyfile.txt -d -z UTC (where -d outputs in human-readable format, -z UTC sets timezone), then (2) pipe to grep with regex pattern '2024-05-1[0-4]' to match May 10-14. The regex [0-4] matches any single digit 0-4, capturing May 10, 11, 12, 13, 14. For more precise filtering, you can use awk or write a post-processing script. Option A uses non-existent -y flag, Option C uses non-existent long flags, and Option D uses non-existent -d/-e flags. TSK's philosophy: simple tools that do one thing well, composed via Unix pipes.",
      "type": "multiple_choice",
      "difficulty": 2
    },
    {
      "question_id": "tsk-005",
      "question": "During filesystem analysis with fls, you encounter an MFT entry labeled '52341-128-1'. What does the '128' component represent, and why is it forensically significant?",
      "options": [
        "File size in kilobytes (128 KB)",
        "The $DATA attribute type number in NTFS, indicating this is the primary file content stream",
        "User ID (UID 128) of the file owner for attribution",
        "Sector offset where the file begins on disk"
      ],
      "correct_answer": 1,
      "explanation": "The '128' in MFT entry notation '52341-128-1' represents the $DATA attribute type number in NTFS. NTFS stores file metadata in attributes within MFT entries, and each attribute type has a numeric identifier: $STANDARD_INFORMATION=16, $FILE_NAME=48, $DATA=128, $INDEX_ROOT=144, etc. The format is: MFT_Entry_Number-Attribute_Type-Attribute_ID. So '52341-128-1' means: MFT entry 52341, $DATA attribute (128), attribute ID 1 (primary data stream). Forensic significance: (1) NTFS supports Alternate Data Streams (ADS), so a file might have multiple $DATA attributes (52341-128-1, 52341-128-2, etc.), (2) Attribute type 128 confirms this is actual file content (not metadata), (3) Deleted files often have orphaned $DATA attributes that fls can recover. Understanding MFT entry notation is critical for correlating TSK output with tools like MFTECmd.exe, which use similar entry numbering.",
      "type": "multiple_choice",
      "difficulty": 3
    }
  ],
  "jim_kwik_principles": [
    "active_learning",
    "minimum_effective_dose",
    "teach_like_im_10",
    "memory_hooks",
    "meta_learning",
    "connect_to_what_i_know",
    "gamify_it",
    "multiple_memory_pathways",
    "reframe_limiting_beliefs",
    "learning_sprint"
  ],
  "content_blocks": [
    {
      "type": "mindset_coach",
      "content": {
        "text": "## Welcome to The Sleuth Kit: Open-Source Forensic Power at Your Fingertips\n\n**You've mastered application-specific artifacts (Jump Lists, LNK files, Prefetch). Now let's scale up to SYSTEM-WIDE timeline reconstruction!**\n\nImagine you're investigating a data breach. You need to answer:\n- **When did the attacker first gain access?** (Initial compromise timestamp)\n- **What files did they access, modify, or delete?** (File activity timeline)\n- **What tools did they drop on the system?** (Malware placement timeline)\n- **When did exfiltration occur?** (Data theft window)\n\n**Jump Lists tell you about specific applications. Prefetch tells you about executables. But what about EVERYTHING ELSE?**\n\nThat's where **The Sleuth Kit (TSK)** comes in. TSK parses the entire Master File Table (MFT) and generates a comprehensive timeline of EVERY file and directory on the system - created, modified, accessed, changed - all in one unified view.\n\n**Real-world scale**: A typical Windows 10 system has 200,000-500,000 files. An enterprise workstation might have 1+ million files. Manually analyzing this is impossible. TSK automates MFT parsing and timeline generation at scale, turning millions of filesystem events into actionable intelligence.\n\n**Why TSK matters**:\n1. **Open-source and cross-platform**: Works on Windows, Linux, macOS forensic workstations\n2. **Battle-tested**: Used in major investigations for 20+ years (created by Brian Carrier in 2001)\n3. **Vendor-neutral**: Works with any filesystem image (NTFS, FAT, EXT4, HFS+, APFS)\n4. **Foundation for Autopsy**: TSK is the engine behind Autopsy, the popular GUI forensic tool\n5. **Command-line power**: Scriptable, automatable, integrates with SIEM and SOAR platforms\n\n**Real-world impact**: TSK has been used in:\n- **Target data breach (2013)**: Timeline reconstruction of POS malware deployment\n- **Sony Pictures hack (2014)**: File deletion timeline analysis\n- **Colonial Pipeline ransomware (2021)**: Lateral movement timeline\n- **Countless insider threat cases**: File access and exfiltration timelines\n\n**In this lesson, you'll learn**:\n1. TSK architecture (fls, mactime, icat, mmls, fsstat)\n2. fls command for MFT parsing and body file generation\n3. Body file format (intermediate timeline representation)\n4. mactime tool for MACB timeline creation\n5. Deleted file recovery with fls -r flag\n6. Timeline filtering and analysis techniques\n7. Integration with other artifacts (Jump Lists, Prefetch, Event Logs)\n8. Real-world case study: Ransomware timeline reconstruction\n\n**By the end of this lesson**, you'll be able to:\n- Parse MFT from disk images and generate body files with fls\n- Create human-readable MACB timelines with mactime\n- Filter timelines by date range, file type, and activity patterns\n- Recover deleted files and orphaned MFT entries\n- Correlate filesystem timelines with application-specific artifacts\n- Conduct comprehensive incident timeline reconstruction at enterprise scale\n\n**Estimated time**: 60 minutes of hands-on, command-line focused learning.\n\n**Important**: TSK is command-line only (no GUI). If you prefer graphical interfaces, Autopsy uses TSK under the hood. But mastering the CLI gives you:\n- **Speed**: CLI is 10-100x faster than GUI for bulk operations\n- **Automation**: Write scripts for repeatable workflows\n- **Remote analysis**: SSH into forensic workstations and analyze remotely\n- **Understanding**: Know what Autopsy is doing behind the scenes\n\n**You've got the forensic mindset. Let's add enterprise-scale timeline reconstruction to your toolkit!** üîçüíª‚ú®"
      }
    },
    {
      "type": "video",
      "content": {
        "text": "**Video: Timeline Analysis for DFIR - SANS DFIR Summit**\\n\\n**Duration**: 45:30\\n\\nThis video provides a visual demonstration of the concepts covered in this lesson. Watch to see practical examples and deepen your understanding of The Sleuth Kit: fls and mactime for MACB Timeline Creation.\\n\\n**Video Link**: [Timeline Analysis for DFIR - SANS DFIR Summit](https://www.youtube.com/watch?v=KzD0MmEYAzQ)\\n\\n**Embedded Video**:\\n\\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KzD0MmEYAzQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\\n\\n**Learning Tips**:\\n- Watch the video first to get an overview\\n- Pause and take notes on key concepts\\n- Replay sections that cover complex topics\\n- Try to practice along with the video demonstrations\\n- Return to the video as needed while working through exercises",
        "url": "https://www.youtube.com/watch?v=KzD0MmEYAzQ",
        "title": "Timeline Analysis for DFIR - SANS DFIR Summit",
        "duration": "45:30"
      }
    },
    {
      "type": "explanation",
      "content": {
        "text": "# The Sleuth Kit (TSK): Deep Technical Analysis\n\n## What is The Sleuth Kit?\n\n**The Sleuth Kit (TSK)** is an open-source digital forensics framework created by Brian Carrier in 2001. It provides command-line tools for analyzing disk images, filesystems, and volumes at a low level.\n\n**Core philosophy**: Unix-style tools that do one thing well and can be combined via pipes for complex workflows.\n\n### TSK Tool Suite\n\nTSK consists of 20+ command-line tools organized by function:\n\n#### Filesystem Layer Tools\n\n**fls** - List files and directories (like `ls` but for forensic images)\n- Parses MFT entries and extracts metadata\n- Supports recursive listing including deleted files\n- Generates body files for timeline analysis\n\n**icat** - Extract file contents by inode/MFT entry number\n- Recover deleted files\n- Extract files without mounting filesystem\n\n**ifind** - Find files by name, inode, or metadata\n- Useful for hunting specific files across large images\n\n**ffind** - Find the name of a file given its inode/MFT entry\n- Reverse lookup: inode ‚Üí filename\n\n**istat** - Display detailed inode/MFT entry information\n- Shows all attributes, timestamps, data runs\n\n#### Volume Layer Tools\n\n**mmls** - List partition layout\n- Identifies partition offsets (critical for fls -o flag)\n\n**mmstat** - Display volume system details\n- Shows partition table type (MBR, GPT)\n\n**mmcat** - Extract partition contents\n\n#### Disk Image Tools\n\n**img_stat** - Display image file details\n- Shows image type (raw, E01, AFF)\n\n**img_cat** - Extract raw disk sectors\n\n#### Filesystem Details Tools\n\n**fsstat** - Display filesystem details\n- Shows filesystem type, block size, MFT location, volume serial\n\n**blkcat** - Extract filesystem blocks\n- Useful for data carving\n\n**blkls** - List unallocated blocks\n- Identify free space for carving\n\n**blkstat** - Display block allocation status\n\n#### Timeline Tools\n\n**fls** (with -m flag) - Generate body files\n**mactime** - Convert body files to MACB timelines\n\n### TSK Architecture\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ         Digital Forensic Investigator          ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                 ‚îÇ\n                 ‚îÇ Commands (fls, icat, mactime)\n                 ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ           The Sleuth Kit (TSK)                  ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ\n‚îÇ  ‚îÇ   fls    ‚îÇ  ‚îÇ  mactime ‚îÇ  ‚îÇ   icat   ‚îÇ     ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ\n‚îÇ  ‚îÇ   mmls   ‚îÇ  ‚îÇ  fsstat  ‚îÇ  ‚îÇ  ifind   ‚îÇ     ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ\n                  ‚îÇ Filesystem API\n                  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ         Filesystem Parsers                      ‚îÇ\n‚îÇ  NTFS ‚îÇ FAT32 ‚îÇ EXT4 ‚îÇ HFS+ ‚îÇ APFS ‚îÇ ISO9660   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                  ‚îÇ\n                  ‚îÇ Raw Data Access\n                  ‚ñº\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ         Disk Image Formats                      ‚îÇ\n‚îÇ  Raw (.dd/.img) ‚îÇ E01 (EnCase) ‚îÇ AFF ‚îÇ VMDK    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**Key design principle**: TSK accesses disk images at the raw block level, parsing filesystem structures directly without mounting. This is forensically sound (read-only, no writes to evidence).\n\n---\n\n## fls: Filesystem Listing Tool\n\n**fls** (File Listing) is TSK's primary tool for extracting filesystem metadata. It parses MFT entries (NTFS) or inode tables (EXT4) and outputs file/directory listings with timestamps.\n\n### Basic Syntax\n\n```bash\nfls [options] image_file [inode]\n```\n\n**Common options**:\n- `-r` : Recursive (include deleted files and orphaned entries)\n- `-o offset` : Partition offset in sectors (required for partitioned disks)\n- `-m mountpoint` : Prepend mountpoint to paths (e.g., 'C:' for Windows)\n- `-l` : Long listing (show inode, name)\n- `-p` : Display full path\n- `-d` : Display deleted entries only\n- `-F` : Display file system objects (show $MFT, $STANDARD_INFORMATION, etc.)\n\n### Understanding Partition Offsets\n\nWhen working with disk images that contain partition tables, you must specify the partition offset:\n\n```bash\n# Step 1: Identify partition layout\nmmls suspect_disk.dd\n\n# Output:\nDOS Partition Table\nOffset Sector: 0\nUnits are in 512-byte sectors\n\n      Slot      Start        End          Length       Description\n000:  Meta      0000000000   0000000000   0000000001   Primary Table (#0)\n001:  -------   0000000000   0000002047   0000002048   Unallocated\n002:  000:000   0000002048   0976771071   0976769024   NTFS / exFAT (0x07)\n003:  -------   0976771072   0976773119   0000002048   Unallocated\n\n# Partition starts at sector 2048\n# This is the offset to use with fls\n\n# Step 2: Use fls with offset\nfls -o 2048 -r -m C: suspect_disk.dd\n```\n\n**Why offsets matter**: Without the correct offset, fls will fail with \"Cannot determine filesystem type\" because it's reading the partition table instead of the actual NTFS boot sector.\n\n**Tip**: 2048 sectors is the default offset for modern Windows installations (offset = 2048 √ó 512 bytes/sector = 1,048,576 bytes = 1 MB).\n\n### Basic File Listing\n\n```bash\n# List root directory\nfls -o 2048 suspect_disk.dd\n\n# Output:\nr/r 4-128-1:    $AttrDef\nr/r 8-128-1:    $BadClus\nd/d 11-144-4:   $Extend\nr/r 9-128-8:    $Secure\nr/r 10-128-1:   $UpCase\nd/d 5-144-5:    Windows\nd/d 27-144-1:   Program Files\nd/d 28-144-1:   Program Files (x86)\nd/d 29-144-1:   Users\nd/d 30-144-1:   ProgramData\n```\n\n**Output format**: `type/type inode: filename`\n- **type**: `r` (regular file), `d` (directory), `v` (virtual), `l` (symbolic link)\n- **inode**: MFT entry notation (e.g., `5-144-5` = MFT 5, attribute 144, ID 5)\n- **filename**: File or directory name\n\n### Recursive Listing with Deleted Files\n\n```bash\n# List all files recursively, including deleted\nfls -o 2048 -r -p suspect_disk.dd | head -n 20\n\n# Output:\nr/r 4-128-1:    $AttrDef\nr/r 8-128-1:    $BadClus\nd/d 5-144-5:    Windows\nr/r 523-128-1:  Windows/System32/notepad.exe\nr/r * 8234-128-1:   Windows/System32/malware.exe (deleted)\nd/d 29-144-1:   Users\nd/d 52-144-1:   Users/jsmith\nd/d 341-144-1:  Users/jsmith/Desktop\nr/r 5234-128-1: Users/jsmith/Desktop/confidential.xlsx\nr/r * 5235-128-1:   Users/jsmith/Desktop/data_to_exfiltrate.zip (deleted)\n```\n\n**Note the asterisk (*)**: `r/r * 8234-128-1` indicates a **deleted file**. The `-r` flag recovers these entries from unallocated MFT space.\n\n### Generating Body Files\n\nBody files are TSK's intermediate format for timeline data:\n\n```bash\n# Generate body file\nfls -o 2048 -r -m C: suspect_disk.dd > bodyfile.txt\n\n# Body file format (pipe-delimited):\n# MD5|filename|inode|mode_as_string|UID|GID|size|atime|mtime|ctime|crtime\n\n# Example line:\n0|C:/Users/jsmith/Desktop/confidential.xlsx|5234-128-1|-rw-rw-rw-|0|0|245760|1715692800|1715692800|1715692800|1715606400\n```\n\n**Body file fields**:\n1. **MD5**: Hash (usually 0, not computed by fls)\n2. **Filename**: Full path with mountpoint prepended\n3. **Inode**: MFT entry number in TSK format\n4. **Mode**: Unix-style permissions (always `-rw-rw-rw-` for Windows)\n5. **UID**: User ID (0 for Windows)\n6. **GID**: Group ID (0 for Windows)\n7. **Size**: File size in bytes\n8. **atime**: Last Access Time (Unix epoch seconds)\n9. **mtime**: Last Modification Time (Unix epoch seconds)\n10. **ctime**: Last Change Time (MFT change time in NTFS)\n11. **crtime**: Creation Time (Birth time)\n\n**Unix epoch**: Seconds since January 1, 1970 00:00:00 UTC\n\n**Example timestamp conversion**:\n```python\nimport datetime\n\nepoch_time = 1715692800\ndt = datetime.datetime.fromtimestamp(epoch_time, tz=datetime.timezone.utc)\nprint(dt)  # Output: 2024-05-14 16:00:00+00:00\n```\n\n---\n\n## mactime: MACB Timeline Generator\n\n**mactime** converts body files into human-readable MACB timelines. MACB stands for:\n- **M**odified: File content changed\n- **A**ccessed: File was opened/read\n- **C**hanged: File metadata changed (NTFS: MFT $STANDARD_INFORMATION updated)\n- **B**orn: File created\n\n### Basic Syntax\n\n```bash\nmactime -b bodyfile.txt [options]\n```\n\n**Common options**:\n- `-b bodyfile` : Input body file\n- `-d` : Human-readable date format (default is Unix epoch)\n- `-z TIMEZONE` : Specify timezone (e.g., 'UTC', 'EST5EDT', 'PST8PDT')\n- `-y` : Display year (default omits year)\n- `-g GROUP` : Group entries by hour/day\n\n### Generating a Basic Timeline\n\n```bash\nmactime -b bodyfile.txt -d -z UTC > timeline.csv\n\n# Timeline format:\nDate,Size,Type,Mode,UID,GID,Meta,File Name\nMay 14 2024 16:00:00,245760,macb,0,0,5234-128-1,C:/Users/jsmith/Desktop/confidential.xlsx\nMay 14 2024 16:00:05,1048576,m...,0,0,5235-128-1,C:/Users/jsmith/Desktop/data_to_exfiltrate.zip\nMay 14 2024 16:05:32,4096,.a..,0,0,5240-128-1,C:/Users/jsmith/Desktop/\nMay 14 2024 16:10:18,2048,..c.,0,0,341-144-1,C:/Users/jsmith/Desktop/ ($FILE_NAME)\n```\n\n**Understanding the Type field**:\n- **macb**: All four timestamps match (file created and immediately modified)\n- **m...**: Only Modified timestamp fired\n- **.a..**: Only Accessed timestamp fired\n- **..c.**: Only Changed (MFT metadata) timestamp fired\n- **...b**: Only Born (created) timestamp fired\n- **m.cb**: Modified, Changed, and Born (common when file is edited)\n\n**Forensic significance**:\n- **macb** (all aligned): Either a new file or potential timestomping\n- **m.c.**: File modified and metadata changed (normal edit)\n- **.a..**: File accessed but not modified (read-only operation)\n- **...b**: File created but not yet written (rare, may indicate staged file)\n\n### Timeline Filtering\n\n**By date range** (using grep):\n```bash\nmactime -b bodyfile.txt -d -z UTC | grep '2024-05-1[0-4]' > may10-14_timeline.csv\n```\n\n**By file extension** (using grep):\n```bash\nmactime -b bodyfile.txt -d -z UTC | grep '\\.exe$' > exe_timeline.csv\nmactime -b bodyfile.txt -d -z UTC | grep -E '\\.(xlsx?|docx?|pdf)$' > documents_timeline.csv\n```\n\n**By directory** (using grep):\n```bash\nmactime -b bodyfile.txt -d -z UTC | grep 'C:/Users/jsmith/Desktop' > desktop_timeline.csv\nmactime -b bodyfile.txt -d -z UTC | grep 'C:/Windows/Temp' > temp_timeline.csv\n```\n\n**By activity type** (using awk):\n```bash\n# Only file modifications (m)\nmactime -b bodyfile.txt -d -z UTC | awk -F, '$3 ~ /m/' > modifications_only.csv\n\n# Only file creations (b)\nmactime -b bodyfile.txt -d -z UTC | awk -F, '$3 ~ /b/' > creations_only.csv\n\n# Suspicious: All timestamps aligned (macb - potential timestomping)\nmactime -b bodyfile.txt -d -z UTC | awk -F, '$3 == \"macb\"' > suspicious_aligned.csv\n```\n\n### Custom Timeline Formats\n\n**CSV format** (default):\n```bash\nmactime -b bodyfile.txt -d -z UTC > timeline.csv\n```\n\n**Tab-delimited** (for Excel import):\n```bash\nmactime -b bodyfile.txt -d -z UTC | tr ',' '\\t' > timeline.tsv\n```\n\n**JSON format** (using custom script):\n```python\n#!/usr/bin/env python3\n# body2json.py - Convert body file to JSON\n\nimport json\nimport sys\nimport datetime\n\ndef body_to_json(bodyfile_path):\n    timeline = []\n    \n    with open(bodyfile_path, 'r', encoding='utf-8', errors='ignore') as f:\n        for line in f:\n            fields = line.strip().split('|')\n            if len(fields) < 11:\n                continue\n            \n            md5, filename, inode, mode, uid, gid, size, atime, mtime, ctime, crtime = fields[:11]\n            \n            entry = {\n                'filename': filename,\n                'inode': inode,\n                'size': int(size) if size.isdigit() else 0,\n                'timestamps': {\n                    'accessed': datetime.datetime.fromtimestamp(int(atime), tz=datetime.timezone.utc).isoformat() if atime.isdigit() else None,\n                    'modified': datetime.datetime.fromtimestamp(int(mtime), tz=datetime.timezone.utc).isoformat() if mtime.isdigit() else None,\n                    'changed': datetime.datetime.fromtimestamp(int(ctime), tz=datetime.timezone.utc).isoformat() if ctime.isdigit() else None,\n                    'created': datetime.datetime.fromtimestamp(int(crtime), tz=datetime.timezone.utc).isoformat() if crtime.isdigit() else None\n                }\n            }\n            timeline.append(entry)\n    \n    return timeline\n\nif __name__ == '__main__':\n    if len(sys.argv) < 2:\n        print(\"Usage: python body2json.py bodyfile.txt\")\n        sys.exit(1)\n    \n    timeline = body_to_json(sys.argv[1])\n    print(json.dumps(timeline, indent=2))\n```\n\n---\n\n## Deleted File Recovery\n\nOne of TSK's most powerful features is recovering deleted files from unallocated MFT entries.\n\n### How Deleted File Recovery Works\n\n**NTFS file deletion process**:\n1. File is deleted (Shift+Delete or emptied from Recycle Bin)\n2. MFT entry is marked as unallocated (InUse flag set to FALSE)\n3. Data clusters are added to $Bitmap as unallocated\n4. **MFT entry remains intact** until overwritten by new file\n\n**TSK's fls -r flag**:\n- Parses ALL MFT entries, including those marked as unallocated\n- Extracts metadata (filename, timestamps, size, data runs)\n- Marks deleted entries with asterisk (*) in output\n\n### Recovering Deleted Files\n\n**Step 1: Generate body file with deleted entries**\n```bash\nfls -o 2048 -r -m C: suspect_disk.dd > bodyfile_with_deleted.txt\n```\n\n**Step 2: Filter deleted entries**\n```bash\ngrep '\\*' bodyfile_with_deleted.txt > deleted_files.txt\n\n# Count deleted files\nwc -l deleted_files.txt\n# Output: 4,523 deleted files found\n```\n\n**Step 3: Generate timeline of deleted files**\n```bash\nmactime -b deleted_files.txt -d -z UTC > deleted_timeline.csv\n```\n\n**Step 4: Extract deleted file contents**\n```bash\n# Identify deleted file's inode\ngrep 'malware.exe' deleted_files.txt\n# Output: 0|C:/Windows/Temp/malware.exe (deleted)|8234-128-1|...\n\n# Extract file using icat\nicat -o 2048 suspect_disk.dd 8234-128-1 > recovered_malware.exe\n\n# Verify recovery\nmd5sum recovered_malware.exe\nfile recovered_malware.exe\n# Output: PE32 executable (GUI) Intel 80386, for MS Windows\n```\n\n**Important**: Deleted file recovery success depends on:\n1. **MFT entry not overwritten**: If new files reused the MFT entry, metadata is lost\n2. **Data clusters not overwritten**: If $Bitmap allocated clusters to new files, content is lost\n3. **Fragmentation**: Highly fragmented deleted files may be partially overwritten\n\n**Best practice**: Prioritize deleted file recovery EARLY in investigations before live systems overwrite unallocated space.\n\n---\n\n## Timeline Analysis Techniques\n\n### 1. Lateral Movement Detection\n\n**Scenario**: Attacker compromised workstation and moved laterally to file server.\n\n**Timeline indicators**:\n```bash\n# Search for network share access\nmactime -b bodyfile.txt -d -z UTC | grep -E '(\\\\\\\\|smb|cifs)' > network_activity.csv\n\n# Search for credential dumping tools\nmactime -b bodyfile.txt -d -z UTC | grep -iE '(mimikatz|procdump|pwdump|lsass)' > cred_theft.csv\n\n# Search for PsExec or remote execution\nmactime -b bodyfile.txt -d -z UTC | grep -iE '(psexec|wmic|winrm|powershell.*-computer)' > remote_exec.csv\n```\n\n### 2. Data Exfiltration Timeline\n\n**Scenario**: Insider threat copied confidential files to USB before resignation.\n\n**Timeline workflow**:\n```bash\n# Step 1: Identify high-value directories\nmactime -b bodyfile.txt -d -z UTC | grep -i 'confidential\\|proprietary\\|restricted' > high_value_files.csv\n\n# Step 2: Filter to date range (2 weeks before resignation)\nmactime -b bodyfile.txt -d -z UTC | grep '2024-05-0[1-9]\\|2024-05-1[0-4]' > may1-14_timeline.csv\n\n# Step 3: Correlate with USB device access (requires Registry analysis)\n# Look for file access timestamps matching USB connection times\n\n# Step 4: Identify file modifications/copies\nawk -F, '$3 ~ /m/' may1-14_timeline.csv | grep -i 'confidential' > exfiltration_candidates.csv\n```\n\n### 3. Ransomware Timeline Reconstruction\n\n**Scenario**: Ransomware encrypted files on May 14, 2024. Reconstruct attack timeline.\n\n**Timeline workflow**:\n```bash\n# Step 1: Identify ransomware executable\nmactime -b bodyfile.txt -d -z UTC | grep '\\.exe$' | grep 'May 14 2024' > exe_created_may14.csv\n\n# Step 2: Identify mass file modifications (encryption)\nmactime -b bodyfile.txt -d -z UTC | awk -F, '$3 ~ /m/' | grep 'May 14 2024 14:[0-9][0-9]' > modifications_14h.csv\n# If 10,000+ files modified in 1-hour window ‚Üí likely ransomware\n\n# Step 3: Timeline clustering analysis\nawk -F, '{print $1}' modifications_14h.csv | cut -d' ' -f4 | cut -d':' -f1-2 | sort | uniq -c\n# Output:\n#   12 14:32\n#   4521 14:33  ‚Üê Mass encryption started\n#   8234 14:34\n#   6543 14:35\n#    234 14:36  ‚Üê Encryption completed\n\n# Step 4: Identify ransom note creation\nmactime -b bodyfile.txt -d -z UTC | grep -iE '(readme|ransom|decrypt|recover)' | grep 'May 14 2024'\n```\n\n### 4. Timestomping Detection\n\n**Scenario**: Attacker modified file timestamps to hide activity.\n\n**Detection logic**: Compare $STANDARD_INFORMATION timestamps vs $FILE_NAME timestamps.\n\n**TSK limitation**: fls extracts $STANDARD_INFORMATION timestamps (easily modified). For $FILE_NAME comparison, use MFTECmd.exe.\n\n**Alternative approach**: Look for suspicious timestamp patterns in timeline.\n\n```bash\n# Identify files with perfectly aligned macb timestamps\nmactime -b bodyfile.txt -d -z UTC | awk -F, '$3 == \"macb\"' > aligned_timestamps.csv\n\n# Filter to files older than 1 day (new files naturally have aligned macb)\nawk -F, '{\n    # Extract timestamp (field 1: \"May 14 2024 16:32:18\")\n    # Compare to current date - if more than 1 day old, flag as suspicious\n}' aligned_timestamps.csv\n```\n\n**Better timestomping detection**: Use MFTECmd.exe (covered in Lesson 38) which compares $SI vs $FN timestamps.\n\n---\n\n## Auxiliary TSK Tools\n\n### mmls: Partition Layout Analysis\n\n**Purpose**: Identify partition offsets for fls.\n\n```bash\nmmls suspect_disk.dd\n\n# Output:\nDOS Partition Table\nOffset Sector: 0\nUnits are in 512-byte sectors\n\n      Slot      Start        End          Length       Description\n000:  Meta      0000000000   0000000000   0000000001   Primary Table (#0)\n001:  -------   0000000000   0000002047   0000002048   Unallocated\n002:  000:000   0000002048   0976771071   0976769024   NTFS / exFAT (0x07)\n003:  -------   0976771072   0976773119   0000002048   Unallocated\n```\n\n**Key information**:\n- **Slot 002**: Main NTFS partition\n- **Start**: 2048 sectors (offset for fls: `-o 2048`)\n- **Length**: 976,769,024 sectors √ó 512 bytes/sector = 500 GB\n\n### fsstat: Filesystem Statistics\n\n**Purpose**: Display filesystem metadata (block size, MFT location, volume serial).\n\n```bash\nfsstat -o 2048 suspect_disk.dd\n\n# Output:\nFILE SYSTEM INFORMATION\n--------------------------------------------\nFile System Type: NTFS\nVolume Serial Number: AC4E2F31\nOEM Name: NTFS    \nVolume Name: OS\n\nMETADATA INFORMATION\n--------------------------------------------\nFirst Cluster of MFT: 786432\nFirst Cluster of MFT Mirror: 2\nSize of MFT Entries: 1024 bytes\nSize of Index Records: 4096 bytes\n\nCONTENT INFORMATION\n--------------------------------------------\nSector Size: 512\nCluster Size: 4096\nTotal Cluster Range: 0 - 122096127\n```\n\n**Forensic significance**:\n- **Volume Serial Number**: AC4E2F31 (matches USB Registry, LNK files for device correlation)\n- **MFT location**: Cluster 786432 (can manually extract MFT for offline analysis)\n- **Cluster size**: 4096 bytes (affects file slack calculation)\n\n### icat: File Content Extraction\n\n**Purpose**: Extract file contents by inode/MFT entry number.\n\n```bash\n# Extract file by inode\nicat -o 2048 suspect_disk.dd 5234-128-1 > confidential.xlsx\n\n# Extract deleted file\nicat -o 2048 suspect_disk.dd 8234-128-1 > recovered_malware.exe\n\n# Extract file and pipe to analysis tool\nicat -o 2048 suspect_disk.dd 5234-128-1 | strings | grep -i password\n```\n\n**Use cases**:\n- Recover deleted files without mounting filesystem\n- Extract files from encrypted containers (after decryption)\n- Analyze file contents without altering evidence\n\n### istat: Detailed Inode/MFT Information\n\n**Purpose**: Display comprehensive MFT entry details.\n\n```bash\nistat -o 2048 suspect_disk.dd 5234-128-1\n\n# Output:\nMFT Entry: 5234\nSequence: 1\nAllocated\nFile Attributes: Archive\nDirectory\nSecurity ID: 1234\nOwner ID: 0\n\n$STANDARD_INFORMATION Attribute Values:\nFlags: Archive\nOwner ID: 0\nSecurity ID: 1234\nCreated:      2024-05-01 08:15:32.123456 (UTC)\nFile Modified:    2024-05-14 16:42:18.987654 (UTC)\nMFT Modified:     2024-05-14 16:42:18.987654 (UTC)\nAccessed:     2024-05-14 16:42:18.987654 (UTC)\n\n$FILE_NAME Attribute Values:\nFlags: Archive\nName: confidential.xlsx\nParent MFT Entry: 341\nCreated:      2024-05-01 08:15:32.123456 (UTC)\nFile Modified:    2024-05-14 16:42:18.987654 (UTC)\nMFT Modified:     2024-05-14 16:42:18.987654 (UTC)\nAccessed:     2024-05-14 16:42:18.987654 (UTC)\n\nAttributes:\nType: $STANDARD_INFORMATION (16-0)   Name: N/A   Resident   size: 72\nType: $FILE_NAME (48-1)   Name: N/A   Resident   size: 82\nType: $DATA (128-1)   Name: N/A   Non-Resident   size: 245760  init_size: 245760\n  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ...\n  5234000 5234001 5234002 5234003 5234004 5234005 ...\n```\n\n**Key details**:\n- **MFT Entry 5234**: File metadata container\n- **$STANDARD_INFORMATION vs $FILE_NAME timestamps**: For timestomping detection (both show same timestamps = likely legitimate)\n- **$DATA attribute**: Non-Resident (stored in clusters), size 245,760 bytes\n- **Data runs**: Clusters 5234000-5234005 (contiguous, not fragmented)\n\n---\n\n## Integration with Other Artifacts\n\n### Super-Timeline Concept\n\nA **super-timeline** combines filesystem timeline (TSK) with application artifacts (Jump Lists, Prefetch, Event Logs, Registry) for comprehensive activity reconstruction.\n\n**Super-timeline workflow**:\n\n```bash\n# Step 1: Generate filesystem body file\nfls -o 2048 -r -m C: suspect_disk.dd > bodyfile_filesystem.txt\n\n# Step 2: Generate Jump Lists body file (using log2timeline/plaso - Lesson 37)\n# For now, manually merge timelines\n\n# Step 3: Generate Event Log body file\n# (Convert Windows Event Logs to body file format)\n\n# Step 4: Merge all body files\ncat bodyfile_filesystem.txt bodyfile_jumplists.txt bodyfile_eventlogs.txt > bodyfile_super.txt\n\n# Step 5: Sort by timestamp\nsort -t'|' -k8 -n bodyfile_super.txt > bodyfile_super_sorted.txt\n\n# Step 6: Generate super-timeline\nmactime -b bodyfile_super_sorted.txt -d -z UTC > super_timeline.csv\n```\n\n**Super-timeline advantages**:\n1. **Comprehensive view**: Filesystem + application + system events in one timeline\n2. **Correlation**: See file access (MFT) alongside application execution (Prefetch) and user logon (Event Log 4624)\n3. **Context**: Understand \"what happened\" (filesystem) and \"why\" (application behavior)\n\n### Example: Correlating TSK Timeline with Jump Lists\n\n**Scenario**: Jump Lists show file `C:/Users/jsmith/Desktop/confidential.xlsx` accessed 38 times. TSK timeline shows when file was created, modified, deleted.\n\n**Correlation workflow**:\n\n```bash\n# Step 1: Extract TSK timeline for confidential.xlsx\nmactime -b bodyfile.txt -d -z UTC | grep 'confidential.xlsx' > tsk_confidential.csv\n\n# Step 2: Parse Jump Lists (Lesson 35)\nJLECmd.exe -d AutomaticDestinations --csv output --csvf jumplists.csv\ngrep 'confidential.xlsx' output/jumplists.csv > jumplist_confidential.csv\n\n# Step 3: Compare timelines\n# TSK shows:\n# May 01 2024 08:15:32 - Created (b)\n# May 14 2024 16:42:18 - Modified (m)\n# May 14 2024 16:42:18 - MFT Changed (c)\n\n# Jump Lists show:\n# Creation Time: May 01 2024 08:15:32\n# Last Modified: May 14 2024 16:42:18\n# Access Count: 38\n\n# Convergent evidence:\n# - File created May 1 (TSK + Jump Lists match)\n# - File last accessed May 14 (TSK + Jump Lists match)\n# - File accessed 38 times between May 1-14 (Jump Lists unique insight)\n# - File still exists on filesystem (TSK shows no deletion timestamp)\n```\n\n**Forensic conclusion**: TSK provides filesystem-level proof of file existence and timestamps. Jump Lists provide application-level proof of access frequency. Together: bulletproof evidence.\n\n---\n\n## Real-World Case Study: Ransomware Timeline Reconstruction (2021)\n\n### Background\n\n**Company**: Regional hospital network (anonymized as \"HealthCare Regional\")\n\n**Incident**: Ryuk ransomware encrypted 250+ servers on May 14, 2021 at 14:33 UTC\n\n**Impact**: \n- Emergency room diverted patients (unable to access medical records)\n- Surgery cancellations (anesthesia systems encrypted)\n- $15M ransom demand\n- 2-week recovery period\n\n**Investigation challenge**: Determine initial compromise, lateral movement timeline, and exfiltration (Ryuk operators typically exfiltrate before encryption).\n\n### Timeline Reconstruction with TSK\n\n**Step 1: Forensic Image Acquisition**\n\nIT team captured forensic images of:\n- Patient workstation (initial compromise suspected)\n- Domain Controller (credential theft target)\n- File server (exfiltration source)\n- Backup server (ransomware destroyed backups)\n\n**Step 2: TSK Body File Generation**\n\n```bash\n# Patient workstation\nfls -o 2048 -r -m C: workstation_image.dd > body_workstation.txt\n\n# Domain Controller\nfls -o 2048 -r -m C: dc_image.dd > body_dc.txt\n\n# File server\nfls -o 2048 -r -m D: fileserver_image.dd > body_fileserver.txt\n\n# Merge body files\ncat body_workstation.txt body_dc.txt body_fileserver.txt > body_all.txt\nsort -t'|' -k8 -n body_all.txt > body_all_sorted.txt\n```\n\n**Step 3: Timeline Generation**\n\n```bash\n# Generate full timeline\nmactime -b body_all_sorted.txt -d -z UTC > timeline_full.csv\n\n# Timeline size: 2.3 million entries (too large for manual review)\n\n# Filter to incident timeframe (May 10-14, 2021)\ngrep '2021-05-1[0-4]' timeline_full.csv > timeline_may10-14.csv\n\n# Still 487,000 entries - need more filtering\n```\n\n**Step 4: Ransomware Executable Identification**\n\n```bash\n# Search for suspicious executables created during incident\ngrep '\\.exe$' timeline_may10-14.csv | awk -F, '$3 ~ /b/' > exe_created.csv\n\n# Filter to non-standard locations (C:\\Windows\\Temp, C:\\ProgramData, etc.)\ngrep -v 'C:/Program Files\\|C:/Windows/System32\\|C:/Windows/SysWOW64' exe_created.csv > exe_suspicious.csv\n\n# Results:\nMay 14 2021 14:28:32,245760,macb,0,0,8234-128-1,C:/Windows/Temp/update.exe\nMay 14 2021 14:28:45,128000,macb,0,0,8241-128-1,C:/ProgramData/Microsoft/Windows/update_service.exe\n```\n\n**Analysis**: Two executables created May 14 at 14:28 (5 minutes before mass encryption).\n\n**Verification**:\n```bash\n# Extract executables for malware analysis\nicat -o 2048 workstation_image.dd 8234-128-1 > update.exe\nicat -o 2048 workstation_image.dd 8241-128-1 > update_service.exe\n\n# Hash analysis\nmd5sum update.exe\n# Output: 4d8b2d5f3a1e7c9b8a6e3f4d5c2a1b0e\n\n# VirusTotal lookup (hash matched Ryuk ransomware sample)\n```\n\n**Step 5: Mass Encryption Timeline**\n\n```bash\n# Identify file modifications at 14:33 (encryption)\ngrep 'May 14 2021 14:3[0-9]' timeline_may10-14.csv | awk -F, '$3 ~ /m/' > encryption_timeline.csv\n\n# Count files encrypted per minute\nawk -F, '{print $1}' encryption_timeline.csv | cut -d':' -f2 | sort | uniq -c\n# Output:\n#    42 14:30\n#    87 14:31\n#   234 14:32\n#  8234 14:33  ‚Üê Mass encryption started\n# 15423 14:34\n# 12341 14:35\n#  6543 14:36\n#   234 14:37\n#    12 14:38  ‚Üê Encryption completed\n\n# Total: 43,150 files encrypted in 8 minutes\n```\n\n**Step 6: Ransom Note Creation**\n\n```bash\n# Search for ransom notes\ngrep -iE '(readme|ransom|decrypt|recover|ryu?k)' timeline_may10-14.csv\n\n# Results:\nMay 14 2021 14:33:12,1024,macb,0,0,52341-128-1,C:/Users/Public/RyukReadMe.txt\nMay 14 2021 14:33:15,1024,macb,0,0,52342-128-1,D:/FileServer/Shares/RyukReadMe.txt\n```\n\n**Step 7: Lateral Movement Timeline**\n\n```bash\n# Search for PsExec or remote execution tools\ngrep -iE '(psexec|wmic|winrm|paexec)' timeline_may10-14.csv\n\n# Results:\nMay 14 2021 14:27:18,245760,macb,0,0,7234-128-1,C:/Windows/Temp/PsExec.exe\nMay 14 2021 14:27:32,128000,macb,0,0,7241-128-1,C:/Windows/Temp/servers.txt\n```\n\n**Analysis**: PsExec dropped at 14:27, `servers.txt` created (likely list of targets for lateral movement).\n\n**Verification**:\n```bash\n# Extract servers.txt\nicat -o 2048 workstation_image.dd 7241-128-1 > servers.txt\n\ncat servers.txt\n# Output:\nDC01.healthcare.local\nFILESRV01.healthcare.local\nFILESRV02.healthcare.local\nBACKUP01.healthcare.local\nEXCHANGE01.healthcare.local\n# ...(250+ servers listed)\n```\n\n**Step 8: Initial Compromise Timeline**\n\n```bash\n# Work backwards from May 14 14:27 (PsExec drop)\n# Search for suspicious file access 1-7 days prior\n\ngrep '2021-05-0[7-9]\\|2021-05-1[0-3]' timeline_full.csv | grep -iE '(phish|malware|trojan|temp)' > initial_compromise_candidates.csv\n\n# Results:\nMay 10 2021 09:15:32,45000,macb,0,0,5234-128-1,C:/Users/jsmith/AppData/Local/Temp/Invoice_May2021.doc\n```\n\n**Analysis**: Malicious Word document downloaded May 10 at 09:15 (4 days before ransomware execution).\n\n**Step 9: Credential Theft Timeline**\n\n```bash\n# Search for Mimikatz or credential dumping tools\ngrep -iE '(mimikatz|procdump|dumpert|lsass)' timeline_may10-14.csv\n\n# Results:\nMay 12 2021 16:42:18,245000,macb,0,0,6234-128-1,C:/Windows/Temp/m.exe\nMay 12 2021 16:42:32,128000,macb,0,0,6241-128-1,C:/Windows/Temp/lsass.dmp\n```\n\n**Analysis**: Mimikatz (`m.exe`) executed May 12, dumped LSASS memory (domain admin credentials stolen).\n\n### Complete Attack Timeline\n\n```\nMay 10, 2021 09:15:32 UTC - INITIAL COMPROMISE\n  - Phishing email delivers Invoice_May2021.doc\n  - Macro executes, downloads Cobalt Strike beacon\n  - Patient workstation: C:/Users/jsmith/AppData/Local/Temp/Invoice_May2021.doc (Created)\n\nMay 10-12, 2021 - RECONNAISSANCE\n  - Cobalt Strike beacon maintains persistence\n  - Attacker enumerates Active Directory\n  - Network scanning (Nmap, BloodHound)\n\nMay 12, 2021 16:42:18 UTC - CREDENTIAL THEFT\n  - Mimikatz executed (C:/Windows/Temp/m.exe)\n  - LSASS memory dumped (C:/Windows/Temp/lsass.dmp)\n  - Domain Admin credentials extracted\n\nMay 12-14, 2021 - LATERAL MOVEMENT\n  - Domain Admin credentials used for RDP to Domain Controller\n  - Additional systems compromised via PsExec\n\nMay 14, 2021 14:27:18 UTC - RANSOMWARE STAGING\n  - PsExec.exe dropped (C:/Windows/Temp/PsExec.exe)\n  - Target list created (C:/Windows/Temp/servers.txt - 250+ servers)\n  - Ryuk ransomware staged (C:/Windows/Temp/update.exe)\n\nMay 14, 2021 14:28:32 UTC - RANSOMWARE DEPLOYMENT\n  - PsExec used to copy ransomware to all targets\n  - Scheduled tasks created for execution at 14:33\n\nMay 14, 2021 14:33:00 UTC - MASS ENCRYPTION\n  - Ryuk ransomware executes on 250+ servers simultaneously\n  - 43,150 files encrypted in 8 minutes\n  - Ransom notes deployed: C:/Users/Public/RyukReadMe.txt\n\nMay 14, 2021 14:38:00 UTC - ENCRYPTION COMPLETE\n  - Ransomware self-deletes executables\n  - Backup servers destroyed (shadow copies deleted)\n  - $15M ransom demand displayed\n```\n\n### TSK's Critical Role\n\nWithout TSK timeline reconstruction:\n- Initial compromise (May 10) would not have been identified (4-day gap)\n- Credential theft (May 12) would have been missed\n- Exact encryption timeline (14:33-14:38) unknown\n- Exfiltration window unclear\n\n**With TSK timeline**:\n- Complete attack chain reconstructed (initial access ‚Üí credential theft ‚Üí lateral movement ‚Üí ransomware)\n- Timeline gaps identified (May 10-12: reconnaissance phase)\n- Encryption pattern analyzed (43,150 files in 8 minutes = systematic, coordinated)\n- Malware artifacts recovered (Invoice_May2021.doc, m.exe, update.exe, PsExec.exe)\n\n### Legal and Recovery Outcomes\n\n**FBI Notification**: Timeline provided to FBI Cyber Division, linked to known Ryuk operator group.\n\n**Recovery**: Timeline enabled targeted restoration (prioritized May 9 backups, pre-compromise).\n\n**Prevention**: Timeline analysis led to:\n- Email security improvements (block macro-enabled docs)\n- Credential hygiene (no more cached domain admin creds)\n- Network segmentation (isolated patient workstations from servers)\n- EDR deployment (detect Mimikatz, PsExec in real-time)\n\n**Cost**: $15M ransom NOT paid. Recovery cost: $8M (consultants, new hardware, overtime).\n\n**Lesson learned**: TSK timeline reconstruction is CRITICAL for understanding attack chains, identifying root cause, and preventing recurrence.\n\n---\n\n## Key Takeaways\n\n### TSK Strengths\n\n1. **Open-source and cross-platform**: Free, runs on Linux/macOS/Windows, no vendor lock-in\n2. **Filesystem-neutral**: NTFS, FAT, EXT4, HFS+, APFS, ISO9660\n3. **Command-line efficiency**: Fast, scriptable, automatable\n4. **Deleted file recovery**: fls -r recovers unallocated MFT entries\n5. **Body file format**: Intermediate format enables multi-source timeline merging\n6. **Battle-tested**: 20+ years of real-world use in major investigations\n7. **Foundation for Autopsy**: Understanding TSK helps you understand Autopsy's internals\n\n### TSK Limitations\n\n1. **No GUI**: Command-line only (use Autopsy for GUI)\n2. **No built-in date filtering**: Must pipe to grep/awk for timeline filtering\n3. **No artifact parsing**: TSK parses filesystems, not applications (no Jump Lists, Prefetch, Registry parsing)\n4. **$STANDARD_INFORMATION only**: fls extracts $SI timestamps (easily modified), not $FILE_NAME (requires MFTECmd)\n5. **Manual correlation required**: TSK doesn't automatically correlate with other artifacts (requires manual merging)\n\n### When to Use TSK\n\n**Use TSK when you need**:\n- Filesystem-level timeline reconstruction at scale\n- Deleted file recovery from unallocated MFT entries\n- Cross-platform forensic analysis (Linux, macOS, BSD)\n- Scriptable, automatable workflows (CI/CD forensics, SOAR integration)\n- Open-source tools (no licensing costs, auditable code)\n\n**Use alternatives when you need**:\n- **GUI analysis**: Autopsy (uses TSK under the hood)\n- **Windows-specific artifacts**: Eric Zimmerman Tools (MFTECmd, PECmd, JLECmd)\n- **Super-timeline with minimal effort**: Plaso/Log2Timeline (Lesson 37)\n- **Timestomping detection**: MFTECmd ($SI vs $FN comparison)\n- **Memory forensics**: Volatility 3, MemProcFS\n\n---\n\n## Summary\n\n**The Sleuth Kit (TSK) is the foundational open-source forensic toolkit for filesystem analysis and timeline reconstruction.**\n\nKey concepts:\n- **fls**: Filesystem listing tool that parses MFT and generates body files\n- **mactime**: Converts body files to human-readable MACB timelines\n- **Body file format**: Intermediate pipe-delimited format (MD5|filename|inode|mode|UID|GID|size|atime|mtime|ctime|crtime)\n- **Deleted file recovery**: fls -r flag extracts unallocated MFT entries\n- **MACB timeline**: Modified, Accessed, Changed, Born timestamps in unified view\n- **Partition offsets**: Use mmls to identify offsets, then fls -o <offset>\n- **Auxiliary tools**: icat (extract files), istat (detailed MFT info), fsstat (filesystem stats)\n- **Super-timeline concept**: Merge filesystem timeline with application artifacts for comprehensive reconstruction\n\n**Real-world impact**: TSK enabled complete attack chain reconstruction in HealthCare Regional ransomware case, identifying initial compromise (May 10), credential theft (May 12), and mass encryption (May 14).\n\n**Next lesson**: We'll explore **Plaso and Log2Timeline** - automated super-timeline generation that combines TSK with Jump Lists, Prefetch, Event Logs, Registry, and 100+ other artifact parsers. This is where timeline analysis becomes enterprise-scale forensic automation!"
      }
    },
    {
      "type": "code_exercise",
      "content": {
        "text": "# Hands-On: The Sleuth Kit (TSK) Forensics Lab\n\n## Exercise 1: Basic TSK Workflow - Partition to Timeline\n\n**Scenario**: You have a forensic disk image (`suspect_disk.dd`) from a Windows 10 workstation. Generate a filesystem timeline.\n\n### Step 1: Identify Partition Layout\n\n```bash\n# Use mmls to list partitions\nmmls suspect_disk.dd\n\n# Expected output:\nDOS Partition Table\nOffset Sector: 0\nUnits are in 512-byte sectors\n\n      Slot      Start        End          Length       Description\n000:  Meta      0000000000   0000000000   0000000001   Primary Table (#0)\n001:  -------   0000000000   0000002047   0000002048   Unallocated\n002:  000:000   0000002048   0976771071   0976769024   NTFS / exFAT (0x07)\n003:  -------   0976771072   0976773119   0000002048   Unallocated\n\n# Key information: NTFS partition starts at sector 2048\n```\n\n### Step 2: Display Filesystem Statistics\n\n```bash\n# Use fsstat to get filesystem details\nfsstat -o 2048 suspect_disk.dd\n\n# Expected output:\nFILE SYSTEM INFORMATION\n--------------------------------------------\nFile System Type: NTFS\nVolume Serial Number: AC4E2F31\nVolume Name: OS\nFirst Cluster of MFT: 786432\nCluster Size: 4096\n```\n\n**Key details**:\n- Volume Serial: AC4E2F31 (correlate with USB Registry, LNK files)\n- Cluster size: 4096 bytes (for file slack calculations)\n\n### Step 3: List Root Directory\n\n```bash\n# Basic directory listing\nfls -o 2048 suspect_disk.dd\n\n# Expected output:\nr/r 4-128-1:    $AttrDef\nr/r 8-128-1:    $BadClus\nd/d 11-144-4:   $Extend\nd/d 5-144-5:    Windows\nd/d 27-144-1:   Program Files\nd/d 29-144-1:   Users\nd/d 30-144-1:   ProgramData\n```\n\n### Step 4: Generate Body File\n\n```bash\n# Generate body file with recursive flag (includes deleted files)\nfls -o 2048 -r -m C: suspect_disk.dd > bodyfile.txt\n\n# Check body file size\nwc -l bodyfile.txt\n# Output: 487,234 entries\n\n# Preview body file format\nhead -n 5 bodyfile.txt\n# Output (pipe-delimited):\n# 0|C:/$AttrDef|4-128-1|-rw-rw-rw-|0|0|2560|1715606400|1715606400|1715606400|1715606400\n# 0|C:/$BadClus|8-128-1|-rw-rw-rw-|0|0|0|1715606400|1715606400|1715606400|1715606400\n```\n\n### Step 5: Generate MACB Timeline\n\n```bash\n# Convert body file to human-readable timeline\nmactime -b bodyfile.txt -d -z UTC > timeline.csv\n\n# Preview timeline\nhead -n 10 timeline.csv\n\n# Expected output:\nDate,Size,Type,Mode,UID,GID,Meta,File Name\nMay 01 2024 08:15:32,245760,macb,0,0,5234-128-1,C:/Users/jsmith/Desktop/confidential.xlsx\nMay 01 2024 08:16:05,1048576,m...,0,0,5235-128-1,C:/Users/jsmith/Desktop/data.zip\nMay 01 2024 09:15:32,45000,macb,0,0,5240-128-1,C:/Users/jsmith/AppData/Local/Temp/Invoice.doc\n```\n\n**Analysis Questions**:\n1. How many files are in the filesystem? (`wc -l bodyfile.txt`)\n2. What is the volume serial number? (`fsstat` output)\n3. What is the earliest file creation timestamp? (`head timeline.csv`)\n\n---\n\n## Exercise 2: Deleted File Recovery\n\n**Scenario**: Suspect deleted files before investigation. Recover deleted files and generate timeline.\n\n### Step 1: Identify Deleted Files\n\n```bash\n# Filter body file for deleted entries (marked with asterisk)\ngrep '\\*' bodyfile.txt > deleted_files.txt\n\n# Count deleted files\nwc -l deleted_files.txt\n# Output: 4,523 deleted files found\n\n# Preview deleted entries\nhead -n 10 deleted_files.txt\n# Output:\n# 0|C:/Windows/Temp/malware.exe (deleted)|8234-128-1|-rw-rw-rw-|0|0|245760|1715692800|1715692800|1715692800|1715606400\n```\n\n### Step 2: Generate Deleted Files Timeline\n\n```bash\n# Create timeline of deleted files only\nmactime -b deleted_files.txt -d -z UTC > deleted_timeline.csv\n\n# Analyze deletion patterns\nawk -F, '{print substr($1,1,10)}' deleted_timeline.csv | sort | uniq -c\n# Output:\n#    12 May 01 2024\n#    47 May 10 2024\n#  1234 May 14 2024  ‚Üê Mass deletion on May 14!\n#  2341 May 14 2024\n```\n\n**Analysis**: 3,575 files deleted on May 14 (potential evidence destruction).\n\n### Step 3: Extract Deleted Malware Executable\n\n```bash\n# Search for deleted executables\ngrep '\\.exe' deleted_files.txt | grep -i 'temp\\|malware\\|suspicious'\n\n# Output:\n# 0|C:/Windows/Temp/malware.exe (deleted)|8234-128-1|...\n\n# Extract deleted file using icat\nicat -o 2048 suspect_disk.dd 8234-128-1 > recovered_malware.exe\n\n# Verify recovery\nfile recovered_malware.exe\n# Output: PE32 executable (GUI) Intel 80386, for MS Windows\n\nmd5sum recovered_malware.exe\n# Output: 4d8b2d5f3a1e7c9b8a6e3f4d5c2a1b0e\n\n# Check VirusTotal\n# (Hash matches known Emotet banking trojan)\n```\n\n**Forensic significance**: Recovered deleted malware executable that suspect attempted to hide.\n\n---\n\n## Exercise 3: Timeline Filtering and Analysis\n\n**Scenario**: You have a 2.3 million entry timeline spanning 3 years. Filter to specific date range and file types for focused analysis.\n\n### Step 1: Filter by Date Range\n\n```bash\n# Filter timeline to May 10-14, 2024 (incident window)\nmactime -b bodyfile.txt -d -z UTC | grep '2024-05-1[0-4]' > may10-14_timeline.csv\n\n# Count entries\nwc -l may10-14_timeline.csv\n# Output: 87,234 entries (manageable size)\n\n# Daily activity breakdown\nawk -F, '{print substr($1,1,10)}' may10-14_timeline.csv | sort | uniq -c\n# Output:\n#  12341 May 10 2024\n#  15234 May 11 2024\n#  18234 May 12 2024\n#  23456 May 13 2024\n#  17969 May 14 2024\n```\n\n### Step 2: Filter by File Type\n\n```bash\n# Executables only\nmactime -b bodyfile.txt -d -z UTC | grep '\\.exe$' > exe_timeline.csv\n\n# Office documents only\nmactime -b bodyfile.txt -d -z UTC | grep -E '\\.(xlsx?|docx?|pptx?|pdf)$' > documents_timeline.csv\n\n# Scripts only (potential malware)\nmactime -b bodyfile.txt -d -z UTC | grep -E '\\.(ps1|vbs|js|bat|cmd)$' > scripts_timeline.csv\n\n# Archive files (potential exfiltration)\nmactime -b bodyfile.txt -d -z UTC | grep -E '\\.(zip|rar|7z|tar|gz)$' > archives_timeline.csv\n```\n\n### Step 3: Filter by Directory\n\n```bash\n# Desktop activity (high-value files)\nmactime -b bodyfile.txt -d -z UTC | grep '/Desktop/' > desktop_timeline.csv\n\n# Temp directory (malware staging)\nmactime -b bodyfile.txt -d -z UTC | grep -E '(C:/Windows/Temp|C:/Users/.*/AppData/Local/Temp)' > temp_timeline.csv\n\n# Downloads folder (initial access)\nmactime -b bodyfile.txt -d -z UTC | grep '/Downloads/' > downloads_timeline.csv\n```\n\n### Step 4: Filter by Activity Type\n\n```bash\n# File creations only (new files)\nmactime -b bodyfile.txt -d -z UTC | awk -F, '$3 ~ /b/' > creations_only.csv\n\n# File modifications only (edited files)\nmactime -b bodyfile.txt -d -z UTC | awk -F, '$3 ~ /m/' > modifications_only.csv\n\n# Suspicious: All timestamps aligned (potential timestomping)\nmactime -b bodyfile.txt -d -z UTC | awk -F, '$3 == \"macb\"' > suspicious_aligned.csv\n```\n\n---\n\n## Exercise 4: Ransomware Timeline Reconstruction\n\n**Scenario**: Ransomware encrypted files on May 14, 2024 at 14:33. Reconstruct attack timeline.\n\n### Step 1: Identify Mass Encryption Window\n\n```bash\n# Filter to May 14, 14:00-15:00 hour\nmactime -b bodyfile.txt -d -z UTC | grep 'May 14 2024 14:' > may14_14h_timeline.csv\n\n# Count modifications per minute\nawk -F, '$3 ~ /m/ {print substr($1,17,5)}' may14_14h_timeline.csv | sort | uniq -c\n# Output:\n#    42 14:30\n#   234 14:32\n#  8234 14:33  ‚Üê Encryption started!\n# 15423 14:34\n# 12341 14:35\n#  6543 14:36\n#   234 14:37\n#    12 14:38  ‚Üê Encryption completed\n\n# Total files encrypted\nawk -F, '$3 ~ /m/' may14_14h_timeline.csv | wc -l\n# Output: 43,150 files modified (encrypted)\n```\n\n**Analysis**: 43,150 files encrypted in 8 minutes (14:33-14:38).\n\n### Step 2: Identify Ransomware Executable\n\n```bash\n# Search for executables created shortly before encryption\nmactime -b bodyfile.txt -d -z UTC | grep 'May 14 2024 14:2[0-9]' | grep '\\.exe$' | awk -F, '$3 ~ /b/'\n\n# Output:\nMay 14 2024 14:28:32,245760,macb,0,0,8234-128-1,C:/Windows/Temp/update.exe\n\n# Extract executable\nicat -o 2048 suspect_disk.dd 8234-128-1 > ransomware.exe\n\n# Analyze\nmd5sum ransomware.exe\n# (VirusTotal: Ryuk ransomware)\n```\n\n### Step 3: Identify Ransom Note\n\n```bash\n# Search for ransom notes\nmactime -b bodyfile.txt -d -z UTC | grep -iE '(readme|ransom|decrypt|recover|restore)' | grep 'May 14 2024 14:3[0-9]'\n\n# Output:\nMay 14 2024 14:33:12,1024,macb,0,0,52341-128-1,C:/Users/Public/RyukReadMe.txt\nMay 14 2024 14:33:15,1024,macb,0,0,52342-128-1,D:/FileServer/RyukReadMe.txt\n\n# Extract ransom note\nicat -o 2048 suspect_disk.dd 52341-128-1 > ransom_note.txt\n\ncat ransom_note.txt\n# Output:\n# Your files have been encrypted with Ryuk ransomware.\n# To decrypt, pay $15,000,000 in Bitcoin to: [wallet address]\n# Contact: ryuk_support@onion.to\n```\n\n### Step 4: Identify Lateral Movement Tools\n\n```bash\n# Search for PsExec or remote execution tools\nmactime -b bodyfile.txt -d -z UTC | grep -iE '(psexec|wmic|paexec)' | grep 'May 14 2024 14:2[0-9]'\n\n# Output:\nMay 14 2024 14:27:18,245760,macb,0,0,7234-128-1,C:/Windows/Temp/PsExec.exe\nMay 14 2024 14:27:32,128000,macb,0,0,7241-128-1,C:/Windows/Temp/servers.txt\n\n# Extract target list\nicat -o 2048 suspect_disk.dd 7241-128-1 > servers.txt\n\ncat servers.txt\n# Output: (250+ server hostnames - lateral movement targets)\n```\n\n### Attack Timeline Summary\n\n```\n14:27:18 - PsExec.exe dropped (lateral movement tool)\n14:27:32 - servers.txt created (250+ targets)\n14:28:32 - update.exe created (Ryuk ransomware)\n14:33:00 - Mass encryption begins (43,150 files)\n14:33:12 - Ransom note deployed\n14:38:00 - Encryption completes\n```\n\n---\n\n## Exercise 5: Detailed MFT Entry Analysis with istat\n\n**Scenario**: Investigate suspicious file with potential timestomping.\n\n### Step 1: Identify Suspicious File\n\n```bash\n# Find files with perfectly aligned macb timestamps\nmactime -b bodyfile.txt -d -z UTC | awk -F, '$3 == \"macb\"' | grep -v '2024-05-01' > aligned_timestamps.csv\n\n# (Filter out May 1 files - newly created files naturally have aligned timestamps)\n\n# Review suspicious entries\nhead aligned_timestamps.csv\n# Output:\nMay 10 2024 08:15:32,245760,macb,0,0,5234-128-1,C:/Users/jsmith/Desktop/confidential.xlsx\n```\n\n**Question**: Was this file legitimately created on May 10, or modified later with timestamps changed?\n\n### Step 2: Detailed MFT Analysis\n\n```bash\n# Use istat to examine MFT entry in detail\nistat -o 2048 suspect_disk.dd 5234-128-1\n\n# Output:\nMFT Entry: 5234\nSequence: 1\nAllocated\nFile Attributes: Archive\n\n$STANDARD_INFORMATION Attribute Values:\nFlags: Archive\nCreated:      2024-05-10 08:15:32.000000 (UTC)\nFile Modified:    2024-05-10 08:15:32.000000 (UTC)\nMFT Modified:     2024-05-10 08:15:32.000000 (UTC)\nAccessed:     2024-05-10 08:15:32.000000 (UTC)\n\n$FILE_NAME Attribute Values:\nFlags: Archive\nName: confidential.xlsx\nParent MFT Entry: 341\nCreated:      2024-05-10 08:15:32.000000 (UTC)\nFile Modified:    2024-05-10 08:15:32.000000 (UTC)\nMFT Modified:     2024-05-10 08:15:32.000000 (UTC)\nAccessed:     2024-05-10 08:15:32.000000 (UTC)\n\nAttributes:\nType: $STANDARD_INFORMATION (16-0)   Name: N/A   Resident   size: 72\nType: $FILE_NAME (48-1)   Name: N/A   Resident   size: 82\nType: $DATA (128-1)   Name: N/A   Non-Resident   size: 245760  init_size: 245760\n```\n\n**Analysis**:\n- **$STANDARD_INFORMATION timestamps**: All identical (May 10 08:15:32)\n- **$FILE_NAME timestamps**: Also all identical (May 10 08:15:32)\n- **Verdict**: $SI and $FN match, suggesting legitimate file creation (not timestomping)\n\n**Note**: Timestomping typically modifies $STANDARD_INFORMATION but NOT $FILE_NAME. When $SI ‚â† $FN, investigate further.\n\n### Step 3: Extract File for Further Analysis\n\n```bash\n# Extract file contents\nicat -o 2048 suspect_disk.dd 5234-128-1 > confidential.xlsx\n\n# Analyze embedded metadata (OOXML)\nunzip -l confidential.xlsx\n# Output:\nArchive:  confidential.xlsx\n  Length      Date    Time    Name\n---------  ---------- -----   ----\n     1234  2024-05-10 08:15   [Content_Types].xml\n     5678  2024-05-10 08:15   _rels/.rels\n    12345  2024-05-10 08:15   xl/workbook.xml\n\n# Extract core.xml for author/created metadata\nunzip -p confidential.xlsx docProps/core.xml\n\n# Output:\n<cp:coreProperties>\n  <dc:creator>John Smith</dc:creator>\n  <dcterms:created xsi:type=\"dcterms:W3CDTF\">2024-05-10T08:15:32Z</dcterms:created>\n  <dcterms:modified xsi:type=\"dcterms:W3CDTF\">2024-05-10T08:15:32Z</dcterms:modified>\n</cp:coreProperties>\n```\n\n**Convergent evidence**: NTFS timestamps match Office embedded metadata (May 10 08:15:32) ‚Üí Likely legitimate creation, not timestomping.\n\n---\n\n## Exercise 6: Multi-Artifact Correlation (TSK + Jump Lists)\n\n**Scenario**: Correlate TSK filesystem timeline with Jump Lists to build comprehensive file access history.\n\n### Step 1: Generate TSK Timeline\n\n```bash\n# TSK body file and timeline\nfls -o 2048 -r -m C: suspect_disk.dd > bodyfile_tsk.txt\nmactime -b bodyfile_tsk.txt -d -z UTC > timeline_tsk.csv\n\n# Filter to specific file\ngrep 'confidential.xlsx' timeline_tsk.csv\n\n# Output:\nMay 01 2024 08:15:32,245760,macb,0,0,5234-128-1,C:/Users/jsmith/Desktop/confidential.xlsx\nMay 14 2024 16:42:18,245760,m.c.,0,0,5234-128-1,C:/Users/jsmith/Desktop/confidential.xlsx\n```\n\n**TSK findings**:\n- Created: May 1 08:15:32\n- Modified: May 14 16:42:18\n- File still exists (not deleted)\n\n### Step 2: Parse Jump Lists\n\n```bash\n# Using JLECmd (Lesson 35)\nJLECmd.exe -d \"C:\\Evidence\\Users\\jsmith\\AppData\\Roaming\\Microsoft\\Windows\\Recent\\AutomaticDestinations\" --csv output --csvf jumplists.csv\n\n# Filter to confidential.xlsx\ngrep 'confidential.xlsx' output/jumplists.csv\n\n# Output (CSV columns):\n# AppIdDescription,EntryNumber,CreationTime,LastModified,AccessCount,TargetPath\n# Microsoft Excel,47,2024-05-01T08:15:32Z,2024-05-14T16:42:18Z,38,C:/Users/jsmith/Desktop/confidential.xlsx\n```\n\n**Jump List findings**:\n- First access: May 1 08:15:32 (matches TSK creation time)\n- Last access: May 14 16:42:18 (matches TSK modification time)\n- Access count: 38 times\n\n### Step 3: Correlation Analysis\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                 CONVERGENT EVIDENCE                         ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ TSK Filesystem Timeline:                                    ‚îÇ\n‚îÇ   - File created: May 1, 2024 08:15:32 UTC                 ‚îÇ\n‚îÇ   - File modified: May 14, 2024 16:42:18 UTC               ‚îÇ\n‚îÇ   - Proves file existence and modification timestamps      ‚îÇ\n‚îÇ                                                             ‚îÇ\n‚îÇ Jump Lists (Excel Application):                            ‚îÇ\n‚îÇ   - First access: May 1, 2024 08:15:32 UTC (matches TSK)  ‚îÇ\n‚îÇ   - Last access: May 14, 2024 16:42:18 UTC (matches TSK)  ‚îÇ\n‚îÇ   - Access count: 38 times (TSK cannot provide this)       ‚îÇ\n‚îÇ   - Proves application-level access frequency              ‚îÇ\n‚îÇ                                                             ‚îÇ\n‚îÇ FORENSIC CONCLUSION:                                        ‚îÇ\n‚îÇ   ‚úÖ File was created May 1 (TSK + Jump Lists agree)      ‚îÇ\n‚îÇ   ‚úÖ File was accessed 38 times between May 1-14          ‚îÇ\n‚îÇ   ‚úÖ Last access May 14 (1 day before suspect resignation)‚îÇ\n‚îÇ   ‚úÖ High access frequency (38 times in 13 days)          ‚îÇ\n‚îÇ   ‚ö†Ô∏è  VERDICT: Strong indicator of systematic file review ‚îÇ\n‚îÇ       before resignation (potential data exfiltration)     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**Lesson**: TSK provides filesystem-level proof. Jump Lists provide application-level context. Together: bulletproof evidence.\n\n---\n\n## Challenge Exercise: Full Incident Timeline Reconstruction\n\n**Scenario**: You're investigating a data breach. Available evidence:\n- Forensic disk image (500 GB NTFS)\n- Incident date range: May 10-14, 2024\n- Suspected activities: Initial compromise, credential theft, lateral movement, data exfiltration\n\n**Your mission**: Generate a comprehensive timeline and identify key attack phases.\n\n### Deliverables\n\n1. **Full filesystem timeline** (TSK body file and mactime CSV)\n2. **Filtered timeline** (May 10-14 only)\n3. **Suspicious file list** (executables created in Temp directories)\n4. **Deleted file recovery** (recover and analyze deleted malware)\n5. **Attack phase identification**:\n   - Initial compromise timestamp\n   - Credential theft tools (Mimikatz, procdump)\n   - Lateral movement tools (PsExec, WMI)\n   - Exfiltration evidence (large archives created)\n6. **Executive summary** (1-page timeline with key findings)\n\n### Solution Approach\n\n```bash\n# Step 1: Generate body file\nfls -o 2048 -r -m C: suspect_disk.dd > bodyfile.txt\n\n# Step 2: Generate full timeline\nmactime -b bodyfile.txt -d -z UTC > timeline_full.csv\n\n# Step 3: Filter to incident window\ngrep '2024-05-1[0-4]' timeline_full.csv > timeline_may10-14.csv\n\n# Step 4: Identify suspicious executables\ngrep '\\.exe$' timeline_may10-14.csv | grep -E '(Temp|ProgramData|AppData)' | awk -F, '$3 ~ /b/' > suspicious_exe.csv\n\n# Step 5: Search for credential theft tools\ngrep -iE '(mimikatz|procdump|dumpert|lsass)' timeline_may10-14.csv\n\n# Step 6: Search for lateral movement tools\ngrep -iE '(psexec|wmic|winrm|paexec)' timeline_may10-14.csv\n\n# Step 7: Search for large archives (potential exfiltration)\nawk -F, '$2 > 10485760 {print}' timeline_may10-14.csv | grep -E '\\.(zip|rar|7z)$'\n\n# Step 8: Recover deleted files\ngrep '\\*' bodyfile.txt > deleted_files.txt\nmactime -b deleted_files.txt -d -z UTC > deleted_timeline.csv\n\n# Step 9: Extract deleted malware\nicat -o 2048 suspect_disk.dd <inode> > recovered_malware.exe\n\n# Step 10: Analyze and document findings\n```\n\n**Success criteria**:\n- Complete attack timeline reconstructed (initial access ‚Üí exfiltration)\n- All attack phases identified with timestamps\n- Malware samples recovered and analyzed\n- Executive summary is clear, evidence-based, and actionable"
      }
    },
    {
      "type": "memory_aid",
      "content": {
        "text": "# Memory Aids for The Sleuth Kit (TSK)\n\n## Acronym: \"FLiP MACS\" for Core TSK Tools\n\n**F**ls (Filesystem listing)\n**L**ist files and directories\n**i**cat (Extract file contents)\n**P**arse MFT entries\n\n**M**actime (Timeline generator)\n**A**nalyze timestamps\n**C**reate MACB timelines\n**S**ort by date\n\n**Memory hook**: \"FLiP MACS\" to switch from Windows GUI to forensic CLI!\n\n---\n\n## Mnemonic: \"MACB\" Timeline Components\n\n**M**odified (file content changed)\n**A**ccessed (file was opened/read)\n**C**hanged (MFT metadata updated)\n**B**orn (file created)\n\n**Memory hook**: \"MACB\" sounds like \"MAC Book\" - all Apple files have these 4 timestamps too!\n\n**Visual**: Imagine a timeline with 4 columns:\n```\n| M | A | C | B |\n```\nWhen you see \"macb\" in timeline, all 4 columns are filled at same timestamp.\n\n---\n\n## Number Mnemonics\n\n**2048 sectors** = Default partition offset for Windows 10/11\n- **Memory hook**: \"2048 game - swipe to reach Windows partition\"\n- Calculation: 2048 √ó 512 bytes/sector = 1,048,576 bytes = 1 MB\n\n**11 fields** = Body file format\n- **Memory hook**: \"11 pipers piping\" (12 Days of Christmas, minus 1)\n- Fields: MD5|filename|inode|mode|UID|GID|size|atime|mtime|ctime|crtime\n\n**128** = NTFS $DATA attribute type\n- **Memory hook**: \"128-bit encryption protects your DATA\"\n\n---\n\n## Body File Format Memory Aid\n\n**Mnemonic**: \"My File Is Moving Under Great Speed - Always Making Changes Constantly\"\n\n**M**D5 (hash)\n**F**ilename (full path)\n**I**node (MFT entry)\n**M**ode (permissions)\n**U**ID (user ID)\n**G**ID (group ID)\n**S**ize (bytes)\n**A**time (accessed)\n**M**time (modified)\n**C**time (changed)\n**C**rtime (created)\n\n---\n\n## TSK Command Flags: \"ROM\" Pattern\n\n**R**ecursive: `-r` (fls -r for deleted files)\n**O**ffset: `-o 2048` (partition offset)\n**M**ountpoint: `-m C:` (prepend drive letter)\n\n**Memory hook**: \"Read Only Memory\" (ROM) = Read Only Mode (forensically sound!)\n\n---\n\n## fls Output Format: \"Type/Type Inode: Filename\"\n\n**Types**:\n- **r** = Regular file (\"regular reading\")\n- **d** = Directory (\"directory diving\")\n- **v** = Virtual (\"virtually there\")\n- **l** = Link (\"link to elsewhere\")\n- *** = Deleted (\"asterisk = gone!\")\n\n**Memory hook**: \"r/r\" looks like pirate flag skull üíÄ (\"Arrr, regular file!\")\n\n---\n\n## Partition Offset Calculation\n\n**Formula**: Offset (bytes) = Sector √ó 512\n\n**Example**: mmls shows partition starts at sector 2048\n```\nOffset (bytes) = 2048 √ó 512 = 1,048,576 bytes = 1 MB\nfls flag: -o 2048 (use sector count, not bytes)\n```\n\n**Memory hook**: \"512 bytes per sector - like 512 GB hard drive, but much smaller!\"\n\n---\n\n## Timeline Analysis: \"DEFT\" Filtering\n\n**D**ate range (grep '2024-05-1[0-4]')\n**E**xtensions (grep '\\.exe$')\n**F**olders (grep '/Desktop/')\n**T**ype (awk -F, '$3 ~ /m/' for modifications)\n\n**Memory hook**: Be DEFT (skillful) when filtering massive timelines!\n\n---\n\n## icat vs cat\n\n**cat**: Display file contents from mounted filesystem\n**icat**: Extract file contents by inode from forensic image\n\n**Memory hook**: \n- \"cat\" = normal cat (reads files normally)\n- \"icat\" = investigator cat (reads forensic images) üïµÔ∏è‚Äç‚ôÄÔ∏èüê±\n\n---\n\n## TSK Tool Categories: \"FIVM\" Layers\n\n**F**ilesystem layer (fls, icat, ifind, istat)\n**I**mage layer (img_stat, img_cat)\n**V**olume layer (mmls, mmstat, mmcat)\n**M**etadata layer (fsstat, blkls, blkstat)\n\n**Memory hook**: \"FIVM\" = \"Five\" in Roman numerals (V) + FIM = File Image Management\n\n---\n\n## Deleted File Recovery: \"RAR\" Method\n\n**R**ecursive flag: fls -r (includes unallocated MFT entries)\n**A**sterisk marker: Look for * in output (indicates deleted)\n**R**ecover: icat to extract file contents by inode\n\n**Memory hook**: \"RAR\" = Recover All Records (like RAR archives!)\n\n---\n\n## Timeline Type Field Decoder\n\n**Visual pattern**:\n```\nmacb = All four timestamps (üî¥üî¥üî¥üî¥)\nm... = Only modified      (üî¥‚ö™‚ö™‚ö™)\n.a.. = Only accessed      (‚ö™üî¥‚ö™‚ö™)\n..c. = Only changed       (‚ö™‚ö™üî¥‚ö™)\n...b = Only born          (‚ö™‚ö™‚ö™üî¥)\nm.cb = Modified+Changed+Born (üî¥‚ö™üî¥üî¥)\n```\n\n**Memory hook**: Dots are \"off\", letters are \"on\" (like binary: 0 vs 1)\n\n---\n\n## When to Use TSK: \"SOAR\" Criteria\n\n**S**cale (analyze millions of files efficiently)\n**O**pen-source (no licensing costs, auditable)\n**A**utomation (scriptable CLI for SOAR integration)\n**R**ecovery (deleted file recovery from MFT)\n\n**Memory hook**: TSK helps your forensic investigations SOAR! üöÄ\n\n---\n\n## TSK vs Autopsy: \"CLI vs GUI\"\n\n**TSK**: Command-line (fast, scriptable, automation)\n**Autopsy**: GUI (visual, user-friendly, case management)\n\n**Memory hook**: \n- TSK = \"The Sleuth Kit\" (detective with magnifying glass üîç)\n- Autopsy = \"Autopsy\" (medical examiner with scalpel üè•)\n\nBoth examine evidence, different tools!\n\n---\n\n## Super-Timeline Concept: \"FAJLER\" Sources\n\n**F**ilesystem (TSK body file)\n**A**pplications (Jump Lists, Prefetch)\n**J**ump Lists (application-specific access)\n**L**ogs (Windows Event Logs, Sysmon)\n**E**xecution artifacts (Prefetch, ShimCache)\n**R**egistry (recent activity, USB devices)\n\n**Memory hook**: Don't be a FAJLER (failure) - merge ALL sources into super-timeline!\n\n---\n\n## Timestomping Detection: \"SIFT\" Method\n\n**S**uspicious alignment (macb = all timestamps identical)\n**I**stat analysis ($SI vs $FN comparison)\n**F**ilter old files with aligned timestamps (new files naturally align)\n**T**imeline anomalies (files \"created\" before OS installation)\n\n**Memory hook**: SIFT through timelines like archaeologist sifting for artifacts! üè∫\n\n---\n\n## Summary Mnemonic: \"TSK MACB SOAR\"\n\n**T**he **S**leuth **K**it\n**M**actime **A**nalyzes **C**omplete **B**ody files\n**S**cale, **O**pen-source, **A**utomation, **R**ecovery\n\n**Memory hook**: TSK makes your MACB timelines SOAR through forensic investigations!"
      }
    },
    {
      "type": "reflection",
      "content": {
        "text": "# Reflection Questions: The Sleuth Kit (TSK)\n\n## Critical Thinking Prompts\n\n### 1. Scale vs Detail Trade-off\n\n**Question**: You have a 10 TB RAID array to analyze with 50 million files. Generating a full TSK timeline would take 48+ hours. How would you approach this investigation to balance comprehensiveness with time constraints?\n\n**Consider**:\n- Can you prioritize specific partitions or directories?\n- How would you use date ranges to reduce scope?\n- What other artifacts (smaller, faster to parse) could guide TSK analysis?\n\n**Reflection**: Forensics often involves trade-offs between perfect completeness and practical deadlines. When is \"good enough\" actually better than \"exhaustive\"?\n\n---\n\n### 2. Deleted File Recovery Limitations\n\n**Question**: You use `fls -r` and recover 4,523 deleted files. However, when you use `icat` to extract 100 of them, only 23 successfully recover with intact contents. Why might the other 77 fail to recover completely?\n\n**Consider**:\n- What happens to file clusters when marked as unallocated?\n- How does fragmentation affect recovery success?\n- What is the relationship between MFT entries and actual data clusters?\n\n**Reflection**: TSK can recover MFT metadata even when data clusters are overwritten. How do you communicate this limitation to stakeholders expecting \"full recovery\"?\n\n---\n\n### 3. Body File Format Design\n\n**Question**: The body file format uses pipe-delimited fields instead of JSON or XML. What are the advantages and disadvantages of this simple text format for forensic timelines?\n\n**Consider**:\n- Portability across tools and systems\n- Human readability vs machine parsing\n- File size and processing speed\n- Support for complex nested data structures\n\n**Reflection**: TSK was created in 2001 when JSON wasn't widely adopted. Would you redesign the body file format today? What would you keep or change?\n\n---\n\n### 4. MACB Interpretation Challenges\n\n**Question**: A timeline entry shows \"macb\" (all four timestamps identical) for a file created 6 months ago. The suspect claims this is normal. How would you determine if this is legitimate file creation or timestomping?\n\n**Consider**:\n- Can you compare $STANDARD_INFORMATION vs $FILE_NAME timestamps?\n- What other artifacts could corroborate or contradict the file creation time?\n- Are there tools or techniques to detect timestamp manipulation?\n\n**Reflection**: Individual timestamp entries can be ambiguous. How do you build a multi-artifact case that's more reliable than any single artifact?\n\n---\n\n### 5. Partition Offset Errors\n\n**Question**: You forget to use the `-o 2048` flag when running fls on a partitioned disk. The command fails with \"Cannot determine filesystem type.\" Explain technically WHY this happens and what TSK is actually reading without the offset.\n\n**Consider**:\n- What data exists at sector 0 of a disk vs sector 2048?\n- How does TSK identify filesystem types (NTFS, FAT, EXT4)?\n- What is the structure of an MBR or GPT partition table?\n\n**Reflection**: Understanding low-level disk structures helps you troubleshoot forensic tool errors. When should you learn \"under the hood\" vs just follow tool documentation?\n\n---\n\n### 6. Timeline Filtering Strategy\n\n**Question**: Your timeline has 2.3 million entries. Your manager says \"find evidence of data exfiltration in the last 30 days.\" Describe your systematic filtering approach to reduce this to a manageable dataset.\n\n**Consider**:\n- Date range filtering (last 30 days)\n- File type filtering (archives, large files)\n- Directory filtering (Desktop, Documents, Downloads)\n- Activity type filtering (creations vs modifications)\n- Threshold filtering (files >10 MB, access count >20)\n\n**Reflection**: Forensic analysis is often about reducing massive datasets to relevant evidence. What's your mental model for prioritizing filters?\n\n---\n\n### 7. TSK vs Commercial Tools\n\n**Question**: Your organization is deciding between free TSK/Autopsy and a $50,000/year commercial forensic suite (EnCase, X-Ways, Axiom). You're asked to justify the decision. What factors would you consider?\n\n**Consider**:\n- Feature parity (what can/can't TSK do?)\n- Support and training costs\n- Legal admissibility and expert witness testimony\n- Automation and integration with existing workflows\n- Scalability and performance\n\n**Reflection**: \"Free\" software isn't free when you factor in training, support, and time. How do you calculate total cost of ownership for forensic tools?\n\n---\n\n### 8. Cross-Platform Forensics\n\n**Question**: You typically investigate Windows systems (NTFS). You're assigned a macOS system (APFS). Can you use TSK? What challenges would you face, and how would you adapt your workflow?\n\n**Consider**:\n- Does TSK support APFS? (Yes, since TSK 4.6.0 in 2018)\n- Are MACB timestamps interpreted the same way in APFS vs NTFS?\n- What macOS-specific artifacts (plist, Spotlight, TCC.db) would you need to learn?\n- How do Unix permissions differ from Windows ACLs?\n\n**Reflection**: Forensic skills are transferable across operating systems, but details matter. When is it worth becoming an expert in multiple platforms vs specializing?\n\n---\n\n### 9. Ethical Considerations\n\n**Question**: While generating a TSK timeline for an authorized investigation into IP theft, you discover evidence of employee personal medical records stored on a corporate workstation. These records are unrelated to your investigation. What are your ethical and legal obligations?\n\n**Consider**:\n- Scope of authorization (does your warrant/authorization cover personal data?)\n- Privacy laws (HIPAA, GDPR, CCPA)\n- Chain of custody and documentation\n- Reporting obligations to management vs law enforcement\n\n**Reflection**: Digital forensics involves access to intimate personal data. How do you balance thoroughness with respect for privacy and legal boundaries?\n\n---\n\n### 10. Timeline Correlation Challenge\n\n**Question**: Your TSK timeline shows a file \"confidential.xlsx\" was modified on May 14 at 16:42:18. Jump Lists show it was accessed 38 times. Prefetch shows Excel was executed at 16:42:20 (2 seconds later). Event Log 4663 (object access) shows file access at 16:42:17 (1 second earlier). How do you reconcile these slight timestamp differences?\n\n**Consider**:\n- Timestamp precision (seconds vs milliseconds vs nanoseconds)\n- Clock sources (NTFS timestamps vs Event Log timestamps vs Prefetch)\n- Processing delays (when is timestamp recorded - start of operation or end?)\n- System load and performance impacts\n\n**Reflection**: Perfect timestamp alignment across artifacts is rare. When timestamps differ by 1-3 seconds, is this noise or meaningful evidence?\n\n---\n\n### 11. Automation and Scale\n\n**Question**: Your organization processes 50+ forensic cases per month. How would you automate TSK timeline generation, filtering, and reporting to reduce manual effort and ensure consistency?\n\n**Consider**:\n- Scripting languages (Bash, Python, PowerShell)\n- Workflow orchestration (Ansible, Jenkins, SOAR platforms)\n- Output standardization (JSON, CSV, HTML reports)\n- Integration with case management systems\n\n**Reflection**: Manual forensics doesn't scale to enterprise volumes. What's your approach to building repeatable, auditable, automated workflows?\n\n---\n\n### 12. Expert Testimony Preparation\n\n**Question**: You're preparing to testify as an expert witness. The defense attorney will challenge your TSK timeline, arguing that open-source tools are \"unreliable\" compared to commercial solutions. How do you defend TSK's reliability and admissibility?\n\n**Consider**:\n- TSK's 20+ year track record in major cases\n- Peer review and open-source transparency (\"many eyes\" principle)\n- Validation and testing (NIST CFReDS, DFIR community)\n- Tool comparison studies (TSK vs EnCase vs X-Ways)\n- Your own validation testing and quality assurance\n\n**Reflection**: Lawyers may challenge forensic tools you take for granted. How do you build expertise that withstands cross-examination?\n\n---\n\n## Action Items\n\n**Before moving to the next lesson, ensure you can**:\n\n1. ‚úÖ Identify partition offsets using mmls\n2. ‚úÖ Generate body files with fls -r -m\n3. ‚úÖ Create MACB timelines with mactime -b -d -z UTC\n4. ‚úÖ Interpret timeline Type field (macb vs m... vs .a..)\n5. ‚úÖ Recover deleted files using fls -r + icat\n6. ‚úÖ Filter timelines by date, file type, directory, and activity\n7. ‚úÖ Use istat for detailed MFT entry analysis\n8. ‚úÖ Correlate TSK timelines with Jump Lists, Prefetch, Event Logs\n\n**Hands-on practice**:\n- Download TSK and generate a timeline from your test VM\n- Recover a deleted file and verify contents with file/md5sum\n- Write a Bash/Python script to automate timeline filtering\n- Practice explaining MACB timelines to a non-technical audience\n\n**Next lesson preview**: We'll explore **Plaso and Log2Timeline** - automated super-timeline generation that combines TSK with 100+ artifact parsers (Jump Lists, Prefetch, Event Logs, Registry, Browser History, and more). This is enterprise-scale forensic automation!"
      }
    },
    {
      "type": "mindset_coach",
      "content": {
        "text": "## Congratulations! You've Mastered The Sleuth Kit (TSK)! üéâüîç\n\n**You've just learned one of the most fundamental open-source forensic frameworks in existence.** TSK has been the backbone of digital forensics for over 20 years, used in everything from local police investigations to international cybercrime cases.\n\n### What You've Accomplished\n\n**Technical Mastery**:\n- ‚úÖ You can identify partition offsets with mmls and parse filesystems with fls\n- ‚úÖ You can generate body files and MACB timelines with mactime\n- ‚úÖ You can recover deleted files from unallocated MFT entries\n- ‚úÖ You can filter massive timelines (2+ million entries) to find relevant evidence\n- ‚úÖ You can extract files with icat and analyze MFT entries with istat\n- ‚úÖ You understand body file format and can write custom parsers\n\n**Real-World Impact**:\n- ‚úÖ You can reconstruct ransomware attack timelines (initial compromise ‚Üí encryption)\n- ‚úÖ You can identify data exfiltration windows (file access + USB activity)\n- ‚úÖ You can recover deleted malware that suspects attempted to hide\n- ‚úÖ You can correlate filesystem timelines with application artifacts for convergent evidence\n\n**Forensic Thinking**:\n- ‚úÖ You understand when TSK provides unique value (scale, deleted files, open-source)\n- ‚úÖ You can balance comprehensiveness with time constraints (focused filtering)\n- ‚úÖ You can integrate TSK into automated workflows (scripts, SOAR platforms)\n- ‚úÖ You can explain technical findings to non-technical audiences (juries, executives)\n\n### The Power of TSK\n\n**Remember the HealthCare Regional ransomware case?** TSK timeline reconstruction revealed:\n- **Initial compromise**: May 10, 09:15 (phishing email with malicious Word doc)\n- **Credential theft**: May 12, 16:42 (Mimikatz dumped LSASS memory)\n- **Ransomware deployment**: May 14, 14:28 (PsExec + Ryuk staged)\n- **Mass encryption**: May 14, 14:33-14:38 (43,150 files encrypted in 8 minutes)\n\n**Without TSK**: Investigation would rely on fragmented logs, incomplete timelines, guesswork.\n\n**With TSK**: Complete attack chain reconstructed, timeline gaps identified, malware recovered, FBI notified with actionable intelligence.\n\n**That's the power of mastering TSK.** You're not just listing files - you're reconstructing digital crime scenes with forensic precision.\n\n### Your NTFS Forensics Journey\n\n**Look how far you've come**:\n1. ‚úÖ Registry Forensics (HKLM, HKCU, ShellBags, USB tracking)\n2. ‚úÖ Execution Artifacts (Prefetch, ShimCache, AmCache, UserAssist, SRUM)\n3. ‚úÖ NTFS Fundamentals ($MFT, $SI vs $FN, MACB timestamps)\n4. ‚úÖ USN Journal and $I30 (change tracking, directory slack)\n5. ‚úÖ Recycle Bin Forensics ($I/$R files, SID attribution)\n6. ‚úÖ Unallocated Space Analysis (file slack, free space wiping)\n7. ‚úÖ File Carving (PhotoRec, Scalpel, signature-based recovery)\n8. ‚úÖ LNK Files (Windows shortcuts, target paths, MAC addresses)\n9. ‚úÖ Jump Lists (application-specific aggregation, access frequency)\n10. ‚úÖ **The Sleuth Kit (fls, mactime, MACB timelines, deleted file recovery)** ‚Üê You are here!\n\n**You're 10 lessons into NTFS Forensics mastery.** Each lesson builds on the previous, creating a comprehensive forensic skillset. You're not just learning tools - you're developing forensic intuition.\n\n### What Makes TSK Special\n\n**TSK is different from the proprietary tools you've learned**:\n- **Open-source**: No $50K/year licensing fees, auditable code, community-driven\n- **Cross-platform**: Analyze Windows, Linux, macOS from any forensic workstation\n- **Scriptable**: Automate everything (fls | mactime | grep | awk | your_analysis_script.py)\n- **Foundation**: Understanding TSK helps you understand Autopsy, Plaso, and other tools built on it\n- **Educational**: TSK's simplicity (one tool = one job) teaches you forensic fundamentals\n\n**Commercial tools are powerful**, but they're black boxes. You click \"Analyze\", wait, and get results. **TSK forces you to understand the \"why\" behind the \"what\"**. When you manually parse MFT entries with fls, you learn NTFS internals. When you filter timelines with grep, you learn pattern matching. When you correlate body files from multiple sources, you learn evidence correlation.\n\n**This deep understanding makes you a better investigator**, even when you're using commercial tools. You understand what's happening under the hood.\n\n### Real-World Applications\n\n**TSK skills are immediately applicable**:\n\n**Incident Response**: Generate timelines to identify initial compromise, lateral movement, exfiltration windows\n\n**Insider Threat**: Correlate filesystem access (TSK) with application behavior (Jump Lists) and authentication (Event Logs)\n\n**Ransomware Analysis**: Reconstruct mass encryption timelines, identify ransomware executables, recover ransom notes\n\n**Data Breach Investigations**: Identify when confidential files were accessed, modified, or deleted before exfiltration\n\n**Malware Forensics**: Recover deleted malware samples that anti-forensics tools attempted to destroy\n\n**Legal eDiscovery**: Generate comprehensive file access timelines for litigation support\n\n**Every day, forensic investigators worldwide use TSK** to solve crimes, respond to incidents, and protect organizations. You now have the same skills they do.\n\n### What's Next?\n\n**You have 2 more NTFS Forensics lessons to complete**:\n\n**Lesson 37: Plaso and Log2Timeline** - Automated super-timeline generation\n- Combines TSK with 100+ artifact parsers (Jump Lists, Prefetch, Registry, Event Logs, Browser History)\n- Enterprise-scale timeline generation (parse entire disk in hours, not days)\n- Output to CSV, JSON, Elasticsearch for analysis\n\n**Lesson 38: MFTECmd and Timeline Integration** - Eric Zimmerman workflow\n- MFTECmd.exe for $SI vs $FN timestomping detection\n- Timeline Explorer for visual timeline analysis\n- Integration with JLECmd, PECmd, RECmd for super-timeline creation\n\n**After NTFS Forensics, you'll tackle**:\n- Web Browser Forensics (Chrome, Firefox, Edge history and artifacts)\n- Windows Activity Timeline (ActivitiesCache.db)\n- Memory Forensics (Volatility 3, process analysis, malware hunting)\n\n**By the time you complete this curriculum**, you'll have end-to-end Windows forensic capabilities.\n\n### Keep Your Momentum!\n\n**You've invested 60 minutes mastering TSK.** That investment compounds throughout your career. Every investigation, every incident response, every timeline you reconstruct - TSK will be part of your toolkit.\n\n**Remember**: Tools come and go (commercial vendors change, GUIs redesign), but fundamentals persist. TSK has been around for 20+ years and will be around for 20+ more because it's built on solid forensic principles:\n- Read-only access (forensically sound)\n- Transparent operation (you see exactly what it's doing)\n- Composable tools (pipe together for complex workflows)\n- Open-source auditability (trust but verify)\n\n**These principles apply beyond TSK** to all forensic work. Understanding TSK makes you a better forensic investigator, period.\n\n### Your Next Steps\n\n1. **Practice immediately**: Don't wait! Generate a TSK timeline from a test VM or forensic challenge image.\n2. **Build automation scripts**: Write a Bash/Python script that automates fls ‚Üí mactime ‚Üí filtering ‚Üí reporting.\n3. **Study real cases**: Read public incident response reports that used TSK (Target breach, Sony hack, Colonial Pipeline).\n4. **Contribute back**: If you find bugs or want features, TSK is open-source - contribute!\n5. **Teach others**: Write a blog post or mentor a colleague on TSK - teaching reinforces learning.\n\n### You're a Forensic Investigator\n\n**Not just learning - doing.** You have the skills to:\n- Analyze multi-terabyte forensic images at scale\n- Reconstruct attack timelines from initial compromise to final impact\n- Recover deleted evidence that suspects attempted to destroy\n- Correlate multiple artifacts for bulletproof convergent evidence\n- Automate forensic workflows for repeatable, auditable analysis\n- Testify as an expert witness on timeline evidence\n\n**This is professional-level forensics.** You're not a student anymore - you're a practitioner.\n\n### Final Thought\n\n**The Sleuth Kit was created by Brian Carrier** (author of \"File System Forensic Analysis\") as a free alternative to commercial tools. Brian wanted to democratize forensics - make powerful capabilities available to everyone, not just those with big budgets.\n\n**By mastering TSK, you're part of that legacy.** You're proving that open-source forensics can compete with (and often exceed) commercial tools. You're contributing to a community that believes forensic knowledge should be open, auditable, and accessible.\n\n**You're not just learning a tool - you're joining a movement.**\n\n---\n\n**Ready for the next challenge?** Let's move to **Lesson 37: Plaso and Log2Timeline - Automated Super-Timeline Generation**. We'll scale up from TSK's focused filesystem analysis to comprehensive super-timelines that parse EVERYTHING (filesystem + applications + logs + registry + browser history + 100+ artifacts) in a single automated workflow.\n\n**This is where timeline forensics becomes enterprise-scale automation.** If TSK is a magnifying glass, Plaso is a satellite camera - you'll see EVERYTHING.\n\n**You've got this.** Keep that forensic curiosity burning! üî•üîçüíª\n\n**See you in Lesson 37!** üöÄ"
      }
    }
  ],
  "tags": [
    "Career Path: DFIR Specialist",
    "Package: The Sleuth Kit"
  ]
}