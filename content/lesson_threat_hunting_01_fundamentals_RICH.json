{
  "lesson_id": "24eabbbe-c11b-4deb-aaed-4247c94353df",
  "domain": "threat_hunting",
  "title": "Threat Hunting Fundamentals",
  "difficulty": 1,
  "order_index": 1,
  "prerequisites": [],
  "concepts": [
    "Threat hunting vs detection engineering",
    "Hypothesis-driven hunting",
    "MITRE ATT&CK framework",
    "Hunt metrics and ROI",
    "Threat hunting program structure",
    "Hunt team roles and responsibilities"
  ],
  "estimated_time": 45,
  "learning_objectives": [
    "Understand the difference between threat hunting and traditional detection",
    "Learn hypothesis-driven hunting methodology",
    "Master MITRE ATT&CK framework for threat hunting",
    "Define hunt metrics and measure program success",
    "Build a threat hunting program from scratch",
    "Understand hunt team structure and responsibilities"
  ],
  "post_assessment": [
    {
      "question": "What is the key difference between threat hunting and traditional detection?",
      "options": [
        "Hunting is automated, detection is manual",
        "Hunting is proactive and hypothesis-driven, detection is reactive",
        "Hunting only uses logs, detection uses network traffic",
        "There is no difference"
      ],
      "correct_answer": 1,
      "difficulty": 1,
      "type": "multiple_choice",
      "question_id": "a16faffc-f69b-4541-a705-9a1090b137fc",
      "explanation": "Explanation not provided."
    },
    {
      "question": "In the MITRE ATT&CK framework, what does TTP stand for?",
      "options": [
        "Time To Patch",
        "Tactics, Techniques, and Procedures",
        "Threat Type Profile",
        "Total Target Points"
      ],
      "correct_answer": 1,
      "difficulty": 1,
      "type": "multiple_choice",
      "question_id": "f605cf05-2fda-463a-9151-2bdf2cc7622c",
      "explanation": "Explanation not provided."
    },
    {
      "question": "What is the first step in hypothesis-driven threat hunting?",
      "options": [
        "Deploy new detection rules",
        "Run automated scans",
        "Formulate a testable hypothesis based on threat intelligence",
        "Review all system logs"
      ],
      "correct_answer": 2,
      "difficulty": 2,
      "type": "multiple_choice",
      "question_id": "100a1c5a-3114-4826-8404-63b439cf2252",
      "explanation": "Explanation not provided."
    }
  ],
  "jim_kwik_principles": [
    "active_learning",
    "meta_learning",
    "minimum_effective_dose",
    "teach_like_im_10",
    "memory_hooks",
    "connect_to_what_i_know",
    "reframe_limiting_beliefs",
    "gamify_it",
    "learning_sprint",
    "multiple_memory_pathways"
  ],
  "content_blocks": [
    {
      "type": "explanation",
      "content": {
        "text": "# Welcome to Threat Hunting\n\nYou're about to enter one of the most exciting and proactive areas of cybersecurity: **threat hunting**. While traditional security focuses on responding to alerts, threat hunters actively search for adversaries hiding in the environment.\n\n## What is Threat Hunting?\n\nThreat hunting is the **proactive and iterative search** through networks, endpoints, and datasets to detect threats that evade existing security solutions. Instead of waiting for alerts, hunters assume compromise and actively look for indicators of malicious activity.\n\n### Threat Hunting vs Detection Engineering\n\n**Traditional Detection (Reactive)**:\n- Waits for alerts from SIEM, IDS, EDR\n- Responds to known signatures and rules\n- Often generates false positives\n- Defensive posture\n\n**Threat Hunting (Proactive)**:\n- Assumes breach has already occurred\n- Searches for unknown threats\n- Hypothesis-driven investigation\n- Offensive-defensive mindset\n\n**Detection Engineering (Systematic)**:\n- Creates and tunes detection rules\n- Converts hunt findings into automated detections\n- Reduces false positives\n- Builds detection coverage\n\n**Think of it this way**: Detection engineering builds the alarm system, threat hunting is the security guard actively patrolling the building, and incident response is what happens when the alarm goes off.\n\n## The Threat Hunting Mindset\n\nSuccessful threat hunters think like adversaries:\n\n1. **Assume Breach**: The attacker is already inside\n2. **Think Creatively**: What would *I* do if I were the attacker?\n3. **Question Everything**: Don't trust \"normal\" - validate it\n4. **Follow the Data**: Let evidence guide your investigation\n5. **Document Findings**: Every hunt teaches you something\n\n### Real-World Context\n\nIn 2013, Target was breached via an HVAC vendor. The attackers had access for **19 days** before being discovered. FireEye alerts were generated but **ignored**. A proactive threat hunting program could have discovered the breach days earlier, preventing the theft of 40 million credit cards.\n\n**Average dwell time** (time attackers remain undetected):\n- Global average: **21 days** (2023)\n- APT groups: **60-90 days**\n- Some breaches go undetected for **years**\n\nThreat hunting reduces dwell time by finding adversaries *before* they complete their mission."
      }
    },
    {
      "type": "explanation",
      "content": {
        "text": "## The Hypothesis-Driven Hunt Process\n\nThreat hunting follows a scientific method:\n\n### 1. Develop Hypothesis\n\nStart with a testable assumption based on:\n- **Threat intelligence**: \"APT29 uses WMI for lateral movement\"\n- **Environmental knowledge**: \"Our finance department is a high-value target\"\n- **Adversary TTPs**: \"Attackers abuse PowerShell for execution\"\n- **Anomalies**: \"Unusual spike in DNS queries\"\n\n**Example Hypotheses**:\n- \"If an attacker has compromised our environment, they would use WMI for lateral movement\"\n- \"If ransomware operators are active, they would disable backup services\"\n- \"If data exfiltration is occurring, we would see large uploads during off-hours\"\n\n### 2. Gather Data\n\nCollect relevant data sources:\n- Windows Event Logs (Security, System, Sysmon)\n- Network traffic (NetFlow, Zeek, PCAP)\n- EDR telemetry\n- Proxy logs\n- DNS logs\n- Authentication logs\n\n### 3. Analyze\n\nUse tools and techniques:\n- **Splunk/ELK queries**: Search for indicators\n- **Visualization**: Timeline analysis, network graphs\n- **Statistical analysis**: Identify outliers and anomalies\n- **Threat intelligence**: Enrich findings with IOCs\n\n### 4. Investigate\n\nDeep dive into suspicious findings:\n- Validate true positives vs false positives\n- Expand scope (what else is related?)\n- Build attack timeline\n- Determine impact\n\n### 5. Respond\n\nTake action:\n- **If threat found**: Escalate to incident response\n- **If benign**: Document for future reference\n- **Create detection**: Convert findings into automated rule\n\n### 6. Document\n\nCapture lessons learned:\n- What hypothesis was tested?\n- What data sources were used?\n- What was found (or not found)?\n- What detections were created?\n- What would you do differently?\n\n### The Hunt Loop\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   1. HYPOTHESIS                     â”‚\nâ”‚   \"APT uses WMI for lateral move\"   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n               â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   2. DATA COLLECTION                â”‚\nâ”‚   Sysmon Event ID 19, 20, 21        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n               â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   3. ANALYSIS                       â”‚\nâ”‚   Search for WMI event subscriptionsâ”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n               â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   4. INVESTIGATION                  â”‚\nâ”‚   Found suspicious WMI persistence  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n               â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   5. RESPONSE                       â”‚\nâ”‚   IR escalation + create detection  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n               â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   6. DOCUMENT & REFINE              â”‚\nâ”‚   Update playbook, new hypotheses   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```"
      }
    },
    {
      "type": "explanation",
      "content": {
        "text": "## MITRE ATT&CK Framework for Threat Hunting\n\nThe **MITRE ATT&CK** (Adversarial Tactics, Techniques, and Common Knowledge) framework is a knowledge base of adversary behaviors. It's essential for threat hunting.\n\n### ATT&CK Structure\n\n**Tactics** (The \"Why\") - Adversary goals:\n1. Reconnaissance\n2. Resource Development\n3. Initial Access\n4. Execution\n5. Persistence\n6. Privilege Escalation\n7. Defense Evasion\n8. Credential Access\n9. Discovery\n10. Lateral Movement\n11. Collection\n12. Command and Control\n13. Exfiltration\n14. Impact\n\n**Techniques** (The \"How\") - Methods to achieve tactics\n- Example: \"T1003 - OS Credential Dumping\"\n\n**Sub-Techniques** (Specific implementations)\n- Example: \"T1003.001 - LSASS Memory\"\n\n**Procedures** (Real-world usage)\n- Example: \"APT29 uses Mimikatz to dump LSASS\"\n\n### Using ATT&CK for Hunting\n\n**1. Technique-Based Hunts**\n\nPick a technique and hunt for it:\n- **T1053.005 - Scheduled Task/Job**: Search for suspicious scheduled tasks\n- **T1218.011 - Rundll32**: Hunt for unusual DLL executions\n- **T1021.002 - SMB/Windows Admin Shares**: Look for lateral movement via SMB\n\n**2. Tactic-Based Coverage**\n\nEnsure you have hunts covering all tactics:\n- \"Have we hunted for persistence this month?\"\n- \"When did we last hunt for credential access?\"\n\n**3. Threat Actor Profiling**\n\nUse ATT&CK Navigator to see which techniques specific APT groups use:\n- **APT29 (Cozy Bear)**: PowerShell, WMI, Scheduled Tasks\n- **APT28 (Fancy Bear)**: Credential dumping, Outlook rules\n- **Lazarus Group**: DLL side-loading, registry persistence\n\n**4. Coverage Gap Analysis**\n\nIdentify techniques you *cannot* detect:\n- Do you log WMI events?\n- Can you see PowerShell command-line arguments?\n- Are you monitoring scheduled tasks?\n\n### ATT&CK Hunting Workflow\n\n```\n1. Select technique from ATT&CK (e.g., T1003 - Credential Dumping)\n   â†“\n2. Read data sources needed (Process monitoring, API calls)\n   â†“\n3. Formulate hypothesis (\"If Mimikatz ran, we'd see LSASS access\")\n   â†“\n4. Build search query (Sysmon Event ID 10: TargetImage=lsass.exe)\n   â†“\n5. Execute hunt and analyze results\n   â†“\n6. Document findings and create detection rule\n```\n\n**Memory Aid**: **TAP** - Tactics, Techniques, Procedures\n- **Tactics** = What they want (persistence)\n- **Techniques** = How they do it (scheduled task)\n- **Procedures** = Specific implementation (schtasks.exe /create)"
      }
    },
    {
      "type": "explanation",
      "content": {
        "text": "## Building a Threat Hunting Program\n\n### Program Maturity Levels\n\n**Level 0 - Initial (No Hunting)**\n- Relies only on automated alerts\n- Reactive security posture\n- No dedicated hunt resources\n\n**Level 1 - Ad Hoc (Sporadic Hunting)**\n- Occasional manual searches\n- Hypothesis-driven by senior analysts\n- No formal process or documentation\n- Limited tool availability\n\n**Level 2 - Procedural (Defined Process)**\n- Regular hunt cadence (weekly/monthly)\n- Documented hunt playbooks\n- Dedicated hunt tools (Splunk, EDR queries)\n- Basic metrics tracking\n\n**Level 3 - Innovative (Advanced Hunting)**\n- Automated hunt workflows\n- Machine learning for anomaly detection\n- Threat intelligence integration\n- Continuous hypothesis generation\n\n**Level 4 - Leading (Proactive Defense)**\n- Real-time hunting automation\n- Predictive threat modeling\n- Red/purple team integration\n- Industry-leading detection coverage\n\n### Hunt Team Structure\n\n**Small Organization (1-5 people)**:\n- **Threat Hunter** (generalist): Conducts hunts, creates detections\n- **Detection Engineer**: Builds and tunes SIEM rules\n- Reports to SOC Manager or CISO\n\n**Medium Organization (5-15 people)**:\n- **Hunt Team Lead**: Prioritizes hunts, manages team\n- **Threat Hunters** (2-5): Execute hunts\n- **Detection Engineers** (2-3): Convert findings to detections\n- **Threat Intelligence Analyst**: Provides hunt leads\n\n**Large Organization (15+ people)**:\n- **Hunt Manager**: Strategic direction\n- **Hunt Team Leads** (by domain): Network, endpoint, cloud\n- **Threat Hunters** (specialized): APT hunters, malware analysts\n- **Detection Engineers**: Automation and SOAR integration\n- **Threat Intel Team**: Dedicated intelligence feeds\n\n### Essential Hunt Team Skills\n\n1. **Log Analysis**: Read and query logs (Splunk, ELK, Sentinel)\n2. **Network Analysis**: Understand protocols, packet captures\n3. **Endpoint Forensics**: Memory analysis, process investigation\n4. **Scripting**: Python, PowerShell for automation\n5. **Threat Intelligence**: IOC analysis, adversary profiling\n6. **Communication**: Document findings clearly\n\n### Hunt Program Components\n\n**1. Hunt Mission Statement**\n\nExample:\n> \"Proactively identify and mitigate threats that evade existing security controls, reducing organizational risk and improving detection capabilities.\"\n\n**2. Hunt Scope**\n\nDefine what you hunt:\n- **In Scope**: Corporate network, endpoints, cloud infrastructure\n- **Out of Scope**: Guest WiFi, development environments\n\n**3. Hunt Cadence**\n\n- **Continuous**: 24/7 automated hunting\n- **Scheduled**: Weekly/bi-weekly hypothesis-driven hunts\n- **Event-Driven**: Triggered by new threat intel or incidents\n\n**4. Data Sources**\n\nEnsure access to:\n- Endpoint logs (Windows Event Logs, Sysmon, EDR)\n- Network logs (NetFlow, DNS, proxy, firewall)\n- Authentication logs (AD, VPN, cloud SSO)\n- Application logs (databases, web servers)\n\n**5. Tooling**\n\n- **SIEM**: Splunk, Elastic, Microsoft Sentinel\n- **EDR**: CrowdStrike, Carbon Black, Microsoft Defender ATP\n- **Threat Intel Platforms**: MISP, ThreatConnect\n- **Forensics**: Volatility, Velociraptor, KAPE\n- **Custom Scripts**: Python, PowerShell\n\n**6. Documentation**\n\n- **Hunt Playbooks**: Step-by-step hunt procedures\n- **Hunt Reports**: Findings, recommendations, lessons learned\n- **Detection Library**: Automated rules created from hunts"
      }
    },
    {
      "type": "explanation",
      "content": {
        "text": "## Hunt Metrics and ROI\n\nHow do you measure hunt program success?\n\n### Key Performance Indicators (KPIs)\n\n**1. Dwell Time Reduction**\n- Average time from compromise to detection\n- **Target**: < 24 hours for critical assets\n- Industry average: 21 days\n\n**2. Hunt Efficiency**\n- **Number of hunts conducted** per month\n- **Time per hunt**: How long does each hunt take?\n- **Target**: 4-8 hypothesis-driven hunts per month per hunter\n\n**3. True Positive Rate**\n- **Threats discovered**: How many real threats did hunting uncover?\n- **False positive rate**: How many hunts resulted in benign findings?\n- **Target**: > 30% hunts should yield actionable findings\n\n**4. Detection Coverage**\n- **New detections created**: Rules added to SIEM/EDR from hunt findings\n- **ATT&CK coverage**: % of techniques you can detect\n- **Target**: Cover 70%+ of techniques relevant to your threat model\n\n**5. Mean Time to Detect (MTTD)**\n- How quickly do you find threats after compromise?\n- **Baseline**: Before hunting program\n- **Target**: 50% reduction in MTTD within 6 months\n\n**6. Incident Escalations**\n- **Hunts escalated to IR**: How many hunts became incidents?\n- **Severity of findings**: Critical, high, medium, low\n- **Target**: Find at least 2-4 real incidents per quarter through hunting\n\n### Reporting Hunt Value\n\n**Monthly Hunt Report Template**:\n\n```\n============================================\nTHREAT HUNT MONTHLY REPORT - [Month Year]\n============================================\n\nEXECUTIVE SUMMARY:\n- Hunts conducted: 12\n- Threats discovered: 3 (2 high severity, 1 medium)\n- New detections created: 8\n- Average dwell time: 4 days (down from 18 days)\n\nKEY FINDINGS:\n1. Mimikatz execution discovered on finance workstation\n   - Impact: Credential theft prevented\n   - Remediation: Host isolated, credentials reset\n   \n2. Cobalt Strike beacon detected via DNS tunneling\n   - Impact: C2 communication blocked\n   - Remediation: Firewall rule added\n\nDETECTIONS CREATED:\n- Sysmon Event ID 10 (LSASS access) detection rule\n- DNS query length anomaly detection\n- Unusual PowerShell execution patterns\n\nNEXT MONTH FOCUS:\n- Hunt for lateral movement via RDP\n- Investigate cloud infrastructure for persistence\n- Purple team exercise with red team\n```\n\n### ROI Calculation\n\n**Cost of Threat Hunting**:\n- Hunter salary: $120K/year\n- Tools (SIEM, EDR): $50K/year\n- Training: $10K/year\n- **Total**: ~$180K/year per hunter\n\n**Value of Threat Hunting**:\n- Average data breach cost: **$4.45 million** (IBM 2023)\n- Cost per day of breach: ~$150K-200K\n- If hunting reduces dwell time by **15 days**: **$2.25-3 million saved**\n\n**ROI**: If hunting prevents **one** major breach, it pays for itself **10x over**.\n\n**Additional Value**:\n- Improved detection coverage (fewer alert gaps)\n- Reduced false positives (better-tuned detections)\n- Enhanced analyst skills (hunters become better defenders)\n- Threat intelligence generation (share findings with community)"
      }
    },
    {
      "type": "memory_aid",
      "content": {
        "text": "## Memory Aids for Threat Hunting\n\n### HDDDIR - The Hunt Process\n\n**H** - **Hypothesis**: Start with a testable assumption\n**D** - **Data**: Gather relevant logs and telemetry\n**D** - **Dig**: Analyze data for indicators\n**D** - **Discover**: Investigate findings\n**I** - **Intervene**: Respond and remediate\n**R** - **Record**: Document lessons learned\n\n### PHAR - Hunting Mindset\n\n**P** - **Proactive**: Don't wait for alerts\n**H** - **Hypothesis-driven**: Test assumptions\n**A** - **Assume breach**: Attackers are already inside\n**R** - **Refine**: Continuous improvement\n\n### TAP - ATT&CK Framework\n\n**T** - **Tactics**: What adversaries want (persistence, exfiltration)\n**A** - **Techniques**: How they do it (scheduled tasks, DNS tunneling)\n**P** - **Procedures**: Specific tools/methods (Mimikatz, Cobalt Strike)\n\n### The 3 Cs of Hunt Data\n\n**C** - **Collect**: Gather comprehensive logs\n**C** - **Correlate**: Connect related events\n**C** - **Context**: Enrich with threat intelligence\n\n### Visual: The Hunter's Timeline\n\n```\n[Threat Actor Entry] â”€â”€â†’ [Compromise] â”€â”€â†’ [Dwell Time] â”€â”€â†’ [Detection]\n        Day 0                Day 1           Day 2-21        Day 21+\n                                â†‘\n                    [THREAT HUNTING REDUCES THIS]\n```"
      }
    },
    {
      "type": "real_world",
      "content": {
        "text": "## Real-World Threat Hunting Success Stories\n\n### Case Study 1: The Target Breach (What Went Wrong)\n\n**Background**: In 2013, Target suffered a massive breach affecting 40 million credit cards.\n\n**What Happened**:\n- Attackers entered via HVAC vendor credentials\n- FireEye generated alerts: **Ignored by SOC**\n- Malware uploaded to POS systems for **19 days**\n- Data exfiltration went undetected\n\n**What Threat Hunting Could Have Done**:\n1. **Hypothesis**: \"If attackers compromise vendor access, they'll move laterally to high-value systems\"\n2. **Hunt**: Search for lateral movement from vendor network segment\n3. **Detection**: Unusual connections from HVAC segment to POS network\n4. **Response**: Block lateral movement, isolate compromised systems\n\n**Lesson**: Proactive hunting could have detected the breach **days earlier**, preventing massive data theft.\n\n### Case Study 2: SolarWinds Supply Chain Attack\n\n**Background**: APT29 (Cozy Bear) compromised SolarWinds Orion, affecting 18,000+ organizations.\n\n**How It Was Discovered**:\n- FireEye threat hunters noticed **unusual authentication activity**\n- Investigation revealed **SAML token forgery** (GoldMax backdoor)\n- Hypothesis: \"If attackers forged SAML tokens, we'd see anomalous cloud authentication patterns\"\n\n**Hunt Process**:\n1. Searched Azure AD logs for unusual token usage\n2. Found authentication from unexpected IPs\n3. Discovered backdoor in SolarWinds Orion update\n\n**Impact**: Threat hunting uncovered a nation-state supply chain attack, leading to global response.\n\n**Lesson**: Advanced threats require hypothesis-driven hunting, not just alert response.\n\n### Case Study 3: Carbanak Banking Malware\n\n**Background**: Carbanak APT stole $1 billion from banks worldwide.\n\n**How Threat Hunting Helped**:\n- Hunters noticed **unusual video recording software** on ATM servers\n- Hypothesis: \"If attackers control ATMs, they'd install remote access tools\"\n- Hunt revealed backdoors recording ATM cash-outs\n- Discovered command-and-control infrastructure\n\n**Impact**: Banking industry shared IOCs, preventing further attacks.\n\n**Lesson**: Threat hunting finds threats that automated detection misses.\n\n### Case Study 4: Microsoft Azure Hunt Team\n\n**Program**:\n- **Microsoft Detection and Response Team (DART)** conducts continuous threat hunts across Azure\n- Uses **Kusto Query Language (KQL)** for hunting\n- Hypothesis generation from threat intelligence\n\n**Metrics**:\n- Reduced dwell time from **30 days to < 24 hours**\n- Discovered **nation-state attacks** via proactive hunting\n- Created **hundreds of automated detections** from hunt findings\n\n**Lesson**: Enterprise-scale hunting requires automation, intelligence, and dedicated resources."
      }
    },
    {
      "type": "quiz",
      "content": {
        "text": "## Quick Knowledge Check\n\n**Question 1**: What is the primary goal of threat hunting?\n\nA) Wait for SIEM alerts to trigger\nB) Proactively search for threats that evade existing detection\nC) Patch vulnerabilities\nD) Respond to known incidents\n\n**Answer**: B - Threat hunting is proactive, not reactive.\n\n---\n\n**Question 2**: In the MITRE ATT&CK framework, what are \"Tactics\"?\n\nA) Specific tools attackers use\nB) The adversary's goals (what they want to achieve)\nC) Steps in incident response\nD) Types of malware\n\n**Answer**: B - Tactics represent adversary objectives like persistence or exfiltration.\n\n---\n\n**Question 3**: What is the first step in a hypothesis-driven threat hunt?\n\nA) Run automated scans\nB) Deploy new detection rules\nC) Formulate a testable hypothesis based on intelligence or assumptions\nD) Review all system logs manually\n\n**Answer**: C - Start with a hypothesis to guide your hunt.\n\n---\n\n**Question 4**: What is \"dwell time\"?\n\nA) Time it takes to patch a vulnerability\nB) Time between compromise and detection\nC) Time to respond to an alert\nD) Time to complete a threat hunt\n\n**Answer**: B - Threat hunting aims to reduce dwell time.\n\n---\n\n**Question 5**: Which of these is a key metric for measuring hunt program success?\n\nA) Number of emails sent\nB) Mean Time to Detect (MTTD)\nC) Number of servers\nD) Patch compliance rate\n\n**Answer**: B - MTTD measures how quickly you detect threats."
      }
    },
    {
      "type": "reflection",
      "content": {
        "text": "## Reflection Questions\n\nTake a moment to think about these questions:\n\n1. **If you were starting a threat hunting program at your organization, what would be your first hypothesis to test? Why?**\n\n   *Consider: What are your crown jewels? What threats keep you up at night?*\n\n2. **Think about your current security posture. Are you primarily reactive (waiting for alerts) or proactive (actively hunting)? What would it take to shift toward proactive hunting?**\n\n   *Hint: Tools, skills, time, leadership support?*\n\n3. **Look at the MITRE ATT&CK framework (attack.mitre.org). Pick one tactic (e.g., Credential Access). Can you detect all techniques under that tactic? What are your gaps?**\n\n   *This exercise reveals where you need to focus hunt efforts.*\n\n4. **If you discovered a sophisticated attacker in your environment today, how long do you think they've been there? What evidence would you look for first?**\n\n   *This is the hunter's mindset - assume breach and think like the adversary.*\n\n5. **How would you convince your leadership to invest in a threat hunting program? What ROI would you present?**\n\n   *Remember: Cost of hunting vs cost of a major breach.*"
      }
    },
    {
      "type": "mindset_coach",
      "content": {
        "text": "## Your Threat Hunting Journey Begins\n\n### You're Building a Critical Skill\n\nThreat hunting is one of the most **in-demand skills** in cybersecurity. Organizations are desperate for skilled hunters who can find threats before they cause damage. By mastering this discipline, you're positioning yourself as a **force multiplier** in any security team.\n\n### The Hunter's Mindset\n\n**You are now a digital detective**. Like Sherlock Holmes, you:\n- Observe what others miss\n- Form hypotheses and test them\n- Follow evidence wherever it leads\n- Never assume anything is \"normal\"\n\n**Embrace curiosity**: Every log entry tells a story. Every network connection has a purpose. Your job is to uncover the truth.\n\n### Learning from Every Hunt\n\n**There are no failed hunts**:\n- Found a threat? You're a hero who prevented damage.\n- Found nothing? You validated your defenses and learned what \"normal\" looks like.\n- Found false positive? You improved your detection accuracy.\n\nEvery hunt makes you **better, faster, more intuitive**.\n\n### Your Next Steps\n\n1. **Explore MITRE ATT&CK**: Visit attack.mitre.org and browse techniques\n2. **Practice hypothesis formation**: Write 3 hypotheses about your network\n3. **Set up a lab**: Install Sysmon, generate logs, practice hunting\n4. **Read hunt reports**: Learn from others (SANS Threat Hunting Summit talks)\n5. **Join the community**: Follow threat hunters on Twitter/LinkedIn\n\n### Recommended Resources\n\n- **MITRE ATT&CK**: attack.mitre.org\n- **SANS Threat Hunting Summit**: Free talks on YouTube\n- **Cyber Threat Intelligence**: ThreatConnect, Recorded Future\n- **Books**:\n  - \"Practical Threat Intelligence and Data-Driven Threat Hunting\" by Valentina Costa-GazcÃ³n\n  - \"Intelligence-Driven Incident Response\" by Rebekah Brown & Scott Roberts\n\n### You're Ready\n\nYou now understand the **fundamentals** of threat hunting:\n- âœ… Proactive vs reactive security\n- âœ… Hypothesis-driven methodology\n- âœ… MITRE ATT&CK framework\n- âœ… Hunt program structure\n- âœ… Metrics and ROI\n\n**Next lesson**, we'll dive into specific **hunting methodologies** and build your first hunt playbook.\n\n**Welcome to the hunt. The adversary is out there. Let's find them.** ðŸŽ¯"
      }
    }
  ]
}